{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\adith\\anaconda3\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\adith\\anaconda3\\lib\\site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\adith\\anaconda3\\lib\\site-packages (from xgboost) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "!pip install xgboost\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "malicious_df= pd.read_csv('../Dataset/intent_malware.csv')\n",
    "benign_df= pd.read_csv('../Dataset/intent_benign.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "malicious_df['Label']=[1]*len(malicious_df)\n",
    "benign_df['Label']=[0]*len(benign_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>android.intent.action.AIRPLANE_MODE</th>\n",
       "      <th>android.intent.action.ALL_APPS</th>\n",
       "      <th>android.intent.action.ANSWER</th>\n",
       "      <th>android.intent.action.APP_ERROR</th>\n",
       "      <th>android.intent.action.APPLICATION_PREFERENCES</th>\n",
       "      <th>android.intent.action.APPLICATION_RESTRICTIONS_CHANGED</th>\n",
       "      <th>android.intent.action.ASSIST</th>\n",
       "      <th>android.intent.action.ATTACH_DATA</th>\n",
       "      <th>android.intent.action.BATTERY_CHANGED</th>\n",
       "      <th>android.intent.action.BATTERY_LOW</th>\n",
       "      <th>android.intent.action.BATTERY_OKAY</th>\n",
       "      <th>android.intent.action.BOOT_COMPLETED</th>\n",
       "      <th>android.intent.action.BUG_REPORT</th>\n",
       "      <th>android.intent.action.CALL</th>\n",
       "      <th>android.intent.action.CALL_BUTTON</th>\n",
       "      <th>android.intent.action.CAMERA_BUTTON</th>\n",
       "      <th>android.intent.action.CARRIER_SETUP</th>\n",
       "      <th>android.intent.action.CHOOSER</th>\n",
       "      <th>android.intent.action.CLOSE_SYSTEM_DIALOGS</th>\n",
       "      <th>android.intent.action.CONFIGURATION_CHANGED</th>\n",
       "      <th>android.intent.action.CREATE_DOCUMENT</th>\n",
       "      <th>android.intent.action.CREATE_SHORTCUT</th>\n",
       "      <th>android.intent.action.DATE_CHANGED</th>\n",
       "      <th>android.intent.action.VIEW</th>\n",
       "      <th>android.intent.action.DEFINE</th>\n",
       "      <th>android.intent.action.DELETE</th>\n",
       "      <th>android.intent.action.DEVICE_STORAGE_LOW</th>\n",
       "      <th>android.intent.action.DEVICE_STORAGE_OK</th>\n",
       "      <th>android.intent.action.DIAL</th>\n",
       "      <th>android.intent.action.DOCK_EVENT</th>\n",
       "      <th>android.intent.action.DREAMING_STARTED</th>\n",
       "      <th>android.intent.action.DREAMING_STOPPED</th>\n",
       "      <th>android.intent.action.EDIT</th>\n",
       "      <th>android.intent.action.EXTERNAL_APPLICATIONS_AVAILABLE</th>\n",
       "      <th>android.intent.action.EXTERNAL_APPLICATIONS_UNAVAILABLE</th>\n",
       "      <th>android.intent.action.FACTORY_TEST</th>\n",
       "      <th>android.intent.action.GET_CONTENT</th>\n",
       "      <th>android.intent.action.GET_RESTRICTION_ENTRIES</th>\n",
       "      <th>android.intent.action.GTALK_CONNECTED</th>\n",
       "      <th>android.intent.action.GTALK_DISCONNECTED</th>\n",
       "      <th>android.intent.action.HEADSET_PLUG</th>\n",
       "      <th>android.intent.action.INPUT_METHOD_CHANGED</th>\n",
       "      <th>android.intent.action.INSERT</th>\n",
       "      <th>android.intent.action.INSERT_OR_EDIT</th>\n",
       "      <th>android.intent.action.INSTALL_FAILURE</th>\n",
       "      <th>android.intent.action.INSTALL_PACKAGE</th>\n",
       "      <th>android.intent.action.LOCALE_CHANGED</th>\n",
       "      <th>android.intent.action.LOCKED_BOOT_COMPLETED</th>\n",
       "      <th>android.intent.action.MAIN</th>\n",
       "      <th>...</th>\n",
       "      <th>android.intent.extra.restrictions_intent</th>\n",
       "      <th>android.intent.extra.restrictions_list</th>\n",
       "      <th>android.intent.extra.RESULT_RECEIVER</th>\n",
       "      <th>android.intent.extra.RETURN_RESULT</th>\n",
       "      <th>android.intent.extra.shortcut.ICON</th>\n",
       "      <th>android.intent.extra.shortcut.ICON_RESOURCE</th>\n",
       "      <th>android.intent.extra.shortcut.ID</th>\n",
       "      <th>android.intent.extra.shortcut.INTENT</th>\n",
       "      <th>android.intent.extra.shortcut.NAME</th>\n",
       "      <th>android.intent.extra.SHUTDOWN_USERSPACE_ONLY</th>\n",
       "      <th>android.intent.extra.SPLIT_NAME</th>\n",
       "      <th>android.intent.extra.STREAM</th>\n",
       "      <th>android.intent.extra.SUBJECT</th>\n",
       "      <th>android.intent.extra.SUSPENDED_PACKAGE_EXTRAS</th>\n",
       "      <th>android.intent.extra.TEMPLATE</th>\n",
       "      <th>android.intent.extra.TEXT</th>\n",
       "      <th>android.intent.extra.TITLE</th>\n",
       "      <th>android.intent.extra.UID</th>\n",
       "      <th>android.intent.extra.USER</th>\n",
       "      <th>(0x00000001)</th>\n",
       "      <th>(0x00000004)</th>\n",
       "      <th>(0x00000080)</th>\n",
       "      <th>(0x00000008)</th>\n",
       "      <th>(0x00000002)</th>\n",
       "      <th>(0x00000100)</th>\n",
       "      <th>(0x00000010)</th>\n",
       "      <th>(0x00000040)</th>\n",
       "      <th>(0x00000020)</th>\n",
       "      <th>(0x00400000)</th>\n",
       "      <th>(0x00008000)</th>\n",
       "      <th>(0x04000000)</th>\n",
       "      <th>(0x00080000)</th>\n",
       "      <th>(0x00800000)</th>\n",
       "      <th>(0x02000000)</th>\n",
       "      <th>(0x00001000)</th>\n",
       "      <th>(0x00100000)</th>\n",
       "      <th>(0x00000800)</th>\n",
       "      <th>(0x08000000)</th>\n",
       "      <th>(0x10000000)</th>\n",
       "      <th>(0x00010000)</th>\n",
       "      <th>(0x40000000)</th>\n",
       "      <th>(0x00040000)</th>\n",
       "      <th>(0x01000000)</th>\n",
       "      <th>(0x00020000)</th>\n",
       "      <th>(0x00200000)</th>\n",
       "      <th>(0x00002000)</th>\n",
       "      <th>(0x20000000)</th>\n",
       "      <th>(0x00004000)</th>\n",
       "      <th>android.dock_home</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b971d3ab969ed8850e35fe805e253bcb8ef6b8a449baaf...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2f360c0458e300a92bd44e9c2b7aff25fe295121a3c2f9...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>328ff57e39148daf440359709e92989aad445f1b41b3f3...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32ac3e58124d8ae53d891f296122395e27216856947e0a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4f85637857f489cae9ab492c306b5c122a8efd826c258e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 275 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Unnamed: 0  \\\n",
       "0  b971d3ab969ed8850e35fe805e253bcb8ef6b8a449baaf...   \n",
       "1  2f360c0458e300a92bd44e9c2b7aff25fe295121a3c2f9...   \n",
       "2  328ff57e39148daf440359709e92989aad445f1b41b3f3...   \n",
       "3  32ac3e58124d8ae53d891f296122395e27216856947e0a...   \n",
       "4  4f85637857f489cae9ab492c306b5c122a8efd826c258e...   \n",
       "\n",
       "   android.intent.action.AIRPLANE_MODE  android.intent.action.ALL_APPS  \\\n",
       "0                                    0                               0   \n",
       "1                                    0                               0   \n",
       "2                                    0                               0   \n",
       "3                                    0                               0   \n",
       "4                                    0                               0   \n",
       "\n",
       "   android.intent.action.ANSWER  android.intent.action.APP_ERROR  \\\n",
       "0                             0                                0   \n",
       "1                             0                                0   \n",
       "2                             0                                0   \n",
       "3                             0                                0   \n",
       "4                             0                                0   \n",
       "\n",
       "   android.intent.action.APPLICATION_PREFERENCES  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "\n",
       "   android.intent.action.APPLICATION_RESTRICTIONS_CHANGED  \\\n",
       "0                                                  0        \n",
       "1                                                  0        \n",
       "2                                                  0        \n",
       "3                                                  0        \n",
       "4                                                  0        \n",
       "\n",
       "   android.intent.action.ASSIST  android.intent.action.ATTACH_DATA  \\\n",
       "0                             0                                  0   \n",
       "1                             0                                  0   \n",
       "2                             0                                  0   \n",
       "3                             0                                  0   \n",
       "4                             0                                  0   \n",
       "\n",
       "   android.intent.action.BATTERY_CHANGED  android.intent.action.BATTERY_LOW  \\\n",
       "0                                      0                                  0   \n",
       "1                                      0                                  0   \n",
       "2                                      0                                  0   \n",
       "3                                      0                                  0   \n",
       "4                                      0                                  0   \n",
       "\n",
       "   android.intent.action.BATTERY_OKAY  android.intent.action.BOOT_COMPLETED  \\\n",
       "0                                   0                                     0   \n",
       "1                                   0                                     1   \n",
       "2                                   0                                     1   \n",
       "3                                   0                                     1   \n",
       "4                                   0                                     1   \n",
       "\n",
       "   android.intent.action.BUG_REPORT  android.intent.action.CALL  \\\n",
       "0                                 0                           0   \n",
       "1                                 0                           0   \n",
       "2                                 0                           0   \n",
       "3                                 0                           0   \n",
       "4                                 0                           0   \n",
       "\n",
       "   android.intent.action.CALL_BUTTON  android.intent.action.CAMERA_BUTTON  \\\n",
       "0                                  0                                    0   \n",
       "1                                  0                                    0   \n",
       "2                                  0                                    0   \n",
       "3                                  0                                    0   \n",
       "4                                  0                                    0   \n",
       "\n",
       "   android.intent.action.CARRIER_SETUP  android.intent.action.CHOOSER  \\\n",
       "0                                    0                              0   \n",
       "1                                    0                              0   \n",
       "2                                    0                              0   \n",
       "3                                    0                              0   \n",
       "4                                    0                              0   \n",
       "\n",
       "   android.intent.action.CLOSE_SYSTEM_DIALOGS  \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "\n",
       "   android.intent.action.CONFIGURATION_CHANGED  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "2                                            0   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "\n",
       "   android.intent.action.CREATE_DOCUMENT  \\\n",
       "0                                      0   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "3                                      0   \n",
       "4                                      0   \n",
       "\n",
       "   android.intent.action.CREATE_SHORTCUT  android.intent.action.DATE_CHANGED  \\\n",
       "0                                      0                                   0   \n",
       "1                                      0                                   0   \n",
       "2                                      0                                   0   \n",
       "3                                      0                                   0   \n",
       "4                                      0                                   0   \n",
       "\n",
       "   android.intent.action.VIEW  android.intent.action.DEFINE  \\\n",
       "0                           0                             0   \n",
       "1                           0                             0   \n",
       "2                           0                             0   \n",
       "3                           0                             0   \n",
       "4                           0                             0   \n",
       "\n",
       "   android.intent.action.DELETE  android.intent.action.DEVICE_STORAGE_LOW  \\\n",
       "0                             0                                         0   \n",
       "1                             0                                         0   \n",
       "2                             0                                         0   \n",
       "3                             0                                         0   \n",
       "4                             0                                         0   \n",
       "\n",
       "   android.intent.action.DEVICE_STORAGE_OK  android.intent.action.DIAL  \\\n",
       "0                                        0                           0   \n",
       "1                                        0                           0   \n",
       "2                                        0                           0   \n",
       "3                                        0                           0   \n",
       "4                                        0                           0   \n",
       "\n",
       "   android.intent.action.DOCK_EVENT  android.intent.action.DREAMING_STARTED  \\\n",
       "0                                 0                                       0   \n",
       "1                                 0                                       0   \n",
       "2                                 0                                       0   \n",
       "3                                 0                                       0   \n",
       "4                                 0                                       0   \n",
       "\n",
       "   android.intent.action.DREAMING_STOPPED  android.intent.action.EDIT  \\\n",
       "0                                       0                           0   \n",
       "1                                       0                           0   \n",
       "2                                       0                           0   \n",
       "3                                       0                           0   \n",
       "4                                       0                           0   \n",
       "\n",
       "   android.intent.action.EXTERNAL_APPLICATIONS_AVAILABLE  \\\n",
       "0                                                  0       \n",
       "1                                                  0       \n",
       "2                                                  0       \n",
       "3                                                  0       \n",
       "4                                                  0       \n",
       "\n",
       "   android.intent.action.EXTERNAL_APPLICATIONS_UNAVAILABLE  \\\n",
       "0                                                  0         \n",
       "1                                                  0         \n",
       "2                                                  0         \n",
       "3                                                  0         \n",
       "4                                                  0         \n",
       "\n",
       "   android.intent.action.FACTORY_TEST  android.intent.action.GET_CONTENT  \\\n",
       "0                                   0                                  0   \n",
       "1                                   0                                  0   \n",
       "2                                   0                                  0   \n",
       "3                                   0                                  0   \n",
       "4                                   0                                  0   \n",
       "\n",
       "   android.intent.action.GET_RESTRICTION_ENTRIES  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "\n",
       "   android.intent.action.GTALK_CONNECTED  \\\n",
       "0                                      0   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "3                                      0   \n",
       "4                                      0   \n",
       "\n",
       "   android.intent.action.GTALK_DISCONNECTED  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "\n",
       "   android.intent.action.HEADSET_PLUG  \\\n",
       "0                                   0   \n",
       "1                                   0   \n",
       "2                                   0   \n",
       "3                                   0   \n",
       "4                                   0   \n",
       "\n",
       "   android.intent.action.INPUT_METHOD_CHANGED  android.intent.action.INSERT  \\\n",
       "0                                           0                             0   \n",
       "1                                           0                             0   \n",
       "2                                           0                             0   \n",
       "3                                           0                             0   \n",
       "4                                           0                             0   \n",
       "\n",
       "   android.intent.action.INSERT_OR_EDIT  \\\n",
       "0                                     0   \n",
       "1                                     0   \n",
       "2                                     0   \n",
       "3                                     0   \n",
       "4                                     0   \n",
       "\n",
       "   android.intent.action.INSTALL_FAILURE  \\\n",
       "0                                      0   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "3                                      0   \n",
       "4                                      0   \n",
       "\n",
       "   android.intent.action.INSTALL_PACKAGE  \\\n",
       "0                                      0   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "3                                      0   \n",
       "4                                      0   \n",
       "\n",
       "   android.intent.action.LOCALE_CHANGED  \\\n",
       "0                                     0   \n",
       "1                                     0   \n",
       "2                                     0   \n",
       "3                                     0   \n",
       "4                                     0   \n",
       "\n",
       "   android.intent.action.LOCKED_BOOT_COMPLETED  android.intent.action.MAIN  \\\n",
       "0                                            0                           1   \n",
       "1                                            0                           1   \n",
       "2                                            0                           1   \n",
       "3                                            0                           1   \n",
       "4                                            0                           1   \n",
       "\n",
       "   ...  android.intent.extra.restrictions_intent  \\\n",
       "0  ...                                         0   \n",
       "1  ...                                         0   \n",
       "2  ...                                         0   \n",
       "3  ...                                         0   \n",
       "4  ...                                         0   \n",
       "\n",
       "   android.intent.extra.restrictions_list  \\\n",
       "0                                       0   \n",
       "1                                       0   \n",
       "2                                       0   \n",
       "3                                       0   \n",
       "4                                       0   \n",
       "\n",
       "   android.intent.extra.RESULT_RECEIVER  android.intent.extra.RETURN_RESULT  \\\n",
       "0                                     0                                   0   \n",
       "1                                     0                                   0   \n",
       "2                                     0                                   0   \n",
       "3                                     0                                   0   \n",
       "4                                     0                                   0   \n",
       "\n",
       "   android.intent.extra.shortcut.ICON  \\\n",
       "0                                   0   \n",
       "1                                   0   \n",
       "2                                   0   \n",
       "3                                   0   \n",
       "4                                   0   \n",
       "\n",
       "   android.intent.extra.shortcut.ICON_RESOURCE  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "2                                            0   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "\n",
       "   android.intent.extra.shortcut.ID  android.intent.extra.shortcut.INTENT  \\\n",
       "0                                 0                                     0   \n",
       "1                                 0                                     0   \n",
       "2                                 0                                     0   \n",
       "3                                 0                                     0   \n",
       "4                                 0                                     0   \n",
       "\n",
       "   android.intent.extra.shortcut.NAME  \\\n",
       "0                                   0   \n",
       "1                                   0   \n",
       "2                                   0   \n",
       "3                                   0   \n",
       "4                                   0   \n",
       "\n",
       "   android.intent.extra.SHUTDOWN_USERSPACE_ONLY  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "\n",
       "   android.intent.extra.SPLIT_NAME  android.intent.extra.STREAM  \\\n",
       "0                                0                            0   \n",
       "1                                0                            0   \n",
       "2                                0                            0   \n",
       "3                                0                            0   \n",
       "4                                0                            0   \n",
       "\n",
       "   android.intent.extra.SUBJECT  \\\n",
       "0                             0   \n",
       "1                             0   \n",
       "2                             0   \n",
       "3                             0   \n",
       "4                             0   \n",
       "\n",
       "   android.intent.extra.SUSPENDED_PACKAGE_EXTRAS  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "\n",
       "   android.intent.extra.TEMPLATE  android.intent.extra.TEXT  \\\n",
       "0                              0                          0   \n",
       "1                              0                          0   \n",
       "2                              0                          0   \n",
       "3                              0                          0   \n",
       "4                              0                          0   \n",
       "\n",
       "   android.intent.extra.TITLE  android.intent.extra.UID  \\\n",
       "0                           0                         0   \n",
       "1                           0                         0   \n",
       "2                           0                         0   \n",
       "3                           0                         0   \n",
       "4                           0                         0   \n",
       "\n",
       "   android.intent.extra.USER  (0x00000001)  (0x00000004)  (0x00000080)  \\\n",
       "0                          0             0             0             0   \n",
       "1                          0             0             0             0   \n",
       "2                          0             0             0             0   \n",
       "3                          0             0             0             0   \n",
       "4                          0             0             0             0   \n",
       "\n",
       "   (0x00000008)  (0x00000002)  (0x00000100)  (0x00000010)  (0x00000040)  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   (0x00000020)  (0x00400000)  (0x00008000)  (0x04000000)  (0x00080000)  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   (0x00800000)  (0x02000000)  (0x00001000)  (0x00100000)  (0x00000800)  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   (0x08000000)  (0x10000000)  (0x00010000)  (0x40000000)  (0x00040000)  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   (0x01000000)  (0x00020000)  (0x00200000)  (0x00002000)  (0x20000000)  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   (0x00004000)  android.dock_home  Label  \n",
       "0             0                  0      1  \n",
       "1             0                  0      1  \n",
       "2             0                  0      1  \n",
       "3             0                  0      1  \n",
       "4             0                  0      1  \n",
       "\n",
       "[5 rows x 275 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malicious_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>android.intent.action.AIRPLANE_MODE</th>\n",
       "      <th>android.intent.action.ALL_APPS</th>\n",
       "      <th>android.intent.action.ANSWER</th>\n",
       "      <th>android.intent.action.APP_ERROR</th>\n",
       "      <th>android.intent.action.APPLICATION_PREFERENCES</th>\n",
       "      <th>android.intent.action.APPLICATION_RESTRICTIONS_CHANGED</th>\n",
       "      <th>android.intent.action.ASSIST</th>\n",
       "      <th>android.intent.action.ATTACH_DATA</th>\n",
       "      <th>android.intent.action.BATTERY_CHANGED</th>\n",
       "      <th>android.intent.action.BATTERY_LOW</th>\n",
       "      <th>android.intent.action.BATTERY_OKAY</th>\n",
       "      <th>android.intent.action.BOOT_COMPLETED</th>\n",
       "      <th>android.intent.action.BUG_REPORT</th>\n",
       "      <th>android.intent.action.CALL</th>\n",
       "      <th>android.intent.action.CALL_BUTTON</th>\n",
       "      <th>android.intent.action.CAMERA_BUTTON</th>\n",
       "      <th>android.intent.action.CARRIER_SETUP</th>\n",
       "      <th>android.intent.action.CHOOSER</th>\n",
       "      <th>android.intent.action.CLOSE_SYSTEM_DIALOGS</th>\n",
       "      <th>android.intent.action.CONFIGURATION_CHANGED</th>\n",
       "      <th>android.intent.action.CREATE_DOCUMENT</th>\n",
       "      <th>android.intent.action.CREATE_SHORTCUT</th>\n",
       "      <th>android.intent.action.DATE_CHANGED</th>\n",
       "      <th>android.intent.action.VIEW</th>\n",
       "      <th>android.intent.action.DEFINE</th>\n",
       "      <th>android.intent.action.DELETE</th>\n",
       "      <th>android.intent.action.DEVICE_STORAGE_LOW</th>\n",
       "      <th>android.intent.action.DEVICE_STORAGE_OK</th>\n",
       "      <th>android.intent.action.DIAL</th>\n",
       "      <th>android.intent.action.DOCK_EVENT</th>\n",
       "      <th>android.intent.action.DREAMING_STARTED</th>\n",
       "      <th>android.intent.action.DREAMING_STOPPED</th>\n",
       "      <th>android.intent.action.EDIT</th>\n",
       "      <th>android.intent.action.EXTERNAL_APPLICATIONS_AVAILABLE</th>\n",
       "      <th>android.intent.action.EXTERNAL_APPLICATIONS_UNAVAILABLE</th>\n",
       "      <th>android.intent.action.FACTORY_TEST</th>\n",
       "      <th>android.intent.action.GET_CONTENT</th>\n",
       "      <th>android.intent.action.GET_RESTRICTION_ENTRIES</th>\n",
       "      <th>android.intent.action.GTALK_CONNECTED</th>\n",
       "      <th>android.intent.action.GTALK_DISCONNECTED</th>\n",
       "      <th>android.intent.action.HEADSET_PLUG</th>\n",
       "      <th>android.intent.action.INPUT_METHOD_CHANGED</th>\n",
       "      <th>android.intent.action.INSERT</th>\n",
       "      <th>android.intent.action.INSERT_OR_EDIT</th>\n",
       "      <th>android.intent.action.INSTALL_FAILURE</th>\n",
       "      <th>android.intent.action.INSTALL_PACKAGE</th>\n",
       "      <th>android.intent.action.LOCALE_CHANGED</th>\n",
       "      <th>android.intent.action.LOCKED_BOOT_COMPLETED</th>\n",
       "      <th>android.intent.action.MAIN</th>\n",
       "      <th>...</th>\n",
       "      <th>android.intent.extra.restrictions_intent</th>\n",
       "      <th>android.intent.extra.restrictions_list</th>\n",
       "      <th>android.intent.extra.RESULT_RECEIVER</th>\n",
       "      <th>android.intent.extra.RETURN_RESULT</th>\n",
       "      <th>android.intent.extra.shortcut.ICON</th>\n",
       "      <th>android.intent.extra.shortcut.ICON_RESOURCE</th>\n",
       "      <th>android.intent.extra.shortcut.ID</th>\n",
       "      <th>android.intent.extra.shortcut.INTENT</th>\n",
       "      <th>android.intent.extra.shortcut.NAME</th>\n",
       "      <th>android.intent.extra.SHUTDOWN_USERSPACE_ONLY</th>\n",
       "      <th>android.intent.extra.SPLIT_NAME</th>\n",
       "      <th>android.intent.extra.STREAM</th>\n",
       "      <th>android.intent.extra.SUBJECT</th>\n",
       "      <th>android.intent.extra.SUSPENDED_PACKAGE_EXTRAS</th>\n",
       "      <th>android.intent.extra.TEMPLATE</th>\n",
       "      <th>android.intent.extra.TEXT</th>\n",
       "      <th>android.intent.extra.TITLE</th>\n",
       "      <th>android.intent.extra.UID</th>\n",
       "      <th>android.intent.extra.USER</th>\n",
       "      <th>(0x00000001)</th>\n",
       "      <th>(0x00000004)</th>\n",
       "      <th>(0x00000080)</th>\n",
       "      <th>(0x00000008)</th>\n",
       "      <th>(0x00000002)</th>\n",
       "      <th>(0x00000100)</th>\n",
       "      <th>(0x00000010)</th>\n",
       "      <th>(0x00000040)</th>\n",
       "      <th>(0x00000020)</th>\n",
       "      <th>(0x00400000)</th>\n",
       "      <th>(0x00008000)</th>\n",
       "      <th>(0x04000000)</th>\n",
       "      <th>(0x00080000)</th>\n",
       "      <th>(0x00800000)</th>\n",
       "      <th>(0x02000000)</th>\n",
       "      <th>(0x00001000)</th>\n",
       "      <th>(0x00100000)</th>\n",
       "      <th>(0x00000800)</th>\n",
       "      <th>(0x08000000)</th>\n",
       "      <th>(0x10000000)</th>\n",
       "      <th>(0x00010000)</th>\n",
       "      <th>(0x40000000)</th>\n",
       "      <th>(0x00040000)</th>\n",
       "      <th>(0x01000000)</th>\n",
       "      <th>(0x00020000)</th>\n",
       "      <th>(0x00200000)</th>\n",
       "      <th>(0x00002000)</th>\n",
       "      <th>(0x20000000)</th>\n",
       "      <th>(0x00004000)</th>\n",
       "      <th>android.dock_home</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8919.xml</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7534.xml</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8715.xml</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1779.xml</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3982.xml</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 275 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  android.intent.action.AIRPLANE_MODE  \\\n",
       "0   8919.xml                                    0   \n",
       "1   7534.xml                                    0   \n",
       "2   8715.xml                                    0   \n",
       "3   1779.xml                                    0   \n",
       "4   3982.xml                                    0   \n",
       "\n",
       "   android.intent.action.ALL_APPS  android.intent.action.ANSWER  \\\n",
       "0                               0                             0   \n",
       "1                               0                             0   \n",
       "2                               0                             0   \n",
       "3                               0                             0   \n",
       "4                               0                             0   \n",
       "\n",
       "   android.intent.action.APP_ERROR  \\\n",
       "0                                0   \n",
       "1                                0   \n",
       "2                                0   \n",
       "3                                0   \n",
       "4                                0   \n",
       "\n",
       "   android.intent.action.APPLICATION_PREFERENCES  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "\n",
       "   android.intent.action.APPLICATION_RESTRICTIONS_CHANGED  \\\n",
       "0                                                  0        \n",
       "1                                                  0        \n",
       "2                                                  0        \n",
       "3                                                  0        \n",
       "4                                                  0        \n",
       "\n",
       "   android.intent.action.ASSIST  android.intent.action.ATTACH_DATA  \\\n",
       "0                             0                                  0   \n",
       "1                             0                                  0   \n",
       "2                             0                                  0   \n",
       "3                             0                                  0   \n",
       "4                             0                                  0   \n",
       "\n",
       "   android.intent.action.BATTERY_CHANGED  android.intent.action.BATTERY_LOW  \\\n",
       "0                                      0                                  0   \n",
       "1                                      0                                  0   \n",
       "2                                      0                                  0   \n",
       "3                                      0                                  0   \n",
       "4                                      0                                  0   \n",
       "\n",
       "   android.intent.action.BATTERY_OKAY  android.intent.action.BOOT_COMPLETED  \\\n",
       "0                                   0                                     0   \n",
       "1                                   0                                     0   \n",
       "2                                   0                                     0   \n",
       "3                                   0                                     0   \n",
       "4                                   0                                     0   \n",
       "\n",
       "   android.intent.action.BUG_REPORT  android.intent.action.CALL  \\\n",
       "0                                 0                           0   \n",
       "1                                 0                           0   \n",
       "2                                 0                           0   \n",
       "3                                 0                           0   \n",
       "4                                 0                           0   \n",
       "\n",
       "   android.intent.action.CALL_BUTTON  android.intent.action.CAMERA_BUTTON  \\\n",
       "0                                  0                                    0   \n",
       "1                                  0                                    0   \n",
       "2                                  0                                    0   \n",
       "3                                  0                                    0   \n",
       "4                                  0                                    0   \n",
       "\n",
       "   android.intent.action.CARRIER_SETUP  android.intent.action.CHOOSER  \\\n",
       "0                                    0                              0   \n",
       "1                                    0                              0   \n",
       "2                                    0                              0   \n",
       "3                                    0                              0   \n",
       "4                                    0                              0   \n",
       "\n",
       "   android.intent.action.CLOSE_SYSTEM_DIALOGS  \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "\n",
       "   android.intent.action.CONFIGURATION_CHANGED  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "2                                            0   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "\n",
       "   android.intent.action.CREATE_DOCUMENT  \\\n",
       "0                                      0   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "3                                      0   \n",
       "4                                      0   \n",
       "\n",
       "   android.intent.action.CREATE_SHORTCUT  android.intent.action.DATE_CHANGED  \\\n",
       "0                                      0                                   0   \n",
       "1                                      0                                   0   \n",
       "2                                      0                                   0   \n",
       "3                                      0                                   0   \n",
       "4                                      0                                   0   \n",
       "\n",
       "   android.intent.action.VIEW  android.intent.action.DEFINE  \\\n",
       "0                           0                             0   \n",
       "1                           0                             0   \n",
       "2                           0                             0   \n",
       "3                           0                             0   \n",
       "4                           0                             0   \n",
       "\n",
       "   android.intent.action.DELETE  android.intent.action.DEVICE_STORAGE_LOW  \\\n",
       "0                             0                                         0   \n",
       "1                             0                                         0   \n",
       "2                             0                                         0   \n",
       "3                             0                                         0   \n",
       "4                             0                                         0   \n",
       "\n",
       "   android.intent.action.DEVICE_STORAGE_OK  android.intent.action.DIAL  \\\n",
       "0                                        0                           0   \n",
       "1                                        0                           0   \n",
       "2                                        0                           0   \n",
       "3                                        0                           0   \n",
       "4                                        0                           0   \n",
       "\n",
       "   android.intent.action.DOCK_EVENT  android.intent.action.DREAMING_STARTED  \\\n",
       "0                                 0                                       0   \n",
       "1                                 0                                       0   \n",
       "2                                 0                                       0   \n",
       "3                                 0                                       0   \n",
       "4                                 0                                       0   \n",
       "\n",
       "   android.intent.action.DREAMING_STOPPED  android.intent.action.EDIT  \\\n",
       "0                                       0                           0   \n",
       "1                                       0                           0   \n",
       "2                                       0                           0   \n",
       "3                                       0                           0   \n",
       "4                                       0                           0   \n",
       "\n",
       "   android.intent.action.EXTERNAL_APPLICATIONS_AVAILABLE  \\\n",
       "0                                                  0       \n",
       "1                                                  0       \n",
       "2                                                  0       \n",
       "3                                                  0       \n",
       "4                                                  0       \n",
       "\n",
       "   android.intent.action.EXTERNAL_APPLICATIONS_UNAVAILABLE  \\\n",
       "0                                                  0         \n",
       "1                                                  0         \n",
       "2                                                  0         \n",
       "3                                                  0         \n",
       "4                                                  0         \n",
       "\n",
       "   android.intent.action.FACTORY_TEST  android.intent.action.GET_CONTENT  \\\n",
       "0                                   0                                  0   \n",
       "1                                   0                                  0   \n",
       "2                                   0                                  0   \n",
       "3                                   0                                  0   \n",
       "4                                   0                                  0   \n",
       "\n",
       "   android.intent.action.GET_RESTRICTION_ENTRIES  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "\n",
       "   android.intent.action.GTALK_CONNECTED  \\\n",
       "0                                      0   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "3                                      0   \n",
       "4                                      0   \n",
       "\n",
       "   android.intent.action.GTALK_DISCONNECTED  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "\n",
       "   android.intent.action.HEADSET_PLUG  \\\n",
       "0                                   0   \n",
       "1                                   0   \n",
       "2                                   0   \n",
       "3                                   0   \n",
       "4                                   0   \n",
       "\n",
       "   android.intent.action.INPUT_METHOD_CHANGED  android.intent.action.INSERT  \\\n",
       "0                                           0                             0   \n",
       "1                                           0                             0   \n",
       "2                                           0                             0   \n",
       "3                                           0                             0   \n",
       "4                                           0                             0   \n",
       "\n",
       "   android.intent.action.INSERT_OR_EDIT  \\\n",
       "0                                     0   \n",
       "1                                     0   \n",
       "2                                     0   \n",
       "3                                     0   \n",
       "4                                     0   \n",
       "\n",
       "   android.intent.action.INSTALL_FAILURE  \\\n",
       "0                                      0   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "3                                      0   \n",
       "4                                      0   \n",
       "\n",
       "   android.intent.action.INSTALL_PACKAGE  \\\n",
       "0                                      0   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "3                                      0   \n",
       "4                                      0   \n",
       "\n",
       "   android.intent.action.LOCALE_CHANGED  \\\n",
       "0                                     0   \n",
       "1                                     0   \n",
       "2                                     0   \n",
       "3                                     0   \n",
       "4                                     0   \n",
       "\n",
       "   android.intent.action.LOCKED_BOOT_COMPLETED  android.intent.action.MAIN  \\\n",
       "0                                            0                           1   \n",
       "1                                            0                           1   \n",
       "2                                            0                           1   \n",
       "3                                            0                           1   \n",
       "4                                            0                           1   \n",
       "\n",
       "   ...  android.intent.extra.restrictions_intent  \\\n",
       "0  ...                                         0   \n",
       "1  ...                                         0   \n",
       "2  ...                                         0   \n",
       "3  ...                                         0   \n",
       "4  ...                                         0   \n",
       "\n",
       "   android.intent.extra.restrictions_list  \\\n",
       "0                                       0   \n",
       "1                                       0   \n",
       "2                                       0   \n",
       "3                                       0   \n",
       "4                                       0   \n",
       "\n",
       "   android.intent.extra.RESULT_RECEIVER  android.intent.extra.RETURN_RESULT  \\\n",
       "0                                     0                                   0   \n",
       "1                                     0                                   0   \n",
       "2                                     0                                   0   \n",
       "3                                     0                                   0   \n",
       "4                                     0                                   0   \n",
       "\n",
       "   android.intent.extra.shortcut.ICON  \\\n",
       "0                                   0   \n",
       "1                                   0   \n",
       "2                                   0   \n",
       "3                                   0   \n",
       "4                                   0   \n",
       "\n",
       "   android.intent.extra.shortcut.ICON_RESOURCE  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "2                                            0   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "\n",
       "   android.intent.extra.shortcut.ID  android.intent.extra.shortcut.INTENT  \\\n",
       "0                                 0                                     0   \n",
       "1                                 0                                     0   \n",
       "2                                 0                                     0   \n",
       "3                                 0                                     0   \n",
       "4                                 0                                     0   \n",
       "\n",
       "   android.intent.extra.shortcut.NAME  \\\n",
       "0                                   0   \n",
       "1                                   0   \n",
       "2                                   0   \n",
       "3                                   0   \n",
       "4                                   0   \n",
       "\n",
       "   android.intent.extra.SHUTDOWN_USERSPACE_ONLY  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "\n",
       "   android.intent.extra.SPLIT_NAME  android.intent.extra.STREAM  \\\n",
       "0                                0                            0   \n",
       "1                                0                            0   \n",
       "2                                0                            0   \n",
       "3                                0                            0   \n",
       "4                                0                            0   \n",
       "\n",
       "   android.intent.extra.SUBJECT  \\\n",
       "0                             0   \n",
       "1                             0   \n",
       "2                             0   \n",
       "3                             0   \n",
       "4                             0   \n",
       "\n",
       "   android.intent.extra.SUSPENDED_PACKAGE_EXTRAS  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "\n",
       "   android.intent.extra.TEMPLATE  android.intent.extra.TEXT  \\\n",
       "0                              0                          0   \n",
       "1                              0                          0   \n",
       "2                              0                          0   \n",
       "3                              0                          0   \n",
       "4                              0                          0   \n",
       "\n",
       "   android.intent.extra.TITLE  android.intent.extra.UID  \\\n",
       "0                           0                         0   \n",
       "1                           0                         0   \n",
       "2                           0                         0   \n",
       "3                           0                         0   \n",
       "4                           0                         0   \n",
       "\n",
       "   android.intent.extra.USER  (0x00000001)  (0x00000004)  (0x00000080)  \\\n",
       "0                          0             0             0             0   \n",
       "1                          0             0             0             0   \n",
       "2                          0             0             0             0   \n",
       "3                          0             0             0             0   \n",
       "4                          0             0             0             0   \n",
       "\n",
       "   (0x00000008)  (0x00000002)  (0x00000100)  (0x00000010)  (0x00000040)  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   (0x00000020)  (0x00400000)  (0x00008000)  (0x04000000)  (0x00080000)  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   (0x00800000)  (0x02000000)  (0x00001000)  (0x00100000)  (0x00000800)  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   (0x08000000)  (0x10000000)  (0x00010000)  (0x40000000)  (0x00040000)  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   (0x01000000)  (0x00020000)  (0x00200000)  (0x00002000)  (0x20000000)  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   (0x00004000)  android.dock_home  Label  \n",
       "0             0                  0      0  \n",
       "1             0                  0      0  \n",
       "2             0                  0      0  \n",
       "3             0                  0      0  \n",
       "4             0                  0      0  \n",
       "\n",
       "[5 rows x 275 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benign_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "malicious_df=malicious_df.drop(malicious_df.columns[[0]], axis = 1)\n",
    "benign_df=benign_df.drop(benign_df.columns[[0]], axis = 1)\n",
    "df=pd.concat([malicious_df, benign_df])\n",
    "df = df.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>android.intent.action.AIRPLANE_MODE</th>\n",
       "      <th>android.intent.action.ALL_APPS</th>\n",
       "      <th>android.intent.action.ANSWER</th>\n",
       "      <th>android.intent.action.APP_ERROR</th>\n",
       "      <th>android.intent.action.APPLICATION_PREFERENCES</th>\n",
       "      <th>android.intent.action.APPLICATION_RESTRICTIONS_CHANGED</th>\n",
       "      <th>android.intent.action.ASSIST</th>\n",
       "      <th>android.intent.action.ATTACH_DATA</th>\n",
       "      <th>android.intent.action.BATTERY_CHANGED</th>\n",
       "      <th>android.intent.action.BATTERY_LOW</th>\n",
       "      <th>android.intent.action.BATTERY_OKAY</th>\n",
       "      <th>android.intent.action.BOOT_COMPLETED</th>\n",
       "      <th>android.intent.action.BUG_REPORT</th>\n",
       "      <th>android.intent.action.CALL</th>\n",
       "      <th>android.intent.action.CALL_BUTTON</th>\n",
       "      <th>android.intent.action.CAMERA_BUTTON</th>\n",
       "      <th>android.intent.action.CARRIER_SETUP</th>\n",
       "      <th>android.intent.action.CHOOSER</th>\n",
       "      <th>android.intent.action.CLOSE_SYSTEM_DIALOGS</th>\n",
       "      <th>android.intent.action.CONFIGURATION_CHANGED</th>\n",
       "      <th>android.intent.action.CREATE_DOCUMENT</th>\n",
       "      <th>android.intent.action.CREATE_SHORTCUT</th>\n",
       "      <th>android.intent.action.DATE_CHANGED</th>\n",
       "      <th>android.intent.action.VIEW</th>\n",
       "      <th>android.intent.action.DEFINE</th>\n",
       "      <th>android.intent.action.DELETE</th>\n",
       "      <th>android.intent.action.DEVICE_STORAGE_LOW</th>\n",
       "      <th>android.intent.action.DEVICE_STORAGE_OK</th>\n",
       "      <th>android.intent.action.DIAL</th>\n",
       "      <th>android.intent.action.DOCK_EVENT</th>\n",
       "      <th>android.intent.action.DREAMING_STARTED</th>\n",
       "      <th>android.intent.action.DREAMING_STOPPED</th>\n",
       "      <th>android.intent.action.EDIT</th>\n",
       "      <th>android.intent.action.EXTERNAL_APPLICATIONS_AVAILABLE</th>\n",
       "      <th>android.intent.action.EXTERNAL_APPLICATIONS_UNAVAILABLE</th>\n",
       "      <th>android.intent.action.FACTORY_TEST</th>\n",
       "      <th>android.intent.action.GET_CONTENT</th>\n",
       "      <th>android.intent.action.GET_RESTRICTION_ENTRIES</th>\n",
       "      <th>android.intent.action.GTALK_CONNECTED</th>\n",
       "      <th>android.intent.action.GTALK_DISCONNECTED</th>\n",
       "      <th>android.intent.action.HEADSET_PLUG</th>\n",
       "      <th>android.intent.action.INPUT_METHOD_CHANGED</th>\n",
       "      <th>android.intent.action.INSERT</th>\n",
       "      <th>android.intent.action.INSERT_OR_EDIT</th>\n",
       "      <th>android.intent.action.INSTALL_FAILURE</th>\n",
       "      <th>android.intent.action.INSTALL_PACKAGE</th>\n",
       "      <th>android.intent.action.LOCALE_CHANGED</th>\n",
       "      <th>android.intent.action.LOCKED_BOOT_COMPLETED</th>\n",
       "      <th>android.intent.action.MAIN</th>\n",
       "      <th>android.intent.action.MANAGE_NETWORK_USAGE</th>\n",
       "      <th>...</th>\n",
       "      <th>android.intent.extra.restrictions_intent</th>\n",
       "      <th>android.intent.extra.restrictions_list</th>\n",
       "      <th>android.intent.extra.RESULT_RECEIVER</th>\n",
       "      <th>android.intent.extra.RETURN_RESULT</th>\n",
       "      <th>android.intent.extra.shortcut.ICON</th>\n",
       "      <th>android.intent.extra.shortcut.ICON_RESOURCE</th>\n",
       "      <th>android.intent.extra.shortcut.ID</th>\n",
       "      <th>android.intent.extra.shortcut.INTENT</th>\n",
       "      <th>android.intent.extra.shortcut.NAME</th>\n",
       "      <th>android.intent.extra.SHUTDOWN_USERSPACE_ONLY</th>\n",
       "      <th>android.intent.extra.SPLIT_NAME</th>\n",
       "      <th>android.intent.extra.STREAM</th>\n",
       "      <th>android.intent.extra.SUBJECT</th>\n",
       "      <th>android.intent.extra.SUSPENDED_PACKAGE_EXTRAS</th>\n",
       "      <th>android.intent.extra.TEMPLATE</th>\n",
       "      <th>android.intent.extra.TEXT</th>\n",
       "      <th>android.intent.extra.TITLE</th>\n",
       "      <th>android.intent.extra.UID</th>\n",
       "      <th>android.intent.extra.USER</th>\n",
       "      <th>(0x00000001)</th>\n",
       "      <th>(0x00000004)</th>\n",
       "      <th>(0x00000080)</th>\n",
       "      <th>(0x00000008)</th>\n",
       "      <th>(0x00000002)</th>\n",
       "      <th>(0x00000100)</th>\n",
       "      <th>(0x00000010)</th>\n",
       "      <th>(0x00000040)</th>\n",
       "      <th>(0x00000020)</th>\n",
       "      <th>(0x00400000)</th>\n",
       "      <th>(0x00008000)</th>\n",
       "      <th>(0x04000000)</th>\n",
       "      <th>(0x00080000)</th>\n",
       "      <th>(0x00800000)</th>\n",
       "      <th>(0x02000000)</th>\n",
       "      <th>(0x00001000)</th>\n",
       "      <th>(0x00100000)</th>\n",
       "      <th>(0x00000800)</th>\n",
       "      <th>(0x08000000)</th>\n",
       "      <th>(0x10000000)</th>\n",
       "      <th>(0x00010000)</th>\n",
       "      <th>(0x40000000)</th>\n",
       "      <th>(0x00040000)</th>\n",
       "      <th>(0x01000000)</th>\n",
       "      <th>(0x00020000)</th>\n",
       "      <th>(0x00200000)</th>\n",
       "      <th>(0x00002000)</th>\n",
       "      <th>(0x20000000)</th>\n",
       "      <th>(0x00004000)</th>\n",
       "      <th>android.dock_home</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3698</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4934</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 274 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      android.intent.action.AIRPLANE_MODE  android.intent.action.ALL_APPS  \\\n",
       "721                                     0                               0   \n",
       "3698                                    0                               0   \n",
       "4934                                    0                               0   \n",
       "704                                     0                               0   \n",
       "3020                                    0                               0   \n",
       "\n",
       "      android.intent.action.ANSWER  android.intent.action.APP_ERROR  \\\n",
       "721                              0                                0   \n",
       "3698                             0                                0   \n",
       "4934                             0                                0   \n",
       "704                              0                                0   \n",
       "3020                             0                                0   \n",
       "\n",
       "      android.intent.action.APPLICATION_PREFERENCES  \\\n",
       "721                                               0   \n",
       "3698                                              0   \n",
       "4934                                              0   \n",
       "704                                               0   \n",
       "3020                                              0   \n",
       "\n",
       "      android.intent.action.APPLICATION_RESTRICTIONS_CHANGED  \\\n",
       "721                                                   0        \n",
       "3698                                                  0        \n",
       "4934                                                  0        \n",
       "704                                                   0        \n",
       "3020                                                  0        \n",
       "\n",
       "      android.intent.action.ASSIST  android.intent.action.ATTACH_DATA  \\\n",
       "721                              0                                  0   \n",
       "3698                             0                                  0   \n",
       "4934                             0                                  0   \n",
       "704                              0                                  0   \n",
       "3020                             0                                  0   \n",
       "\n",
       "      android.intent.action.BATTERY_CHANGED  \\\n",
       "721                                       0   \n",
       "3698                                      0   \n",
       "4934                                      0   \n",
       "704                                       0   \n",
       "3020                                      0   \n",
       "\n",
       "      android.intent.action.BATTERY_LOW  android.intent.action.BATTERY_OKAY  \\\n",
       "721                                   0                                   0   \n",
       "3698                                  0                                   0   \n",
       "4934                                  0                                   0   \n",
       "704                                   0                                   0   \n",
       "3020                                  0                                   0   \n",
       "\n",
       "      android.intent.action.BOOT_COMPLETED  android.intent.action.BUG_REPORT  \\\n",
       "721                                      0                                 0   \n",
       "3698                                     0                                 0   \n",
       "4934                                     0                                 0   \n",
       "704                                      0                                 0   \n",
       "3020                                     1                                 0   \n",
       "\n",
       "      android.intent.action.CALL  android.intent.action.CALL_BUTTON  \\\n",
       "721                            0                                  0   \n",
       "3698                           0                                  0   \n",
       "4934                           0                                  0   \n",
       "704                            0                                  0   \n",
       "3020                           0                                  0   \n",
       "\n",
       "      android.intent.action.CAMERA_BUTTON  \\\n",
       "721                                     0   \n",
       "3698                                    0   \n",
       "4934                                    0   \n",
       "704                                     0   \n",
       "3020                                    0   \n",
       "\n",
       "      android.intent.action.CARRIER_SETUP  android.intent.action.CHOOSER  \\\n",
       "721                                     0                              0   \n",
       "3698                                    0                              0   \n",
       "4934                                    0                              0   \n",
       "704                                     0                              0   \n",
       "3020                                    0                              0   \n",
       "\n",
       "      android.intent.action.CLOSE_SYSTEM_DIALOGS  \\\n",
       "721                                            0   \n",
       "3698                                           0   \n",
       "4934                                           0   \n",
       "704                                            0   \n",
       "3020                                           0   \n",
       "\n",
       "      android.intent.action.CONFIGURATION_CHANGED  \\\n",
       "721                                             0   \n",
       "3698                                            0   \n",
       "4934                                            0   \n",
       "704                                             0   \n",
       "3020                                            0   \n",
       "\n",
       "      android.intent.action.CREATE_DOCUMENT  \\\n",
       "721                                       0   \n",
       "3698                                      0   \n",
       "4934                                      0   \n",
       "704                                       0   \n",
       "3020                                      0   \n",
       "\n",
       "      android.intent.action.CREATE_SHORTCUT  \\\n",
       "721                                       0   \n",
       "3698                                      0   \n",
       "4934                                      0   \n",
       "704                                       0   \n",
       "3020                                      0   \n",
       "\n",
       "      android.intent.action.DATE_CHANGED  android.intent.action.VIEW  \\\n",
       "721                                    0                           0   \n",
       "3698                                   0                           0   \n",
       "4934                                   0                           0   \n",
       "704                                    0                           0   \n",
       "3020                                   0                           0   \n",
       "\n",
       "      android.intent.action.DEFINE  android.intent.action.DELETE  \\\n",
       "721                              0                             0   \n",
       "3698                             0                             0   \n",
       "4934                             0                             0   \n",
       "704                              0                             0   \n",
       "3020                             0                             0   \n",
       "\n",
       "      android.intent.action.DEVICE_STORAGE_LOW  \\\n",
       "721                                          0   \n",
       "3698                                         0   \n",
       "4934                                         0   \n",
       "704                                          0   \n",
       "3020                                         0   \n",
       "\n",
       "      android.intent.action.DEVICE_STORAGE_OK  android.intent.action.DIAL  \\\n",
       "721                                         0                           0   \n",
       "3698                                        0                           0   \n",
       "4934                                        0                           0   \n",
       "704                                         0                           0   \n",
       "3020                                        0                           0   \n",
       "\n",
       "      android.intent.action.DOCK_EVENT  \\\n",
       "721                                  0   \n",
       "3698                                 0   \n",
       "4934                                 0   \n",
       "704                                  0   \n",
       "3020                                 0   \n",
       "\n",
       "      android.intent.action.DREAMING_STARTED  \\\n",
       "721                                        0   \n",
       "3698                                       0   \n",
       "4934                                       0   \n",
       "704                                        0   \n",
       "3020                                       0   \n",
       "\n",
       "      android.intent.action.DREAMING_STOPPED  android.intent.action.EDIT  \\\n",
       "721                                        0                           0   \n",
       "3698                                       0                           0   \n",
       "4934                                       0                           0   \n",
       "704                                        0                           0   \n",
       "3020                                       0                           0   \n",
       "\n",
       "      android.intent.action.EXTERNAL_APPLICATIONS_AVAILABLE  \\\n",
       "721                                                   0       \n",
       "3698                                                  0       \n",
       "4934                                                  0       \n",
       "704                                                   0       \n",
       "3020                                                  0       \n",
       "\n",
       "      android.intent.action.EXTERNAL_APPLICATIONS_UNAVAILABLE  \\\n",
       "721                                                   0         \n",
       "3698                                                  0         \n",
       "4934                                                  0         \n",
       "704                                                   0         \n",
       "3020                                                  0         \n",
       "\n",
       "      android.intent.action.FACTORY_TEST  android.intent.action.GET_CONTENT  \\\n",
       "721                                    0                                  0   \n",
       "3698                                   0                                  0   \n",
       "4934                                   0                                  0   \n",
       "704                                    0                                  0   \n",
       "3020                                   0                                  0   \n",
       "\n",
       "      android.intent.action.GET_RESTRICTION_ENTRIES  \\\n",
       "721                                               0   \n",
       "3698                                              0   \n",
       "4934                                              0   \n",
       "704                                               0   \n",
       "3020                                              0   \n",
       "\n",
       "      android.intent.action.GTALK_CONNECTED  \\\n",
       "721                                       0   \n",
       "3698                                      0   \n",
       "4934                                      0   \n",
       "704                                       0   \n",
       "3020                                      0   \n",
       "\n",
       "      android.intent.action.GTALK_DISCONNECTED  \\\n",
       "721                                          0   \n",
       "3698                                         0   \n",
       "4934                                         0   \n",
       "704                                          0   \n",
       "3020                                         0   \n",
       "\n",
       "      android.intent.action.HEADSET_PLUG  \\\n",
       "721                                    0   \n",
       "3698                                   0   \n",
       "4934                                   0   \n",
       "704                                    0   \n",
       "3020                                   0   \n",
       "\n",
       "      android.intent.action.INPUT_METHOD_CHANGED  \\\n",
       "721                                            0   \n",
       "3698                                           0   \n",
       "4934                                           0   \n",
       "704                                            0   \n",
       "3020                                           1   \n",
       "\n",
       "      android.intent.action.INSERT  android.intent.action.INSERT_OR_EDIT  \\\n",
       "721                              0                                     0   \n",
       "3698                             0                                     0   \n",
       "4934                             0                                     0   \n",
       "704                              0                                     0   \n",
       "3020                             0                                     0   \n",
       "\n",
       "      android.intent.action.INSTALL_FAILURE  \\\n",
       "721                                       0   \n",
       "3698                                      0   \n",
       "4934                                      0   \n",
       "704                                       0   \n",
       "3020                                      0   \n",
       "\n",
       "      android.intent.action.INSTALL_PACKAGE  \\\n",
       "721                                       0   \n",
       "3698                                      0   \n",
       "4934                                      0   \n",
       "704                                       0   \n",
       "3020                                      0   \n",
       "\n",
       "      android.intent.action.LOCALE_CHANGED  \\\n",
       "721                                      0   \n",
       "3698                                     0   \n",
       "4934                                     0   \n",
       "704                                      0   \n",
       "3020                                     0   \n",
       "\n",
       "      android.intent.action.LOCKED_BOOT_COMPLETED  android.intent.action.MAIN  \\\n",
       "721                                             0                           1   \n",
       "3698                                            0                           1   \n",
       "4934                                            0                           1   \n",
       "704                                             0                           1   \n",
       "3020                                            0                           1   \n",
       "\n",
       "      android.intent.action.MANAGE_NETWORK_USAGE  ...  \\\n",
       "721                                            0  ...   \n",
       "3698                                           0  ...   \n",
       "4934                                           0  ...   \n",
       "704                                            0  ...   \n",
       "3020                                           0  ...   \n",
       "\n",
       "      android.intent.extra.restrictions_intent  \\\n",
       "721                                          0   \n",
       "3698                                         0   \n",
       "4934                                         0   \n",
       "704                                          0   \n",
       "3020                                         0   \n",
       "\n",
       "      android.intent.extra.restrictions_list  \\\n",
       "721                                        0   \n",
       "3698                                       0   \n",
       "4934                                       0   \n",
       "704                                        0   \n",
       "3020                                       0   \n",
       "\n",
       "      android.intent.extra.RESULT_RECEIVER  \\\n",
       "721                                      0   \n",
       "3698                                     0   \n",
       "4934                                     0   \n",
       "704                                      0   \n",
       "3020                                     0   \n",
       "\n",
       "      android.intent.extra.RETURN_RESULT  android.intent.extra.shortcut.ICON  \\\n",
       "721                                    0                                   0   \n",
       "3698                                   0                                   0   \n",
       "4934                                   0                                   0   \n",
       "704                                    0                                   0   \n",
       "3020                                   0                                   0   \n",
       "\n",
       "      android.intent.extra.shortcut.ICON_RESOURCE  \\\n",
       "721                                             0   \n",
       "3698                                            0   \n",
       "4934                                            0   \n",
       "704                                             0   \n",
       "3020                                            0   \n",
       "\n",
       "      android.intent.extra.shortcut.ID  android.intent.extra.shortcut.INTENT  \\\n",
       "721                                  0                                     0   \n",
       "3698                                 0                                     0   \n",
       "4934                                 0                                     0   \n",
       "704                                  0                                     0   \n",
       "3020                                 0                                     0   \n",
       "\n",
       "      android.intent.extra.shortcut.NAME  \\\n",
       "721                                    0   \n",
       "3698                                   0   \n",
       "4934                                   0   \n",
       "704                                    0   \n",
       "3020                                   0   \n",
       "\n",
       "      android.intent.extra.SHUTDOWN_USERSPACE_ONLY  \\\n",
       "721                                              0   \n",
       "3698                                             0   \n",
       "4934                                             0   \n",
       "704                                              0   \n",
       "3020                                             0   \n",
       "\n",
       "      android.intent.extra.SPLIT_NAME  android.intent.extra.STREAM  \\\n",
       "721                                 0                            0   \n",
       "3698                                0                            0   \n",
       "4934                                0                            0   \n",
       "704                                 0                            0   \n",
       "3020                                0                            0   \n",
       "\n",
       "      android.intent.extra.SUBJECT  \\\n",
       "721                              0   \n",
       "3698                             0   \n",
       "4934                             0   \n",
       "704                              0   \n",
       "3020                             0   \n",
       "\n",
       "      android.intent.extra.SUSPENDED_PACKAGE_EXTRAS  \\\n",
       "721                                               0   \n",
       "3698                                              0   \n",
       "4934                                              0   \n",
       "704                                               0   \n",
       "3020                                              0   \n",
       "\n",
       "      android.intent.extra.TEMPLATE  android.intent.extra.TEXT  \\\n",
       "721                               0                          0   \n",
       "3698                              0                          0   \n",
       "4934                              0                          0   \n",
       "704                               0                          0   \n",
       "3020                              0                          0   \n",
       "\n",
       "      android.intent.extra.TITLE  android.intent.extra.UID  \\\n",
       "721                            0                         0   \n",
       "3698                           0                         0   \n",
       "4934                           0                         0   \n",
       "704                            0                         0   \n",
       "3020                           0                         0   \n",
       "\n",
       "      android.intent.extra.USER  (0x00000001)  (0x00000004)  (0x00000080)  \\\n",
       "721                           0             0             0             0   \n",
       "3698                          0             0             0             0   \n",
       "4934                          0             0             0             0   \n",
       "704                           0             0             0             0   \n",
       "3020                          0             0             0             0   \n",
       "\n",
       "      (0x00000008)  (0x00000002)  (0x00000100)  (0x00000010)  (0x00000040)  \\\n",
       "721              0             0             0             0             0   \n",
       "3698             0             0             0             0             0   \n",
       "4934             0             0             0             0             0   \n",
       "704              0             0             0             0             0   \n",
       "3020             0             0             0             0             0   \n",
       "\n",
       "      (0x00000020)  (0x00400000)  (0x00008000)  (0x04000000)  (0x00080000)  \\\n",
       "721              0             0             0             0             0   \n",
       "3698             0             0             0             0             0   \n",
       "4934             0             0             0             0             0   \n",
       "704              0             0             0             0             0   \n",
       "3020             0             0             0             0             0   \n",
       "\n",
       "      (0x00800000)  (0x02000000)  (0x00001000)  (0x00100000)  (0x00000800)  \\\n",
       "721              0             0             0             0             0   \n",
       "3698             0             0             0             0             0   \n",
       "4934             0             0             0             0             0   \n",
       "704              0             0             0             0             0   \n",
       "3020             0             0             0             0             0   \n",
       "\n",
       "      (0x08000000)  (0x10000000)  (0x00010000)  (0x40000000)  (0x00040000)  \\\n",
       "721              0             0             0             0             0   \n",
       "3698             0             0             0             0             0   \n",
       "4934             0             0             0             0             0   \n",
       "704              0             0             0             0             0   \n",
       "3020             0             0             0             0             0   \n",
       "\n",
       "      (0x01000000)  (0x00020000)  (0x00200000)  (0x00002000)  (0x20000000)  \\\n",
       "721              0             0             0             0             0   \n",
       "3698             0             0             0             0             0   \n",
       "4934             0             0             0             0             0   \n",
       "704              0             0             0             0             0   \n",
       "3020             0             0             0             0             0   \n",
       "\n",
       "      (0x00004000)  android.dock_home  Label  \n",
       "721              0                  0      0  \n",
       "3698             0                  0      0  \n",
       "4934             0                  0      0  \n",
       "704              0                  0      1  \n",
       "3020             0                  0      1  \n",
       "\n",
       "[5 rows x 274 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of entire Dataset is 11274 \n",
      "The length of Benign Dataset is 5721 \n",
      "The length of Malicious Dataset is 5553 \n"
     ]
    }
   ],
   "source": [
    "print(\"The length of entire Dataset is {} \".format(len(df)))\n",
    "print(\"The length of Benign Dataset is {} \".format(len(benign_df)))\n",
    "print(\"The length of Malicious Dataset is {} \".format(len(malicious_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is (22884, 273)\n",
      "The shape of y is (22884,)\n",
      "Confusion matrix with random forests: \n",
      "[[10642   800]\n",
      " [ 2111  9331]]\n",
      "Accuracy with random forests: \n",
      "0.8727932179688865\n",
      "[[1.         0.        ]\n",
      " [0.78323288 0.21676712]\n",
      " [0.7549327  0.2450673 ]\n",
      " [0.78323288 0.21676712]\n",
      " [0.78323288 0.21676712]\n",
      " [0.78323288 0.21676712]\n",
      " [1.         0.        ]\n",
      " [0.84037042 0.15962958]\n",
      " [1.         0.        ]\n",
      " [0.78323288 0.21676712]]\n",
      "Printing sample regressor outputs: \n",
      "[[0.9954     0.0046    ]\n",
      " [0.78323288 0.21676712]\n",
      " [0.7549327  0.2450673 ]\n",
      " [0.78323288 0.21676712]\n",
      " [0.78323288 0.21676712]\n",
      " [0.78323288 0.21676712]\n",
      " [1.         0.        ]\n",
      " [0.84037042 0.15962958]\n",
      " [1.         0.        ]\n",
      " [0.78323288 0.21676712]]\n"
     ]
    }
   ],
   "source": [
    "#Classifier part\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "df_resamp=pd.read_csv('../Resampled_Datasets_Attack/'+'Random Forests_resamp.csv')\n",
    "X=df_resamp.iloc[:,:-1].values\n",
    "y=df_resamp.iloc[:,-1].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = X, y, X, y\n",
    "print(\"The shape of X is {}\".format(X.shape))\n",
    "print(\"The shape of y is {}\".format(y.shape))\n",
    "\n",
    "classifier = RandomForestClassifier(n_jobs=-1, random_state=0 )\n",
    "classifier.fit(X, y.reshape(-1))\n",
    "y_pred = classifier.predict(X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "y_probs = classifier.predict_proba(X)\n",
    "print(\"Confusion matrix with random forests: \")\n",
    "print(cm)\n",
    "print(\"Accuracy with random forests: \")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y, y_pred))\n",
    "print(y_probs[:10])\n",
    "\n",
    "#Regressor part\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "RF =RandomForestRegressor( n_jobs=-1, random_state=0 )\n",
    "RF.fit(X, y_probs)\n",
    "y_pred = RF.predict(X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Printing sample regressor outputs: \")\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is (22884, 273)\n",
      "The shape of y is (22884,)\n",
      "Confusion matrix with Decision Trees: \n",
      "[[10658   784]\n",
      " [ 2214  9228]]\n",
      "Accuracy with Decision Trees: \n",
      "0.8689914350638\n",
      "[[1.         0.        ]\n",
      " [0.77653295 0.22346705]\n",
      " [0.75555556 0.24444444]\n",
      " [0.77653295 0.22346705]\n",
      " [0.77653295 0.22346705]\n",
      " [0.77653295 0.22346705]\n",
      " [0.92307692 0.07692308]\n",
      " [0.85714286 0.14285714]\n",
      " [1.         0.        ]\n",
      " [0.77653295 0.22346705]]\n",
      "Printing sample regressor outputs: \n",
      "[[1.         0.        ]\n",
      " [0.77653295 0.22346705]\n",
      " [0.75555556 0.24444444]\n",
      " [0.77653295 0.22346705]\n",
      " [0.77653295 0.22346705]\n",
      " [0.77653295 0.22346705]\n",
      " [0.92307692 0.07692308]\n",
      " [0.85714286 0.14285714]\n",
      " [1.         0.        ]\n",
      " [0.77653295 0.22346705]]\n"
     ]
    }
   ],
   "source": [
    "#Classifier part\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "df_resamp=pd.read_csv('../Resampled_Datasets_Attack/'+'Decision Trees_resamp.csv')\n",
    "X=df_resamp.iloc[:,:-1].values\n",
    "y=df_resamp.iloc[:,-1].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = X, y, X, y\n",
    "print(\"The shape of X is {}\".format(X.shape))\n",
    "print(\"The shape of y is {}\".format(y.shape))\n",
    "\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X, y.reshape(-1))\n",
    "y_pred = classifier.predict(X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "y_probs = classifier.predict_proba(X)\n",
    "print(\"Confusion matrix with Decision Trees: \")\n",
    "print(cm)\n",
    "print(\"Accuracy with Decision Trees: \")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y, y_pred))\n",
    "print(y_probs[:10])\n",
    "\n",
    "#Regressor part\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "DT =DecisionTreeRegressor(random_state=0)\n",
    "DT.fit(X, y_probs)\n",
    "y_pred = DT.predict(X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Printing sample regressor outputs: \")\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is (22884, 273)\n",
      "The shape of y is (22884,)\n",
      "Confusion matrix with AdaBoost: \n",
      "[[10028  1414]\n",
      " [ 2541  8901]]\n",
      "Accuracy with AdaBoost: \n",
      "0.8271718231078483\n",
      "[[0.52937247 0.47062753]\n",
      " [0.5062576  0.4937424 ]\n",
      " [0.5062576  0.4937424 ]\n",
      " [0.5062576  0.4937424 ]\n",
      " [0.5062576  0.4937424 ]\n",
      " [0.5062576  0.4937424 ]\n",
      " [0.5062576  0.4937424 ]\n",
      " [0.50474393 0.49525607]\n",
      " [0.52024998 0.47975002]\n",
      " [0.5062576  0.4937424 ]]\n",
      "Printing sample regressor outputs: \n",
      "[[0.52186272 0.47813728]\n",
      " [0.50618889 0.49381111]\n",
      " [0.50618889 0.49381111]\n",
      " [0.50618889 0.49381111]\n",
      " [0.50618889 0.49381111]\n",
      " [0.50618889 0.49381111]\n",
      " [0.50618889 0.49381111]\n",
      " [0.50618889 0.49381111]\n",
      " [0.51914976 0.48085126]\n",
      " [0.50618889 0.49381111]]\n"
     ]
    }
   ],
   "source": [
    "#Classifier part\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "df_resamp=pd.read_csv('../Resampled_Datasets_Attack/'+'AdaBoost Classifier_resamp.csv')\n",
    "X=df_resamp.iloc[:,:-1].values\n",
    "y=df_resamp.iloc[:,-1].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = X, y, X, y\n",
    "print(\"The shape of X is {}\".format(X.shape))\n",
    "print(\"The shape of y is {}\".format(y.shape))\n",
    "\n",
    "classifier=AdaBoostClassifier()\n",
    "classifier.fit(X, y.reshape(-1))\n",
    "y_pred = classifier.predict(X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "y_probs = classifier.predict_proba(X)\n",
    "print(\"Confusion matrix with AdaBoost: \")\n",
    "print(cm)\n",
    "print(\"Accuracy with AdaBoost: \")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y, y_pred))\n",
    "print(y_probs[:10])\n",
    "\n",
    "#Regressor part\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "AdaBoost =AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "AdaBoost= MultiOutputRegressor(AdaBoost)\n",
    "AdaBoost.fit(X, y_probs)\n",
    "y_pred = AdaBoost.predict(X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Printing sample regressor outputs: \")\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is (22884, 273)\n",
      "The shape of y is (22884,)\n",
      "Confusion matrix with SVC: \n",
      "[[10168  1274]\n",
      " [ 2427  9015]]\n",
      "Accuracy with SVC: \n",
      "0.8382712812445376\n",
      "[[0.88795432 0.11204568]\n",
      " [0.81081321 0.18918679]\n",
      " [0.81085636 0.18914364]\n",
      " [0.81081321 0.18918679]\n",
      " [0.81081321 0.18918679]\n",
      " [0.81081321 0.18918679]\n",
      " [0.78230193 0.21769807]\n",
      " [0.80149357 0.19850643]\n",
      " [0.90275141 0.09724859]\n",
      " [0.81081321 0.18918679]]\n",
      "Printing sample regressor outputs: \n",
      "[[0.80601828 0.19400533]\n",
      " [0.72706215 0.27246328]\n",
      " [0.73129153 0.26896654]\n",
      " [0.72706215 0.27246328]\n",
      " [0.72706215 0.27246328]\n",
      " [0.72706215 0.27246328]\n",
      " [0.69537365 0.30452808]\n",
      " [0.70739803 0.29252543]\n",
      " [0.82604407 0.17408499]\n",
      " [0.72706215 0.27246328]]\n"
     ]
    }
   ],
   "source": [
    "#Classifier part\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "df_resamp=pd.read_csv('../Resampled_Datasets_Attack/'+'Support Vector Classifiers_resamp.csv')\n",
    "X=df_resamp.iloc[:,:-1].values\n",
    "y=df_resamp.iloc[:,-1].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = X, y, X, y\n",
    "print(\"The shape of X is {}\".format(X.shape))\n",
    "print(\"The shape of y is {}\".format(y.shape))\n",
    "\n",
    "classifier = SVC(kernel = 'rbf', probability=True)\n",
    "classifier.fit(X, y.reshape(-1))\n",
    "y_pred = classifier.predict(X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "y_probs = classifier.predict_proba(X)\n",
    "print(\"Confusion matrix with SVC: \")\n",
    "print(cm)\n",
    "print(\"Accuracy with SVC: \")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y, y_pred))\n",
    "print(y_probs[:10])\n",
    "\n",
    "#Regressor part\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "SVR =SVR(kernel = 'rbf')\n",
    "SVR= MultiOutputRegressor(SVR)\n",
    "SVR.fit(X, y_probs)\n",
    "y_pred = SVR.predict(X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Printing sample regressor outputs: \")\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is (22884, 273)\n",
      "The shape of y is (22884,)\n",
      "Confusion matrix with Gradient Boosting : \n",
      "[[10142  1300]\n",
      " [ 2373  9069]]\n",
      "Accuracy with Gradient Boosting : \n",
      "0.8394948435588184\n",
      "[[0.97640613 0.02359387]\n",
      " [0.77296367 0.22703633]\n",
      " [0.76184953 0.23815047]\n",
      " [0.77296367 0.22703633]\n",
      " [0.77296367 0.22703633]\n",
      " [0.77296367 0.22703633]\n",
      " [0.73562467 0.26437533]\n",
      " [0.83082185 0.16917815]\n",
      " [0.96130807 0.03869193]\n",
      " [0.77296367 0.22703633]]\n",
      "Printing sample regressor outputs: \n",
      "[[0.94212299 0.05787701]\n",
      " [0.7677464  0.2322536 ]\n",
      " [0.7677464  0.2322536 ]\n",
      " [0.7677464  0.2322536 ]\n",
      " [0.7677464  0.2322536 ]\n",
      " [0.7677464  0.2322536 ]\n",
      " [0.75423077 0.24576923]\n",
      " [0.8198025  0.1801975 ]\n",
      " [0.95886298 0.04113702]\n",
      " [0.7677464  0.2322536 ]]\n"
     ]
    }
   ],
   "source": [
    "#Classifier part\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "df_resamp=pd.read_csv('../Resampled_Datasets_Attack/'+'Gradient Boosting Classifier_resamp.csv')\n",
    "X=df_resamp.iloc[:,:-1].values\n",
    "y=df_resamp.iloc[:,-1].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = X, y, X, y\n",
    "print(\"The shape of X is {}\".format(X.shape))\n",
    "print(\"The shape of y is {}\".format(y.shape))\n",
    "\n",
    "classifier =GradientBoostingClassifier()\n",
    "classifier.fit(X, y)\n",
    "y_pred = classifier.predict(X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "y_probs = classifier.predict_proba(X)\n",
    "print(\"Confusion matrix with Gradient Boosting : \")\n",
    "print(cm)\n",
    "print(\"Accuracy with Gradient Boosting : \")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y, y_pred))\n",
    "print(y_probs[:10])\n",
    "\n",
    "#Regressor part\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "GradientBoosting =GradientBoostingRegressor(random_state=0)\n",
    "GradientBoosting= MultiOutputRegressor(GradientBoosting)\n",
    "GradientBoosting.fit(X, y_probs)\n",
    "y_pred = GradientBoosting.predict(X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Printing sample regressor outputs: \")\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is (22884, 273)\n",
      "The shape of y is (22884,)\n",
      "Confusion matrix with Extra Trees: \n",
      "[[10646   796]\n",
      " [ 2132  9310]]\n",
      "Accuracy with Extra Trees: \n",
      "0.8720503408495018\n",
      "[[1.         0.        ]\n",
      " [0.78256647 0.21743353]\n",
      " [0.75555556 0.24444444]\n",
      " [0.78256647 0.21743353]\n",
      " [0.78256647 0.21743353]\n",
      " [0.78256647 0.21743353]\n",
      " [1.         0.        ]\n",
      " [0.85714286 0.14285714]\n",
      " [1.         0.        ]\n",
      " [0.78256647 0.21743353]]\n",
      "Printing sample regressor outputs: \n",
      "[[1.         0.        ]\n",
      " [0.78256647 0.21743353]\n",
      " [0.75555556 0.24444444]\n",
      " [0.78256647 0.21743353]\n",
      " [0.78256647 0.21743353]\n",
      " [0.78256647 0.21743353]\n",
      " [1.         0.        ]\n",
      " [0.85714286 0.14285714]\n",
      " [1.         0.        ]\n",
      " [0.78256647 0.21743353]]\n"
     ]
    }
   ],
   "source": [
    "#Classifier part\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "df_resamp=pd.read_csv('../Resampled_Datasets_Attack/'+'Extra Tree classifier_resamp.csv')\n",
    "X=df_resamp.iloc[:,:-1].values\n",
    "y=df_resamp.iloc[:,-1].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = X, y, X, y\n",
    "print(\"The shape of X is {}\".format(X.shape))\n",
    "print(\"The shape of y is {}\".format(y.shape))\n",
    "\n",
    "classifier = ExtraTreesClassifier(n_jobs=-1)\n",
    "classifier.fit(X, y.reshape(-1))\n",
    "y_pred = classifier.predict(X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "y_probs = classifier.predict_proba(X)\n",
    "print(\"Confusion matrix with Extra Trees: \")\n",
    "print(cm)\n",
    "print(\"Accuracy with Extra Trees: \")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y, y_pred))\n",
    "print(y_probs[:10])\n",
    "\n",
    "#Regressor part\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "ExtraTree =ExtraTreesRegressor(random_state=0 ,n_jobs=-1)\n",
    "ExtraTree.fit(X, y_probs)\n",
    "y_pred =ExtraTree.predict(X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Printing sample regressor outputs: \")\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is (22884, 273)\n",
      "The shape of y is (22884,)\n",
      "Confusion matrix with Bagging Classifier: \n",
      "[[10122  1320]\n",
      " [ 2415  9027]]\n",
      "Accuracy with Bagging Classifier: \n",
      "0.8367855270057682\n",
      "[[0.8833394  0.1166606 ]\n",
      " [0.81066844 0.18933156]\n",
      " [0.81220619 0.18779381]\n",
      " [0.81066844 0.18933156]\n",
      " [0.81066844 0.18933156]\n",
      " [0.81066844 0.18933156]\n",
      " [0.77562997 0.22437003]\n",
      " [0.79814104 0.20185896]\n",
      " [0.89572822 0.10427178]\n",
      " [0.81066844 0.18933156]]\n",
      "Printing sample regressor outputs: \n",
      "[[0.81019239 0.18979588]\n",
      " [0.72353124 0.2763496 ]\n",
      " [0.73456682 0.26539203]\n",
      " [0.72353124 0.2763496 ]\n",
      " [0.72353124 0.2763496 ]\n",
      " [0.72353124 0.2763496 ]\n",
      " [0.69132418 0.30864759]\n",
      " [0.70642527 0.29350871]\n",
      " [0.81160708 0.18841906]\n",
      " [0.72353124 0.2763496 ]]\n"
     ]
    }
   ],
   "source": [
    "#Classifier part\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "df_resamp=pd.read_csv('../Resampled_Datasets_Attack/'+'Bagging Classifier_resamp.csv')\n",
    "X=df_resamp.iloc[:,:-1].values\n",
    "y=df_resamp.iloc[:,-1].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = X, y, X, y\n",
    "print(\"The shape of X is {}\".format(X.shape))\n",
    "print(\"The shape of y is {}\".format(y.shape))\n",
    "\n",
    "classifier = BaggingClassifier(base_estimator=SVC(probability=True), n_jobs=-1)\n",
    "classifier.fit(X, y.reshape(-1))\n",
    "y_pred = classifier.predict(X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "y_probs = classifier.predict_proba(X)\n",
    "print(\"Confusion matrix with Bagging Classifier: \")\n",
    "print(cm)\n",
    "print(\"Accuracy with Bagging Classifier: \")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y, y_pred))\n",
    "print(y_probs[:10])\n",
    "\n",
    "#Regressor part\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "Bagging=BaggingRegressor(base_estimator=SVR(),n_jobs=-1, random_state=0)\n",
    "Bagging= MultiOutputRegressor(Bagging)\n",
    "Bagging.fit(X, y_probs)\n",
    "y_pred = Bagging.predict(X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Printing sample regressor outputs: \")\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is (22884, 273)\n",
      "The shape of y is (22884,)\n",
      "Confusion matrix with XGB: \n",
      "[[10454   988]\n",
      " [ 2175  9267]]\n",
      "Accuracy with XGB: \n",
      "0.8617811571403601\n",
      "[[0.9981969  0.00180309]\n",
      " [0.7828668  0.21713322]\n",
      " [0.7368305  0.26316956]\n",
      " [0.7828668  0.21713322]\n",
      " [0.7828668  0.21713322]\n",
      " [0.7828668  0.21713322]\n",
      " [0.6763005  0.32369944]\n",
      " [0.7575342  0.24246578]\n",
      " [0.9923045  0.00769551]\n",
      " [0.7828668  0.21713322]]\n",
      "Printing sample regressor outputs: \n",
      "[[ 0.9899806   0.0100193 ]\n",
      " [ 0.7825874   0.21741253]\n",
      " [ 0.7309793   0.26902068]\n",
      " [ 0.7825874   0.21741253]\n",
      " [ 0.7825874   0.21741253]\n",
      " [ 0.7825874   0.21741253]\n",
      " [ 0.6730824   0.32691765]\n",
      " [ 0.7351038   0.2648962 ]\n",
      " [ 1.0071294  -0.00712931]\n",
      " [ 0.7825874   0.21741253]]\n"
     ]
    }
   ],
   "source": [
    "#Classifier part\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "df_resamp=pd.read_csv('../Resampled_Datasets_Attack/'+'XGBoost classifier_resamp.csv')\n",
    "X=df_resamp.iloc[:,:-1].values\n",
    "y=df_resamp.iloc[:,-1].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = X, y, X, y\n",
    "print(\"The shape of X is {}\".format(X.shape))\n",
    "print(\"The shape of y is {}\".format(y.shape))\n",
    "\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(X, y)\n",
    "y_pred = classifier.predict(X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "y_probs = classifier.predict_proba(X)\n",
    "print(\"Confusion matrix with XGB: \")\n",
    "print(cm)\n",
    "print(\"Accuracy with XGB: \")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y, y_pred))\n",
    "print(y_probs[:10])\n",
    "\n",
    "#Regressor part\n",
    "from xgboost import  XGBRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "XGB =XGBRegressor()\n",
    "XGB= MultiOutputRegressor(XGB)\n",
    "XGB.fit(X, y_probs)\n",
    "y_pred = XGB.predict(X)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Printing sample regressor outputs: \")\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2ebb8103dd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    \"\"\"An abstract class representing a Dataset.\n",
    "    All other datasets should subclass it. All subclasses should override\n",
    "    ``__len__``, that provides the size of the dataset, and ``__getitem__``,\n",
    "    supporting integer indexing in range from 0 to len(self) exclusive.\n",
    "    \"\"\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return ConcatDataset([self, other])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasetcustom(Dataset):\n",
    "    \n",
    "    def __init__(self,data, labels, transform=None):\n",
    "        self.data = data.copy()\n",
    "        self.labels=labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # load image as ndarray type (Height * Width * Channels)\n",
    "        # be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\n",
    "        # in this example, i don't use ToTensor() method of torchvision.transforms\n",
    "        # so you can convert numpy ndarray shape to tensor in PyTorch (H, W, C) --> (C, H, W)\n",
    "        image = torch.from_numpy(self.data[index]).float()\n",
    "        label = torch.tensor(self.labels[index])\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifiers={  \"Support Vector Classifiers\": SVR , \"Random Forests\": RF }\n",
    "model=torch.load('../trained_models/Train-512-256-64.pth')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# \"Bagging Classifier\":Bagging, \"Gradient Boosting Classifier\": GradientBoosting, \"XGBoost classifier\": XGB, \"Extra Tree classifier\": ExtraTree , \n",
    "#               \"AdaBoost Classifier\": AdaBoost, \"Decision Trees\": DT,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier used here is : Support Vector Classifiers\n",
      "Correct benign is 10094 \n",
      " correct malicious is 9012 \n",
      " converted to benign is  2430\n",
      "   bits_flipped    TP     TN    FN\n",
      "0             0  9017  10094  2425\n",
      "1             1  9017  10094  2425\n",
      "2             2  9017  10094  2425\n",
      "3             3  9016  10094  2426\n",
      "4             4  9015  10094  2427\n",
      "5             5  9015  10094  2427\n",
      "6             6  9014  10094  2428\n",
      "7             7  9014  10094  2428\n",
      "8             8  9014  10094  2428\n",
      "9             9  9012  10094  2430\n",
      "10           10  9012  10094  2430\n",
      "Classifier used here is : Random Forests\n",
      "Correct benign is 10642 \n",
      " correct malicious is 8038 \n",
      " converted to benign is  3404\n",
      "   bits_flipped    TP     TN    FN\n",
      "0             0  9315  10642  2127\n",
      "1             1  9053  10642  2389\n",
      "2             2  8770  10642  2672\n",
      "3             3  8628  10642  2814\n",
      "4             4  8498  10642  2944\n",
      "5             5  8403  10642  3039\n",
      "6             6  8310  10642  3132\n",
      "7             7  8223  10642  3219\n",
      "8             8  8159  10642  3283\n",
      "9             9  8107  10642  3335\n",
      "10           10  8038  10642  3404\n"
     ]
    }
   ],
   "source": [
    "for Algorithm in Classifiers:\n",
    "        df1=pd.DataFrame(columns = ['bits_flipped','TP', 'TN','FN'])\n",
    "        for i in range(0,11):\n",
    "            df1=df1.append(pd.Series([i, 11442, 0, 0], index= df1.columns), ignore_index=True )\n",
    "        print(\"Classifier used here is : {}\".format(Algorithm))\n",
    "        classifier= Classifiers[Algorithm]\n",
    "        correct_benign=0\n",
    "        correct_malicious=0\n",
    "        convert_to_benign=0\n",
    "        target_model= Classifiers[Algorithm]\n",
    "        df=pd.read_csv('../Resampled_Datasets_Attack/'+Algorithm+'_resamp.csv')\n",
    "        X=df.iloc[:,:-1].values\n",
    "        y=df.iloc[:,-1].values\n",
    "        test_dataset= Datasetcustom(X, y)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "        for images, labels in test_loader:\n",
    "            images.requires_grad = True\n",
    "            model.zero_grad()\n",
    "            output = model(images)\n",
    "            y_pred = classifier.predict(images.detach().numpy().reshape(1,-1))\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            data_grad = images.grad.data\n",
    "            if  y_pred[0][1]>y_pred[0][0] and labels[0]==1:\n",
    "                grad_list=[]\n",
    "                for i in range(273):\n",
    "                    if images[0][i]==0:\n",
    "                        grad_list.append((data_grad[0][i],i))\n",
    "                grad_list.sort(key = lambda x: x[0], reverse=True)\n",
    "                flag=0\n",
    "                for i in range(0,10):\n",
    "                    images[0][grad_list[i][1]]=1\n",
    "                    y_pred = classifier.predict(images.detach().numpy().reshape(1,-1))\n",
    "                    if y_pred[0][0]>y_pred[0][1]:\n",
    "                        for j in range(i,10):  #converted in i+1 flips, hence all bits>=i+1, the FN will increase\n",
    "                            df1.iloc[j+1,3]+=1\n",
    "                            df1.iloc[j+1,1]-=1\n",
    "                        flag=1\n",
    "                        convert_to_benign+=1\n",
    "                        break\n",
    "                if flag==0:          #Even after 10 flips, unable to convert to benignm update malicious counter\n",
    "                    correct_malicious+=1\n",
    "            elif y_pred[0][0]>y_pred[0][1] and labels[0]==1:  #If predicted as benign but is malicious\n",
    "                for j in range(0,11):\n",
    "                    df1.iloc[j,3]+=1\n",
    "                    df1.iloc[j,1]-=1\n",
    "                convert_to_benign+=1\n",
    "            elif  y_pred[0][0]>y_pred[0][1] and labels[0]==0:   #if predicted benign correctly\n",
    "                for j in range(0,11):\n",
    "                    df1.iloc[j,2]+=1\n",
    "                correct_benign+=1\n",
    "        \n",
    "        print(\"Correct benign is {} \\n correct malicious is {} \\n converted to benign is  {}\".format(correct_benign, correct_malicious, convert_to_benign))\n",
    "#         print(\"Final Accuracy is {:.3f} with max {} bits flipped\".format((correct_benign+5553-convert_benign)/11274, num_bits))\n",
    "        print(df1)\n",
    "        df1.to_csv('../Hybrid_Distillation/'+str(Algorithm)+\"_Hybrid_Distillation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_4(nn.Module):\n",
    "    def __init__(self,t):\n",
    "        super(model_4, self).__init__()\n",
    "        self.t=t\n",
    "        self.l1=nn.Linear(273, 512)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.l2=nn.Linear(512, 256)\n",
    "        self.l3=nn.Linear(256, 64)\n",
    "        self.l4=nn.Linear(64, 2)\n",
    "        self.dropout= nn.Dropout(0.4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.l1(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l2(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l3(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l4(x)\n",
    "        x= nn.Softmax(dim=1)(x/self.t)\n",
    "        return x\n",
    "    \n",
    "class model_4dist(nn.Module):\n",
    "    def __init__(self,t):\n",
    "        super(model_4dist, self).__init__()\n",
    "        self.t=t\n",
    "        self.l1=nn.Linear(273, 512)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.l2=nn.Linear(512, 256)\n",
    "        self.l3=nn.Linear(256, 64)\n",
    "        self.l4=nn.Linear(64, 2)\n",
    "        self.dropout= nn.Dropout(0.4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.l1(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l2(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l3(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l4(x)\n",
    "        x= nn.Softmax(dim=1)(x/self.t)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is training the neural network classifier for temperature 1\n",
      "Epoch: 1/50..  Training Loss: 0.500..  Test Loss: 0.485..  Test Accuracy: 0.828\n",
      "Epoch: 2/50..  Training Loss: 0.484..  Test Loss: 0.482..  Test Accuracy: 0.830\n",
      "Epoch: 3/50..  Training Loss: 0.480..  Test Loss: 0.482..  Test Accuracy: 0.830\n",
      "Epoch: 4/50..  Training Loss: 0.479..  Test Loss: 0.477..  Test Accuracy: 0.836\n",
      "Epoch: 5/50..  Training Loss: 0.477..  Test Loss: 0.478..  Test Accuracy: 0.835\n",
      "Epoch: 6/50..  Training Loss: 0.479..  Test Loss: 0.476..  Test Accuracy: 0.837\n",
      "Epoch: 7/50..  Training Loss: 0.478..  Test Loss: 0.477..  Test Accuracy: 0.836\n",
      "Epoch: 8/50..  Training Loss: 0.477..  Test Loss: 0.475..  Test Accuracy: 0.838\n",
      "Epoch: 9/50..  Training Loss: 0.475..  Test Loss: 0.474..  Test Accuracy: 0.839\n",
      "Epoch: 10/50..  Training Loss: 0.478..  Test Loss: 0.495..  Test Accuracy: 0.818\n",
      "Epoch: 11/50..  Training Loss: 0.480..  Test Loss: 0.479..  Test Accuracy: 0.834\n",
      "Epoch: 12/50..  Training Loss: 0.480..  Test Loss: 0.475..  Test Accuracy: 0.838\n",
      "Epoch: 13/50..  Training Loss: 0.476..  Test Loss: 0.476..  Test Accuracy: 0.837\n",
      "Epoch: 14/50..  Training Loss: 0.483..  Test Loss: 0.477..  Test Accuracy: 0.836\n",
      "Epoch: 15/50..  Training Loss: 0.477..  Test Loss: 0.477..  Test Accuracy: 0.836\n",
      "Epoch: 16/50..  Training Loss: 0.478..  Test Loss: 0.475..  Test Accuracy: 0.838\n",
      "Epoch: 17/50..  Training Loss: 0.477..  Test Loss: 0.481..  Test Accuracy: 0.832\n",
      "Epoch: 18/50..  Training Loss: 0.479..  Test Loss: 0.479..  Test Accuracy: 0.835\n",
      "Epoch: 19/50..  Training Loss: 0.476..  Test Loss: 0.475..  Test Accuracy: 0.838\n",
      "Epoch: 20/50..  Training Loss: 0.478..  Test Loss: 0.478..  Test Accuracy: 0.836\n",
      "Epoch: 21/50..  Training Loss: 0.480..  Test Loss: 0.478..  Test Accuracy: 0.835\n",
      "Epoch: 22/50..  Training Loss: 0.483..  Test Loss: 0.492..  Test Accuracy: 0.821\n",
      "Epoch: 23/50..  Training Loss: 0.480..  Test Loss: 0.481..  Test Accuracy: 0.832\n",
      "Epoch: 24/50..  Training Loss: 0.481..  Test Loss: 0.478..  Test Accuracy: 0.835\n",
      "Epoch: 25/50..  Training Loss: 0.478..  Test Loss: 0.479..  Test Accuracy: 0.834\n",
      "Epoch: 26/50..  Training Loss: 0.478..  Test Loss: 0.486..  Test Accuracy: 0.827\n",
      "Epoch: 27/50..  Training Loss: 0.480..  Test Loss: 0.479..  Test Accuracy: 0.834\n",
      "Epoch: 28/50..  Training Loss: 0.478..  Test Loss: 0.476..  Test Accuracy: 0.837\n",
      "Epoch: 29/50..  Training Loss: 0.478..  Test Loss: 0.479..  Test Accuracy: 0.835\n",
      "Epoch: 30/50..  Training Loss: 0.479..  Test Loss: 0.477..  Test Accuracy: 0.837\n",
      "Epoch: 31/50..  Training Loss: 0.476..  Test Loss: 0.484..  Test Accuracy: 0.830\n",
      "Epoch: 32/50..  Training Loss: 0.482..  Test Loss: 0.482..  Test Accuracy: 0.831\n",
      "Epoch: 33/50..  Training Loss: 0.484..  Test Loss: 0.486..  Test Accuracy: 0.827\n",
      "Epoch: 34/50..  Training Loss: 0.482..  Test Loss: 0.481..  Test Accuracy: 0.833\n",
      "Epoch: 35/50..  Training Loss: 0.486..  Test Loss: 0.485..  Test Accuracy: 0.829\n",
      "Epoch: 36/50..  Training Loss: 0.480..  Test Loss: 0.490..  Test Accuracy: 0.823\n",
      "Epoch: 37/50..  Training Loss: 0.518..  Test Loss: 0.481..  Test Accuracy: 0.832\n",
      "Epoch: 38/50..  Training Loss: 0.502..  Test Loss: 0.478..  Test Accuracy: 0.836\n",
      "Epoch: 39/50..  Training Loss: 0.478..  Test Loss: 0.478..  Test Accuracy: 0.835\n",
      "Epoch: 40/50..  Training Loss: 0.480..  Test Loss: 0.478..  Test Accuracy: 0.835\n",
      "Epoch: 41/50..  Training Loss: 0.481..  Test Loss: 0.490..  Test Accuracy: 0.823\n",
      "Epoch: 42/50..  Training Loss: 0.494..  Test Loss: 0.495..  Test Accuracy: 0.818\n",
      "Epoch: 43/50..  Training Loss: 0.479..  Test Loss: 0.476..  Test Accuracy: 0.837\n",
      "Epoch: 44/50..  Training Loss: 0.483..  Test Loss: 0.476..  Test Accuracy: 0.837\n",
      "Epoch: 45/50..  Training Loss: 0.479..  Test Loss: 0.477..  Test Accuracy: 0.836\n",
      "Epoch: 46/50..  Training Loss: 0.479..  Test Loss: 0.482..  Test Accuracy: 0.831\n",
      "Epoch: 47/50..  Training Loss: 0.482..  Test Loss: 0.479..  Test Accuracy: 0.834\n",
      "Epoch: 48/50..  Training Loss: 0.480..  Test Loss: 0.481..  Test Accuracy: 0.832\n",
      "Epoch: 49/50..  Training Loss: 0.480..  Test Loss: 0.477..  Test Accuracy: 0.837\n",
      "Epoch: 50/50..  Training Loss: 0.478..  Test Loss: 0.476..  Test Accuracy: 0.837\n",
      "The length of the dataset is 22884\n",
      "Shape of X is (22884, 273) and shape of y_probs is (22884, 2)\n",
      "Epoch: 1/100..  Training Loss: 0.208..  Test Loss: 0.086.. \n",
      "Epoch: 2/100..  Training Loss: 0.051..  Test Loss: 0.040.. \n",
      "Epoch: 3/100..  Training Loss: 0.039..  Test Loss: 0.035.. \n",
      "Epoch: 4/100..  Training Loss: 0.035..  Test Loss: 0.033.. \n",
      "Epoch: 5/100..  Training Loss: 0.032..  Test Loss: 0.031.. \n",
      "Epoch: 6/100..  Training Loss: 0.031..  Test Loss: 0.028.. \n",
      "Epoch: 7/100..  Training Loss: 0.028..  Test Loss: 0.026.. \n",
      "Epoch: 8/100..  Training Loss: 0.026..  Test Loss: 0.025.. \n",
      "Epoch: 9/100..  Training Loss: 0.023..  Test Loss: 0.022.. \n",
      "Epoch: 10/100..  Training Loss: 0.022..  Test Loss: 0.020.. \n",
      "Epoch: 11/100..  Training Loss: 0.020..  Test Loss: 0.020.. \n",
      "Epoch: 12/100..  Training Loss: 0.019..  Test Loss: 0.018.. \n",
      "Epoch: 13/100..  Training Loss: 0.018..  Test Loss: 0.017.. \n",
      "Epoch: 14/100..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 15/100..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 16/100..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 17/100..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 18/100..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 19/100..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 20/100..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 21/100..  Training Loss: 0.013..  Test Loss: 0.012.. \n",
      "Epoch: 22/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 23/100..  Training Loss: 0.012..  Test Loss: 0.011.. \n",
      "Epoch: 24/100..  Training Loss: 0.012..  Test Loss: 0.011.. \n",
      "Epoch: 25/100..  Training Loss: 0.011..  Test Loss: 0.011.. \n",
      "Epoch: 26/100..  Training Loss: 0.010..  Test Loss: 0.010.. \n",
      "Epoch: 27/100..  Training Loss: 0.010..  Test Loss: 0.011.. \n",
      "Epoch: 28/100..  Training Loss: 0.010..  Test Loss: 0.010.. \n",
      "Epoch: 29/100..  Training Loss: 0.010..  Test Loss: 0.010.. \n",
      "Epoch: 30/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 31/100..  Training Loss: 0.010..  Test Loss: 0.009.. \n",
      "Epoch: 32/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 33/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 34/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 35/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 36/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 37/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 38/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 39/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 40/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 41/100..  Training Loss: 0.008..  Test Loss: 0.015.. \n",
      "Epoch: 42/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 43/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 44/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 45/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 46/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 47/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 48/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 49/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 50/100..  Training Loss: 0.007..  Test Loss: 0.008.. \n",
      "Epoch: 51/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 52/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 53/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 54/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 55/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 56/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 57/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 58/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 59/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 60/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 61/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 62/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 63/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 64/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 65/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 66/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 68/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 69/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 70/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 71/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 72/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 73/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 74/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 75/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 76/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 77/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 78/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 79/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 80/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 81/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 82/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 83/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 84/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 85/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 86/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 87/100..  Training Loss: 0.006..  Test Loss: 0.007.. \n",
      "Epoch: 88/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 89/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 90/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 91/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 92/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 93/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 94/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 95/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 96/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 97/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 98/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 99/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 100/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Classifier used here is : 4-layered\n",
      "Correct benign is 10155 \n",
      " correct malicious is 8068 \n",
      " converted to benign is  3374\n",
      "   bits_flipped    TP     TN    FN\n",
      "0             0  8976  10155  2466\n",
      "1             1  8841  10155  2601\n",
      "2             2  8764  10155  2678\n",
      "3             3  8707  10155  2735\n",
      "4             4  8617  10155  2825\n",
      "5             5  8535  10155  2907\n",
      "6             6  8436  10155  3006\n",
      "7             7  8361  10155  3081\n",
      "8             8  8253  10155  3189\n",
      "9             9  8165  10155  3277\n",
      "10           10  8068  10155  3374\n",
      "This is training the neural network classifier for temperature 5\n",
      "Epoch: 1/50..  Training Loss: 0.500..  Test Loss: 0.483..  Test Accuracy: 0.830\n",
      "Epoch: 2/50..  Training Loss: 0.484..  Test Loss: 0.482..  Test Accuracy: 0.831\n",
      "Epoch: 3/50..  Training Loss: 0.481..  Test Loss: 0.491..  Test Accuracy: 0.821\n",
      "Epoch: 4/50..  Training Loss: 0.481..  Test Loss: 0.477..  Test Accuracy: 0.835\n",
      "Epoch: 5/50..  Training Loss: 0.477..  Test Loss: 0.477..  Test Accuracy: 0.836\n",
      "Epoch: 6/50..  Training Loss: 0.477..  Test Loss: 0.476..  Test Accuracy: 0.837\n",
      "Epoch: 7/50..  Training Loss: 0.477..  Test Loss: 0.475..  Test Accuracy: 0.838\n",
      "Epoch: 8/50..  Training Loss: 0.476..  Test Loss: 0.474..  Test Accuracy: 0.840\n",
      "Epoch: 9/50..  Training Loss: 0.473..  Test Loss: 0.472..  Test Accuracy: 0.841\n",
      "Epoch: 10/50..  Training Loss: 0.472..  Test Loss: 0.472..  Test Accuracy: 0.841\n",
      "Epoch: 11/50..  Training Loss: 0.472..  Test Loss: 0.471..  Test Accuracy: 0.842\n",
      "Epoch: 12/50..  Training Loss: 0.470..  Test Loss: 0.469..  Test Accuracy: 0.843\n",
      "Epoch: 13/50..  Training Loss: 0.471..  Test Loss: 0.469..  Test Accuracy: 0.843\n",
      "Epoch: 14/50..  Training Loss: 0.469..  Test Loss: 0.468..  Test Accuracy: 0.845\n",
      "Epoch: 15/50..  Training Loss: 0.468..  Test Loss: 0.467..  Test Accuracy: 0.846\n",
      "Epoch: 16/50..  Training Loss: 0.468..  Test Loss: 0.466..  Test Accuracy: 0.846\n",
      "Epoch: 17/50..  Training Loss: 0.466..  Test Loss: 0.466..  Test Accuracy: 0.847\n",
      "Epoch: 18/50..  Training Loss: 0.467..  Test Loss: 0.466..  Test Accuracy: 0.846\n",
      "Epoch: 19/50..  Training Loss: 0.464..  Test Loss: 0.464..  Test Accuracy: 0.849\n",
      "Epoch: 20/50..  Training Loss: 0.465..  Test Loss: 0.463..  Test Accuracy: 0.849\n",
      "Epoch: 21/50..  Training Loss: 0.464..  Test Loss: 0.463..  Test Accuracy: 0.850\n",
      "Epoch: 22/50..  Training Loss: 0.464..  Test Loss: 0.462..  Test Accuracy: 0.849\n",
      "Epoch: 23/50..  Training Loss: 0.463..  Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 24/50..  Training Loss: 0.463..  Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 25/50..  Training Loss: 0.462..  Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 26/50..  Training Loss: 0.462..  Test Loss: 0.463..  Test Accuracy: 0.848\n",
      "Epoch: 27/50..  Training Loss: 0.461..  Test Loss: 0.460..  Test Accuracy: 0.851\n",
      "Epoch: 28/50..  Training Loss: 0.460..  Test Loss: 0.460..  Test Accuracy: 0.851\n",
      "Epoch: 29/50..  Training Loss: 0.461..  Test Loss: 0.459..  Test Accuracy: 0.852\n",
      "Epoch: 30/50..  Training Loss: 0.461..  Test Loss: 0.459..  Test Accuracy: 0.853\n",
      "Epoch: 31/50..  Training Loss: 0.462..  Test Loss: 0.464..  Test Accuracy: 0.847\n",
      "Epoch: 32/50..  Training Loss: 0.460..  Test Loss: 0.458..  Test Accuracy: 0.853\n",
      "Epoch: 33/50..  Training Loss: 0.459..  Test Loss: 0.458..  Test Accuracy: 0.853\n",
      "Epoch: 34/50..  Training Loss: 0.461..  Test Loss: 0.459..  Test Accuracy: 0.852\n",
      "Epoch: 35/50..  Training Loss: 0.460..  Test Loss: 0.459..  Test Accuracy: 0.853\n",
      "Epoch: 36/50..  Training Loss: 0.460..  Test Loss: 0.458..  Test Accuracy: 0.854\n",
      "Epoch: 37/50..  Training Loss: 0.459..  Test Loss: 0.462..  Test Accuracy: 0.849\n",
      "Epoch: 38/50..  Training Loss: 0.460..  Test Loss: 0.458..  Test Accuracy: 0.853\n",
      "Epoch: 39/50..  Training Loss: 0.458..  Test Loss: 0.458..  Test Accuracy: 0.853\n",
      "Epoch: 40/50..  Training Loss: 0.458..  Test Loss: 0.457..  Test Accuracy: 0.855\n",
      "Epoch: 41/50..  Training Loss: 0.458..  Test Loss: 0.458..  Test Accuracy: 0.854\n",
      "Epoch: 42/50..  Training Loss: 0.459..  Test Loss: 0.462..  Test Accuracy: 0.850\n",
      "Epoch: 43/50..  Training Loss: 0.458..  Test Loss: 0.458..  Test Accuracy: 0.854\n",
      "Epoch: 44/50..  Training Loss: 0.458..  Test Loss: 0.459..  Test Accuracy: 0.853\n",
      "Epoch: 45/50..  Training Loss: 0.456..  Test Loss: 0.456..  Test Accuracy: 0.856\n",
      "Epoch: 46/50..  Training Loss: 0.457..  Test Loss: 0.458..  Test Accuracy: 0.854\n",
      "Epoch: 47/50..  Training Loss: 0.458..  Test Loss: 0.458..  Test Accuracy: 0.854\n",
      "Epoch: 48/50..  Training Loss: 0.457..  Test Loss: 0.467..  Test Accuracy: 0.845\n",
      "Epoch: 49/50..  Training Loss: 0.458..  Test Loss: 0.456..  Test Accuracy: 0.856\n",
      "Epoch: 50/50..  Training Loss: 0.456..  Test Loss: 0.456..  Test Accuracy: 0.856\n",
      "The length of the dataset is 22884\n",
      "Shape of X is (22884, 273) and shape of y_probs is (22884, 2)\n",
      "Epoch: 1/100..  Training Loss: 0.244..  Test Loss: 0.243.. \n",
      "Epoch: 2/100..  Training Loss: 0.242..  Test Loss: 0.241.. \n",
      "Epoch: 3/100..  Training Loss: 0.240..  Test Loss: 0.239.. \n",
      "Epoch: 4/100..  Training Loss: 0.236..  Test Loss: 0.232.. \n",
      "Epoch: 5/100..  Training Loss: 0.219..  Test Loss: 0.194.. \n",
      "Epoch: 6/100..  Training Loss: 0.130..  Test Loss: 0.078.. \n",
      "Epoch: 7/100..  Training Loss: 0.066..  Test Loss: 0.060.. \n",
      "Epoch: 8/100..  Training Loss: 0.059..  Test Loss: 0.057.. \n",
      "Epoch: 9/100..  Training Loss: 0.056..  Test Loss: 0.055.. \n",
      "Epoch: 10/100..  Training Loss: 0.056..  Test Loss: 0.055.. \n",
      "Epoch: 11/100..  Training Loss: 0.054..  Test Loss: 0.053.. \n",
      "Epoch: 12/100..  Training Loss: 0.053..  Test Loss: 0.052.. \n",
      "Epoch: 13/100..  Training Loss: 0.051..  Test Loss: 0.051.. \n",
      "Epoch: 14/100..  Training Loss: 0.050..  Test Loss: 0.049.. \n",
      "Epoch: 15/100..  Training Loss: 0.048..  Test Loss: 0.047.. \n",
      "Epoch: 16/100..  Training Loss: 0.046..  Test Loss: 0.044.. \n",
      "Epoch: 17/100..  Training Loss: 0.044..  Test Loss: 0.043.. \n",
      "Epoch: 18/100..  Training Loss: 0.042..  Test Loss: 0.041.. \n",
      "Epoch: 19/100..  Training Loss: 0.040..  Test Loss: 0.040.. \n",
      "Epoch: 20/100..  Training Loss: 0.039..  Test Loss: 0.038.. \n",
      "Epoch: 21/100..  Training Loss: 0.037..  Test Loss: 0.036.. \n",
      "Epoch: 22/100..  Training Loss: 0.035..  Test Loss: 0.035.. \n",
      "Epoch: 23/100..  Training Loss: 0.034..  Test Loss: 0.033.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/100..  Training Loss: 0.033..  Test Loss: 0.032.. \n",
      "Epoch: 25/100..  Training Loss: 0.032..  Test Loss: 0.031.. \n",
      "Epoch: 26/100..  Training Loss: 0.031..  Test Loss: 0.030.. \n",
      "Epoch: 27/100..  Training Loss: 0.030..  Test Loss: 0.030.. \n",
      "Epoch: 28/100..  Training Loss: 0.028..  Test Loss: 0.028.. \n",
      "Epoch: 29/100..  Training Loss: 0.027..  Test Loss: 0.026.. \n",
      "Epoch: 30/100..  Training Loss: 0.026..  Test Loss: 0.024.. \n",
      "Epoch: 31/100..  Training Loss: 0.024..  Test Loss: 0.023.. \n",
      "Epoch: 32/100..  Training Loss: 0.022..  Test Loss: 0.022.. \n",
      "Epoch: 33/100..  Training Loss: 0.022..  Test Loss: 0.021.. \n",
      "Epoch: 34/100..  Training Loss: 0.021..  Test Loss: 0.020.. \n",
      "Epoch: 35/100..  Training Loss: 0.020..  Test Loss: 0.019.. \n",
      "Epoch: 36/100..  Training Loss: 0.019..  Test Loss: 0.019.. \n",
      "Epoch: 37/100..  Training Loss: 0.019..  Test Loss: 0.019.. \n",
      "Epoch: 38/100..  Training Loss: 0.019..  Test Loss: 0.018.. \n",
      "Epoch: 39/100..  Training Loss: 0.018..  Test Loss: 0.017.. \n",
      "Epoch: 40/100..  Training Loss: 0.018..  Test Loss: 0.017.. \n",
      "Epoch: 41/100..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 42/100..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 43/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 44/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 45/100..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 46/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 47/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 48/100..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 49/100..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 50/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 51/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 52/100..  Training Loss: 0.013..  Test Loss: 0.014.. \n",
      "Epoch: 53/100..  Training Loss: 0.013..  Test Loss: 0.012.. \n",
      "Epoch: 54/100..  Training Loss: 0.013..  Test Loss: 0.012.. \n",
      "Epoch: 55/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 56/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 57/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 58/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 59/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 60/100..  Training Loss: 0.011..  Test Loss: 0.011.. \n",
      "Epoch: 61/100..  Training Loss: 0.011..  Test Loss: 0.011.. \n",
      "Epoch: 62/100..  Training Loss: 0.011..  Test Loss: 0.010.. \n",
      "Epoch: 63/100..  Training Loss: 0.011..  Test Loss: 0.010.. \n",
      "Epoch: 64/100..  Training Loss: 0.011..  Test Loss: 0.010.. \n",
      "Epoch: 65/100..  Training Loss: 0.010..  Test Loss: 0.010.. \n",
      "Epoch: 66/100..  Training Loss: 0.010..  Test Loss: 0.010.. \n",
      "Epoch: 67/100..  Training Loss: 0.010..  Test Loss: 0.010.. \n",
      "Epoch: 68/100..  Training Loss: 0.011..  Test Loss: 0.010.. \n",
      "Epoch: 69/100..  Training Loss: 0.010..  Test Loss: 0.009.. \n",
      "Epoch: 70/100..  Training Loss: 0.010..  Test Loss: 0.009.. \n",
      "Epoch: 71/100..  Training Loss: 0.009..  Test Loss: 0.010.. \n",
      "Epoch: 72/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 73/100..  Training Loss: 0.010..  Test Loss: 0.009.. \n",
      "Epoch: 74/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 75/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 76/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 77/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 78/100..  Training Loss: 0.009..  Test Loss: 0.010.. \n",
      "Epoch: 79/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 80/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 81/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 82/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 83/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 84/100..  Training Loss: 0.010..  Test Loss: 0.009.. \n",
      "Epoch: 85/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 86/100..  Training Loss: 0.008..  Test Loss: 0.009.. \n",
      "Epoch: 87/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 88/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 89/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 90/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 91/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 92/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 93/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 94/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 95/100..  Training Loss: 0.008..  Test Loss: 0.013.. \n",
      "Epoch: 96/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 97/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 98/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 99/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 100/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Classifier used here is : 4-layered\n",
      "Correct benign is 10444 \n",
      " correct malicious is 7893 \n",
      " converted to benign is  3549\n",
      "   bits_flipped    TP     TN    FN\n",
      "0             0  9083  10444  2359\n",
      "1             1  8909  10444  2533\n",
      "2             2  8689  10444  2753\n",
      "3             3  8540  10444  2902\n",
      "4             4  8420  10444  3022\n",
      "5             5  8335  10444  3107\n",
      "6             6  8239  10444  3203\n",
      "7             7  8142  10444  3300\n",
      "8             8  8054  10444  3388\n",
      "9             9  7967  10444  3475\n",
      "10           10  7893  10444  3549\n",
      "This is training the neural network classifier for temperature 10\n",
      "Epoch: 1/50..  Training Loss: 0.503..  Test Loss: 0.484..  Test Accuracy: 0.829\n",
      "Epoch: 2/50..  Training Loss: 0.487..  Test Loss: 0.488..  Test Accuracy: 0.824\n",
      "Epoch: 3/50..  Training Loss: 0.484..  Test Loss: 0.483..  Test Accuracy: 0.830\n",
      "Epoch: 4/50..  Training Loss: 0.483..  Test Loss: 0.481..  Test Accuracy: 0.831\n",
      "Epoch: 5/50..  Training Loss: 0.481..  Test Loss: 0.479..  Test Accuracy: 0.834\n",
      "Epoch: 6/50..  Training Loss: 0.480..  Test Loss: 0.480..  Test Accuracy: 0.833\n",
      "Epoch: 7/50..  Training Loss: 0.478..  Test Loss: 0.476..  Test Accuracy: 0.837\n",
      "Epoch: 8/50..  Training Loss: 0.477..  Test Loss: 0.476..  Test Accuracy: 0.837\n",
      "Epoch: 9/50..  Training Loss: 0.476..  Test Loss: 0.475..  Test Accuracy: 0.838\n",
      "Epoch: 10/50..  Training Loss: 0.474..  Test Loss: 0.471..  Test Accuracy: 0.842\n",
      "Epoch: 11/50..  Training Loss: 0.472..  Test Loss: 0.471..  Test Accuracy: 0.842\n",
      "Epoch: 12/50..  Training Loss: 0.471..  Test Loss: 0.467..  Test Accuracy: 0.845\n",
      "Epoch: 13/50..  Training Loss: 0.470..  Test Loss: 0.469..  Test Accuracy: 0.844\n",
      "Epoch: 14/50..  Training Loss: 0.469..  Test Loss: 0.466..  Test Accuracy: 0.846\n",
      "Epoch: 15/50..  Training Loss: 0.466..  Test Loss: 0.465..  Test Accuracy: 0.848\n",
      "Epoch: 16/50..  Training Loss: 0.466..  Test Loss: 0.465..  Test Accuracy: 0.848\n",
      "Epoch: 17/50..  Training Loss: 0.466..  Test Loss: 0.465..  Test Accuracy: 0.847\n",
      "Epoch: 18/50..  Training Loss: 0.466..  Test Loss: 0.464..  Test Accuracy: 0.848\n",
      "Epoch: 19/50..  Training Loss: 0.465..  Test Loss: 0.465..  Test Accuracy: 0.847\n",
      "Epoch: 20/50..  Training Loss: 0.465..  Test Loss: 0.464..  Test Accuracy: 0.848\n",
      "Epoch: 21/50..  Training Loss: 0.464..  Test Loss: 0.464..  Test Accuracy: 0.849\n",
      "Epoch: 22/50..  Training Loss: 0.463..  Test Loss: 0.466..  Test Accuracy: 0.847\n",
      "Epoch: 23/50..  Training Loss: 0.463..  Test Loss: 0.463..  Test Accuracy: 0.849\n",
      "Epoch: 24/50..  Training Loss: 0.464..  Test Loss: 0.463..  Test Accuracy: 0.849\n",
      "Epoch: 25/50..  Training Loss: 0.463..  Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 26/50..  Training Loss: 0.462..  Test Loss: 0.468..  Test Accuracy: 0.844\n",
      "Epoch: 27/50..  Training Loss: 0.463..  Test Loss: 0.462..  Test Accuracy: 0.850\n",
      "Epoch: 28/50..  Training Loss: 0.462..  Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 29/50..  Training Loss: 0.462..  Test Loss: 0.460..  Test Accuracy: 0.852\n",
      "Epoch: 30/50..  Training Loss: 0.461..  Test Loss: 0.463..  Test Accuracy: 0.850\n",
      "Epoch: 31/50..  Training Loss: 0.463..  Test Loss: 0.463..  Test Accuracy: 0.849\n",
      "Epoch: 32/50..  Training Loss: 0.464..  Test Loss: 0.462..  Test Accuracy: 0.849\n",
      "Epoch: 33/50..  Training Loss: 0.461..  Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 34/50..  Training Loss: 0.461..  Test Loss: 0.463..  Test Accuracy: 0.850\n",
      "Epoch: 35/50..  Training Loss: 0.462..  Test Loss: 0.463..  Test Accuracy: 0.848\n",
      "Epoch: 36/50..  Training Loss: 0.462..  Test Loss: 0.460..  Test Accuracy: 0.851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37/50..  Training Loss: 0.463..  Test Loss: 0.462..  Test Accuracy: 0.850\n",
      "Epoch: 38/50..  Training Loss: 0.461..  Test Loss: 0.460..  Test Accuracy: 0.851\n",
      "Epoch: 39/50..  Training Loss: 0.461..  Test Loss: 0.462..  Test Accuracy: 0.850\n",
      "Epoch: 40/50..  Training Loss: 0.461..  Test Loss: 0.461..  Test Accuracy: 0.850\n",
      "Epoch: 41/50..  Training Loss: 0.462..  Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 42/50..  Training Loss: 0.461..  Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 43/50..  Training Loss: 0.461..  Test Loss: 0.461..  Test Accuracy: 0.850\n",
      "Epoch: 44/50..  Training Loss: 0.461..  Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 45/50..  Training Loss: 0.461..  Test Loss: 0.463..  Test Accuracy: 0.849\n",
      "Epoch: 46/50..  Training Loss: 0.462..  Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 47/50..  Training Loss: 0.462..  Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 48/50..  Training Loss: 0.461..  Test Loss: 0.460..  Test Accuracy: 0.851\n",
      "Epoch: 49/50..  Training Loss: 0.462..  Test Loss: 0.464..  Test Accuracy: 0.848\n",
      "Epoch: 50/50..  Training Loss: 0.462..  Test Loss: 0.460..  Test Accuracy: 0.851\n",
      "The length of the dataset is 22884\n",
      "Shape of X is (22884, 273) and shape of y_probs is (22884, 2)\n",
      "Epoch: 1/100..  Training Loss: 0.245..  Test Loss: 0.245.. \n",
      "Epoch: 2/100..  Training Loss: 0.244..  Test Loss: 0.244.. \n",
      "Epoch: 3/100..  Training Loss: 0.243..  Test Loss: 0.243.. \n",
      "Epoch: 4/100..  Training Loss: 0.242..  Test Loss: 0.242.. \n",
      "Epoch: 5/100..  Training Loss: 0.241..  Test Loss: 0.240.. \n",
      "Epoch: 6/100..  Training Loss: 0.238..  Test Loss: 0.236.. \n",
      "Epoch: 7/100..  Training Loss: 0.232..  Test Loss: 0.225.. \n",
      "Epoch: 8/100..  Training Loss: 0.210..  Test Loss: 0.188.. \n",
      "Epoch: 9/100..  Training Loss: 0.144..  Test Loss: 0.096.. \n",
      "Epoch: 10/100..  Training Loss: 0.073..  Test Loss: 0.061.. \n",
      "Epoch: 11/100..  Training Loss: 0.057..  Test Loss: 0.054.. \n",
      "Epoch: 12/100..  Training Loss: 0.053..  Test Loss: 0.052.. \n",
      "Epoch: 13/100..  Training Loss: 0.051..  Test Loss: 0.051.. \n",
      "Epoch: 14/100..  Training Loss: 0.050..  Test Loss: 0.049.. \n",
      "Epoch: 15/100..  Training Loss: 0.049..  Test Loss: 0.049.. \n",
      "Epoch: 16/100..  Training Loss: 0.048..  Test Loss: 0.048.. \n",
      "Epoch: 17/100..  Training Loss: 0.047..  Test Loss: 0.047.. \n",
      "Epoch: 18/100..  Training Loss: 0.046..  Test Loss: 0.046.. \n",
      "Epoch: 19/100..  Training Loss: 0.045..  Test Loss: 0.046.. \n",
      "Epoch: 20/100..  Training Loss: 0.045..  Test Loss: 0.044.. \n",
      "Epoch: 21/100..  Training Loss: 0.045..  Test Loss: 0.044.. \n",
      "Epoch: 22/100..  Training Loss: 0.043..  Test Loss: 0.043.. \n",
      "Epoch: 23/100..  Training Loss: 0.042..  Test Loss: 0.042.. \n",
      "Epoch: 24/100..  Training Loss: 0.041..  Test Loss: 0.041.. \n",
      "Epoch: 25/100..  Training Loss: 0.040..  Test Loss: 0.039.. \n",
      "Epoch: 26/100..  Training Loss: 0.039..  Test Loss: 0.039.. \n",
      "Epoch: 27/100..  Training Loss: 0.038..  Test Loss: 0.038.. \n",
      "Epoch: 28/100..  Training Loss: 0.038..  Test Loss: 0.037.. \n",
      "Epoch: 29/100..  Training Loss: 0.036..  Test Loss: 0.036.. \n",
      "Epoch: 30/100..  Training Loss: 0.035..  Test Loss: 0.035.. \n",
      "Epoch: 31/100..  Training Loss: 0.034..  Test Loss: 0.034.. \n",
      "Epoch: 32/100..  Training Loss: 0.033..  Test Loss: 0.032.. \n",
      "Epoch: 33/100..  Training Loss: 0.032..  Test Loss: 0.031.. \n",
      "Epoch: 34/100..  Training Loss: 0.031..  Test Loss: 0.031.. \n",
      "Epoch: 35/100..  Training Loss: 0.030..  Test Loss: 0.029.. \n",
      "Epoch: 36/100..  Training Loss: 0.029..  Test Loss: 0.029.. \n",
      "Epoch: 37/100..  Training Loss: 0.028..  Test Loss: 0.029.. \n",
      "Epoch: 38/100..  Training Loss: 0.028..  Test Loss: 0.027.. \n",
      "Epoch: 39/100..  Training Loss: 0.027..  Test Loss: 0.026.. \n",
      "Epoch: 40/100..  Training Loss: 0.026..  Test Loss: 0.026.. \n",
      "Epoch: 41/100..  Training Loss: 0.026..  Test Loss: 0.026.. \n",
      "Epoch: 42/100..  Training Loss: 0.024..  Test Loss: 0.024.. \n",
      "Epoch: 43/100..  Training Loss: 0.024..  Test Loss: 0.024.. \n",
      "Epoch: 44/100..  Training Loss: 0.023..  Test Loss: 0.022.. \n",
      "Epoch: 45/100..  Training Loss: 0.022..  Test Loss: 0.022.. \n",
      "Epoch: 46/100..  Training Loss: 0.021..  Test Loss: 0.021.. \n",
      "Epoch: 47/100..  Training Loss: 0.021..  Test Loss: 0.021.. \n",
      "Epoch: 48/100..  Training Loss: 0.020..  Test Loss: 0.020.. \n",
      "Epoch: 49/100..  Training Loss: 0.020..  Test Loss: 0.019.. \n",
      "Epoch: 50/100..  Training Loss: 0.019..  Test Loss: 0.019.. \n",
      "Epoch: 51/100..  Training Loss: 0.019..  Test Loss: 0.019.. \n",
      "Epoch: 52/100..  Training Loss: 0.019..  Test Loss: 0.018.. \n",
      "Epoch: 53/100..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 54/100..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 55/100..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 56/100..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 57/100..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 58/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 59/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 60/100..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 61/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 62/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 63/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 64/100..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 65/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 66/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 67/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 68/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 69/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 70/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 71/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 72/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 73/100..  Training Loss: 0.012..  Test Loss: 0.011.. \n",
      "Epoch: 74/100..  Training Loss: 0.011..  Test Loss: 0.011.. \n",
      "Epoch: 75/100..  Training Loss: 0.011..  Test Loss: 0.011.. \n",
      "Epoch: 76/100..  Training Loss: 0.011..  Test Loss: 0.010.. \n",
      "Epoch: 77/100..  Training Loss: 0.010..  Test Loss: 0.010.. \n",
      "Epoch: 78/100..  Training Loss: 0.010..  Test Loss: 0.011.. \n",
      "Epoch: 79/100..  Training Loss: 0.010..  Test Loss: 0.010.. \n",
      "Epoch: 80/100..  Training Loss: 0.010..  Test Loss: 0.010.. \n",
      "Epoch: 81/100..  Training Loss: 0.010..  Test Loss: 0.010.. \n",
      "Epoch: 82/100..  Training Loss: 0.010..  Test Loss: 0.009.. \n",
      "Epoch: 83/100..  Training Loss: 0.010..  Test Loss: 0.009.. \n",
      "Epoch: 84/100..  Training Loss: 0.010..  Test Loss: 0.009.. \n",
      "Epoch: 85/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 86/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 87/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 88/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 89/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 90/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 91/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 92/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 93/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 94/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 95/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 96/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 97/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 98/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 99/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 100/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Classifier used here is : 4-layered\n",
      "Correct benign is 10334 \n",
      " correct malicious is 7566 \n",
      " converted to benign is  3876\n",
      "   bits_flipped    TP     TN    FN\n",
      "0             0  9064  10334  2378\n",
      "1             1  8774  10334  2668\n",
      "2             2  8476  10334  2966\n",
      "3             3  8322  10334  3120\n",
      "4             4  8216  10334  3226\n",
      "5             5  8105  10334  3337\n",
      "6             6  8007  10334  3435\n",
      "7             7  7912  10334  3530\n",
      "8             8  7798  10334  3644\n",
      "9             9  7666  10334  3776\n",
      "10           10  7566  10334  3876\n"
     ]
    }
   ],
   "source": [
    "for t in [1, 5,10]:\n",
    "    epochs=50\n",
    "    \n",
    "    print(\"This is training the neural network classifier for temperature {}\".format(t))\n",
    "    \n",
    "    model_class= model_4(t)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model_class.parameters(), lr=0.001)\n",
    "    \n",
    "    df=pd.read_csv('../Resampled_Datasets_Attack/4-layered'+'_resamp.csv')\n",
    "    X=df.iloc[:,:-1].values\n",
    "    y=df.iloc[:,-1].values\n",
    "    train_dataset = Datasetcustom(X, y)\n",
    "    test_dataset = Datasetcustom(X, y)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=20, shuffle=True)\n",
    "\n",
    "    train_losses, test_losses = [], []\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            log_ps = model_class(images)\n",
    "    #         print(log_ps)\n",
    "            loss = criterion(log_ps, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        else:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "\n",
    "            # Turn off gradients for validation, saves memory and computations\n",
    "            with torch.no_grad():\n",
    "                for images, labels in test_loader:\n",
    "                    log_ps = model_class(images)\n",
    "                    test_loss += criterion(log_ps, labels)\n",
    "\n",
    "                    top_p, top_class = log_ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "            train_losses.append(running_loss/len(train_loader))\n",
    "            test_losses.append(test_loss/len(test_loader))\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))\n",
    "            \n",
    "    print(\"The length of the dataset is {}\".format(len(train_dataset)))\n",
    "    probs_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True)\n",
    "    train_iter = iter(probs_loader)\n",
    "    images, labels = train_iter.next()\n",
    "    y_probs= model_class(images)\n",
    "    y_probs=y_probs.detach().numpy()\n",
    "    X_probs=images.detach().numpy()\n",
    "    \n",
    "    print(\"Shape of X is {} and shape of y_probs is {}\".format(X.shape, y_probs.shape))\n",
    "    X_train, X_test, y_train, y_test =X_probs,X_probs,  y_probs ,  y_probs\n",
    "    \n",
    "    train_dataset_dist = Datasetcustom(X_train, y_train)\n",
    "    test_dataset_dist= Datasetcustom(X_test, y_test)\n",
    "    train_loader_dist = DataLoader(train_dataset_dist, batch_size=20, shuffle=True)\n",
    "    test_loader_dist = DataLoader(test_dataset_dist, batch_size=20, shuffle=True)\n",
    "    \n",
    "    model_reg=model_4dist(t)\n",
    "    criterion_dist =  nn.MSELoss()\n",
    "    optimizer_dist = optim.SGD(model_reg.parameters(), lr=0.02)\n",
    "\n",
    "    epochs= 100\n",
    "    train_losses, test_losses = [], []\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        for images, labels in train_loader_dist:\n",
    "\n",
    "            optimizer_dist.zero_grad()\n",
    "            log_ps = model_reg(images)\n",
    "            loss = criterion_dist(log_ps, labels)\n",
    "            loss.backward()\n",
    "            optimizer_dist.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        else:\n",
    "            test_loss = 0\n",
    "\n",
    "            # Turn off gradients for validation, saves memory and computations\n",
    "            with torch.no_grad():\n",
    "                for images, labels in test_loader_dist:\n",
    "                    log_ps = model_reg(images)\n",
    "                    test_loss += criterion_dist(log_ps, labels)\n",
    "\n",
    "            train_losses.append(running_loss/len(train_loader_dist))\n",
    "            test_losses.append(test_loss/len(test_loader_dist))\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader_dist)),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader_dist)))\n",
    "    \n",
    "    Models={ \"4-layered\": model_reg}\n",
    "    model=torch.load('../trained_models/Train-512-256-64.pth')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    #Attack with original attacker after retraining\n",
    "    for Algorithm in Models:\n",
    "            df1=pd.DataFrame(columns = ['bits_flipped','TP', 'TN','FN'])\n",
    "            for i in range(0,11):\n",
    "                df1=df1.append(pd.Series([i, 11442, 0, 0], index= df1.columns), ignore_index=True )\n",
    "            print(\"Classifier used here is : {}\".format(Algorithm))\n",
    "            classifier= Models[Algorithm]\n",
    "            correct_benign=0\n",
    "            correct_malicious=0\n",
    "            convert_to_benign=0\n",
    "            \n",
    "            df=pd.read_csv('../Resampled_Datasets_Attack/4-layered'+'_resamp.csv')\n",
    "            X=df.iloc[:,:-1].values\n",
    "            y=df.iloc[:,-1].values\n",
    "            target_model= Models[Algorithm]\n",
    "            test_dataset= Datasetcustom(X, y)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "            for images, labels in test_loader:\n",
    "                images.requires_grad = True\n",
    "                model.zero_grad()\n",
    "                output = model(images)\n",
    "                y_pred = target_model(images)\n",
    "                loss = criterion(output, labels)\n",
    "                loss.backward()\n",
    "                data_grad = images.grad.data\n",
    "                if  y_pred[0][1]>y_pred[0][0] and labels[0]==1: #predicted malicious\n",
    "                    grad_list=[]\n",
    "                    for i in range(273):\n",
    "                        if images[0][i]==0:\n",
    "                            grad_list.append((data_grad[0][i],i))\n",
    "                    grad_list.sort(key = lambda x: x[0], reverse=True)\n",
    "                    flag=0\n",
    "                    for i in range(0,10):\n",
    "                        images[0][grad_list[i][1]]=1\n",
    "                        y_pred = target_model(images)\n",
    "                        if y_pred[0][0]>y_pred[0][1]:\n",
    "                            for j in range(i,10):  #converted in i+1 flips, hence all bits>=i+1, the FN will increase\n",
    "                                df1.iloc[j+1,3]+=1\n",
    "                                df1.iloc[j+1,1]-=1\n",
    "                            flag=1\n",
    "                            convert_to_benign+=1\n",
    "                            break\n",
    "                    if flag==0:          #Even after 10 flips, unable to convert to benignm update malicious counter\n",
    "                        correct_malicious+=1\n",
    "                elif y_pred[0][0]>y_pred[0][1] and labels[0]==1:  #If predicted as benign but is malicious\n",
    "                    for j in range(0,11):\n",
    "                        df1.iloc[j,3]+=1\n",
    "                        df1.iloc[j,1]-=1\n",
    "                    convert_to_benign+=1\n",
    "                elif  y_pred[0][0]>y_pred[0][1] and labels[0]==0:  #if predicted benign correctly\n",
    "                    for j in range(0,11):\n",
    "                        df1.iloc[j,2]+=1\n",
    "                    correct_benign+=1\n",
    "\n",
    "            print(\"Correct benign is {} \\n correct malicious is {} \\n converted to benign is  {}\".format(correct_benign, correct_malicious, convert_to_benign))\n",
    "    #         print(\"Final Accuracy is {:.3f} with max {} bits flipped\".format((correct_benign+5553-convert_benign)/11274, num_bits))\n",
    "            print(df1)\n",
    "            df1.to_csv(\"../Hybrid_Distillation/\"+str(Algorithm)+\"_Distillation_\"+str(t)+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Layered Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_2(nn.Module):\n",
    "    def __init__(self,t):\n",
    "        super(model_2, self).__init__()\n",
    "        self.t=t\n",
    "        self.l1=nn.Linear(273, 2)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.dropout= nn.Dropout(0.4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.l1(x)\n",
    "        x= nn.Softmax(dim=1)(x/self.t)\n",
    "        return x\n",
    "    \n",
    "class model_2dist(nn.Module):\n",
    "    def __init__(self,t):\n",
    "        super(model_2dist, self).__init__()\n",
    "        self.t=t\n",
    "        self.l1=nn.Linear(273, 2)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.dropout= nn.Dropout(0.4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.l1(x)\n",
    "        x= nn.Softmax(dim=1)(x/self.t)\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is training the neural network classifier for temperature 1\n",
      "Epoch: 1/50..  Training Loss: 0.600..  Test Loss: 0.552..  Test Accuracy: 0.803\n",
      "Epoch: 2/50..  Training Loss: 0.536..  Test Loss: 0.525..  Test Accuracy: 0.805\n",
      "Epoch: 3/50..  Training Loss: 0.519..  Test Loss: 0.514..  Test Accuracy: 0.805\n",
      "Epoch: 4/50..  Training Loss: 0.511..  Test Loss: 0.509..  Test Accuracy: 0.807\n",
      "Epoch: 5/50..  Training Loss: 0.507..  Test Loss: 0.505..  Test Accuracy: 0.808\n",
      "Epoch: 6/50..  Training Loss: 0.504..  Test Loss: 0.503..  Test Accuracy: 0.809\n",
      "Epoch: 7/50..  Training Loss: 0.502..  Test Loss: 0.501..  Test Accuracy: 0.812\n",
      "Epoch: 8/50..  Training Loss: 0.500..  Test Loss: 0.500..  Test Accuracy: 0.813\n",
      "Epoch: 9/50..  Training Loss: 0.499..  Test Loss: 0.498..  Test Accuracy: 0.814\n",
      "Epoch: 10/50..  Training Loss: 0.498..  Test Loss: 0.497..  Test Accuracy: 0.817\n",
      "Epoch: 11/50..  Training Loss: 0.497..  Test Loss: 0.496..  Test Accuracy: 0.818\n",
      "Epoch: 12/50..  Training Loss: 0.496..  Test Loss: 0.496..  Test Accuracy: 0.819\n",
      "Epoch: 13/50..  Training Loss: 0.495..  Test Loss: 0.495..  Test Accuracy: 0.818\n",
      "Epoch: 14/50..  Training Loss: 0.495..  Test Loss: 0.494..  Test Accuracy: 0.819\n",
      "Epoch: 15/50..  Training Loss: 0.494..  Test Loss: 0.494..  Test Accuracy: 0.822\n",
      "Epoch: 16/50..  Training Loss: 0.494..  Test Loss: 0.494..  Test Accuracy: 0.820\n",
      "Epoch: 17/50..  Training Loss: 0.493..  Test Loss: 0.493..  Test Accuracy: 0.821\n",
      "Epoch: 18/50..  Training Loss: 0.493..  Test Loss: 0.492..  Test Accuracy: 0.824\n",
      "Epoch: 19/50..  Training Loss: 0.492..  Test Loss: 0.492..  Test Accuracy: 0.824\n",
      "Epoch: 20/50..  Training Loss: 0.492..  Test Loss: 0.492..  Test Accuracy: 0.824\n",
      "Epoch: 21/50..  Training Loss: 0.491..  Test Loss: 0.491..  Test Accuracy: 0.824\n",
      "Epoch: 22/50..  Training Loss: 0.491..  Test Loss: 0.490..  Test Accuracy: 0.826\n",
      "Epoch: 23/50..  Training Loss: 0.491..  Test Loss: 0.490..  Test Accuracy: 0.826\n",
      "Epoch: 24/50..  Training Loss: 0.490..  Test Loss: 0.490..  Test Accuracy: 0.825\n",
      "Epoch: 25/50..  Training Loss: 0.490..  Test Loss: 0.490..  Test Accuracy: 0.827\n",
      "Epoch: 26/50..  Training Loss: 0.490..  Test Loss: 0.489..  Test Accuracy: 0.826\n",
      "Epoch: 27/50..  Training Loss: 0.489..  Test Loss: 0.489..  Test Accuracy: 0.826\n",
      "Epoch: 28/50..  Training Loss: 0.489..  Test Loss: 0.489..  Test Accuracy: 0.826\n",
      "Epoch: 29/50..  Training Loss: 0.489..  Test Loss: 0.489..  Test Accuracy: 0.827\n",
      "Epoch: 30/50..  Training Loss: 0.489..  Test Loss: 0.488..  Test Accuracy: 0.827\n",
      "Epoch: 31/50..  Training Loss: 0.489..  Test Loss: 0.488..  Test Accuracy: 0.828\n",
      "Epoch: 32/50..  Training Loss: 0.488..  Test Loss: 0.488..  Test Accuracy: 0.827\n",
      "Epoch: 33/50..  Training Loss: 0.488..  Test Loss: 0.488..  Test Accuracy: 0.828\n",
      "Epoch: 34/50..  Training Loss: 0.488..  Test Loss: 0.488..  Test Accuracy: 0.828\n",
      "Epoch: 35/50..  Training Loss: 0.488..  Test Loss: 0.488..  Test Accuracy: 0.827\n",
      "Epoch: 36/50..  Training Loss: 0.488..  Test Loss: 0.487..  Test Accuracy: 0.828\n",
      "Epoch: 37/50..  Training Loss: 0.487..  Test Loss: 0.487..  Test Accuracy: 0.828\n",
      "Epoch: 38/50..  Training Loss: 0.487..  Test Loss: 0.487..  Test Accuracy: 0.828\n",
      "Epoch: 39/50..  Training Loss: 0.487..  Test Loss: 0.487..  Test Accuracy: 0.830\n",
      "Epoch: 40/50..  Training Loss: 0.487..  Test Loss: 0.487..  Test Accuracy: 0.829\n",
      "Epoch: 41/50..  Training Loss: 0.487..  Test Loss: 0.487..  Test Accuracy: 0.830\n",
      "Epoch: 42/50..  Training Loss: 0.487..  Test Loss: 0.487..  Test Accuracy: 0.830\n",
      "Epoch: 43/50..  Training Loss: 0.487..  Test Loss: 0.487..  Test Accuracy: 0.829\n",
      "Epoch: 44/50..  Training Loss: 0.486..  Test Loss: 0.486..  Test Accuracy: 0.829\n",
      "Epoch: 45/50..  Training Loss: 0.486..  Test Loss: 0.486..  Test Accuracy: 0.829\n",
      "Epoch: 46/50..  Training Loss: 0.487..  Test Loss: 0.486..  Test Accuracy: 0.830\n",
      "Epoch: 47/50..  Training Loss: 0.486..  Test Loss: 0.486..  Test Accuracy: 0.830\n",
      "Epoch: 48/50..  Training Loss: 0.486..  Test Loss: 0.486..  Test Accuracy: 0.830\n",
      "Epoch: 49/50..  Training Loss: 0.486..  Test Loss: 0.486..  Test Accuracy: 0.830\n",
      "Epoch: 50/50..  Training Loss: 0.486..  Test Loss: 0.486..  Test Accuracy: 0.830\n",
      "The length of the dataset is 22884\n",
      "Shape of X is (22884, 273) and shape of y_probs is (22884, 2)\n",
      "Epoch: 1/100..  Training Loss: 0.100..  Test Loss: 0.053.. \n",
      "Epoch: 2/100..  Training Loss: 0.043..  Test Loss: 0.036.. \n",
      "Epoch: 3/100..  Training Loss: 0.033..  Test Loss: 0.031.. \n",
      "Epoch: 4/100..  Training Loss: 0.029..  Test Loss: 0.028.. \n",
      "Epoch: 5/100..  Training Loss: 0.027..  Test Loss: 0.026.. \n",
      "Epoch: 6/100..  Training Loss: 0.025..  Test Loss: 0.025.. \n",
      "Epoch: 7/100..  Training Loss: 0.024..  Test Loss: 0.024.. \n",
      "Epoch: 8/100..  Training Loss: 0.023..  Test Loss: 0.023.. \n",
      "Epoch: 9/100..  Training Loss: 0.023..  Test Loss: 0.022.. \n",
      "Epoch: 10/100..  Training Loss: 0.022..  Test Loss: 0.022.. \n",
      "Epoch: 11/100..  Training Loss: 0.021..  Test Loss: 0.021.. \n",
      "Epoch: 12/100..  Training Loss: 0.021..  Test Loss: 0.021.. \n",
      "Epoch: 13/100..  Training Loss: 0.021..  Test Loss: 0.020.. \n",
      "Epoch: 14/100..  Training Loss: 0.020..  Test Loss: 0.020.. \n",
      "Epoch: 15/100..  Training Loss: 0.020..  Test Loss: 0.020.. \n",
      "Epoch: 16/100..  Training Loss: 0.020..  Test Loss: 0.020.. \n",
      "Epoch: 17/100..  Training Loss: 0.019..  Test Loss: 0.019.. \n",
      "Epoch: 18/100..  Training Loss: 0.019..  Test Loss: 0.019.. \n",
      "Epoch: 19/100..  Training Loss: 0.019..  Test Loss: 0.019.. \n",
      "Epoch: 20/100..  Training Loss: 0.019..  Test Loss: 0.018.. \n",
      "Epoch: 21/100..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 22/100..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 23/100..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 24/100..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 25/100..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 26/100..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 27/100..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 28/100..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 29/100..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 30/100..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 31/100..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 32/100..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 33/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 34/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 35/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 36/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 37/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 38/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 39/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 40/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 41/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 42/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 43/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 44/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 45/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 46/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 47/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 48/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 49/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 50/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 51/100..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 52/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 53/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 54/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 55/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 56/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 57/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 58/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 59/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 60/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 61/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 62/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 63/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 64/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 65/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 66/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 68/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 69/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 70/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 71/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 72/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 73/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 74/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 75/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 76/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 77/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 78/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 79/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 80/100..  Training Loss: 0.013..  Test Loss: 0.012.. \n",
      "Epoch: 81/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 82/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 83/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 84/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 85/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 86/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 87/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 88/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 89/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 90/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 91/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 92/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 93/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 94/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 95/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 96/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 97/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 98/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 99/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 100/100..  Training Loss: 0.012..  Test Loss: 0.011.. \n",
      "Classifier used here is : 2-layered\n",
      "Correct benign is 9922 \n",
      " correct malicious is 7941 \n",
      " converted to benign is  3501\n",
      "   bits_flipped    TP    TN    FN\n",
      "0             0  8708  9922  2734\n",
      "1             1  8478  9922  2964\n",
      "2             2  8409  9922  3033\n",
      "3             3  8354  9922  3088\n",
      "4             4  8303  9922  3139\n",
      "5             5  8240  9922  3202\n",
      "6             6  8179  9922  3263\n",
      "7             7  8105  9922  3337\n",
      "8             8  8058  9922  3384\n",
      "9             9  8005  9922  3437\n",
      "10           10  7941  9922  3501\n",
      "This is training the neural network classifier for temperature 5\n",
      "Epoch: 1/50..  Training Loss: 0.662..  Test Loss: 0.637..  Test Accuracy: 0.802\n",
      "Epoch: 2/50..  Training Loss: 0.618..  Test Loss: 0.601..  Test Accuracy: 0.798\n",
      "Epoch: 3/50..  Training Loss: 0.589..  Test Loss: 0.577..  Test Accuracy: 0.800\n",
      "Epoch: 4/50..  Training Loss: 0.569..  Test Loss: 0.560..  Test Accuracy: 0.802\n",
      "Epoch: 5/50..  Training Loss: 0.554..  Test Loss: 0.548..  Test Accuracy: 0.803\n",
      "Epoch: 6/50..  Training Loss: 0.544..  Test Loss: 0.539..  Test Accuracy: 0.803\n",
      "Epoch: 7/50..  Training Loss: 0.536..  Test Loss: 0.532..  Test Accuracy: 0.801\n",
      "Epoch: 8/50..  Training Loss: 0.530..  Test Loss: 0.527..  Test Accuracy: 0.804\n",
      "Epoch: 9/50..  Training Loss: 0.525..  Test Loss: 0.523..  Test Accuracy: 0.804\n",
      "Epoch: 10/50..  Training Loss: 0.522..  Test Loss: 0.520..  Test Accuracy: 0.805\n",
      "Epoch: 11/50..  Training Loss: 0.519..  Test Loss: 0.517..  Test Accuracy: 0.805\n",
      "Epoch: 12/50..  Training Loss: 0.516..  Test Loss: 0.515..  Test Accuracy: 0.806\n",
      "Epoch: 13/50..  Training Loss: 0.514..  Test Loss: 0.513..  Test Accuracy: 0.806\n",
      "Epoch: 14/50..  Training Loss: 0.513..  Test Loss: 0.512..  Test Accuracy: 0.806\n",
      "Epoch: 15/50..  Training Loss: 0.511..  Test Loss: 0.511..  Test Accuracy: 0.807\n",
      "Epoch: 16/50..  Training Loss: 0.510..  Test Loss: 0.510..  Test Accuracy: 0.807\n",
      "Epoch: 17/50..  Training Loss: 0.509..  Test Loss: 0.509..  Test Accuracy: 0.807\n",
      "Epoch: 18/50..  Training Loss: 0.508..  Test Loss: 0.508..  Test Accuracy: 0.808\n",
      "Epoch: 19/50..  Training Loss: 0.507..  Test Loss: 0.507..  Test Accuracy: 0.808\n",
      "Epoch: 20/50..  Training Loss: 0.507..  Test Loss: 0.506..  Test Accuracy: 0.808\n",
      "Epoch: 21/50..  Training Loss: 0.506..  Test Loss: 0.506..  Test Accuracy: 0.808\n",
      "Epoch: 22/50..  Training Loss: 0.505..  Test Loss: 0.505..  Test Accuracy: 0.808\n",
      "Epoch: 23/50..  Training Loss: 0.505..  Test Loss: 0.505..  Test Accuracy: 0.808\n",
      "Epoch: 24/50..  Training Loss: 0.505..  Test Loss: 0.504..  Test Accuracy: 0.808\n",
      "Epoch: 25/50..  Training Loss: 0.504..  Test Loss: 0.504..  Test Accuracy: 0.808\n",
      "Epoch: 26/50..  Training Loss: 0.504..  Test Loss: 0.503..  Test Accuracy: 0.808\n",
      "Epoch: 27/50..  Training Loss: 0.503..  Test Loss: 0.503..  Test Accuracy: 0.809\n",
      "Epoch: 28/50..  Training Loss: 0.503..  Test Loss: 0.503..  Test Accuracy: 0.809\n",
      "Epoch: 29/50..  Training Loss: 0.502..  Test Loss: 0.502..  Test Accuracy: 0.810\n",
      "Epoch: 30/50..  Training Loss: 0.502..  Test Loss: 0.502..  Test Accuracy: 0.810\n",
      "Epoch: 31/50..  Training Loss: 0.502..  Test Loss: 0.502..  Test Accuracy: 0.811\n",
      "Epoch: 32/50..  Training Loss: 0.502..  Test Loss: 0.501..  Test Accuracy: 0.811\n",
      "Epoch: 33/50..  Training Loss: 0.501..  Test Loss: 0.501..  Test Accuracy: 0.811\n",
      "Epoch: 34/50..  Training Loss: 0.501..  Test Loss: 0.501..  Test Accuracy: 0.811\n",
      "Epoch: 35/50..  Training Loss: 0.501..  Test Loss: 0.500..  Test Accuracy: 0.812\n",
      "Epoch: 36/50..  Training Loss: 0.500..  Test Loss: 0.500..  Test Accuracy: 0.812\n",
      "Epoch: 37/50..  Training Loss: 0.500..  Test Loss: 0.500..  Test Accuracy: 0.812\n",
      "Epoch: 38/50..  Training Loss: 0.500..  Test Loss: 0.499..  Test Accuracy: 0.812\n",
      "Epoch: 39/50..  Training Loss: 0.499..  Test Loss: 0.499..  Test Accuracy: 0.812\n",
      "Epoch: 40/50..  Training Loss: 0.499..  Test Loss: 0.499..  Test Accuracy: 0.813\n",
      "Epoch: 41/50..  Training Loss: 0.499..  Test Loss: 0.499..  Test Accuracy: 0.813\n",
      "Epoch: 42/50..  Training Loss: 0.499..  Test Loss: 0.499..  Test Accuracy: 0.813\n",
      "Epoch: 43/50..  Training Loss: 0.498..  Test Loss: 0.498..  Test Accuracy: 0.814\n",
      "Epoch: 44/50..  Training Loss: 0.498..  Test Loss: 0.498..  Test Accuracy: 0.815\n",
      "Epoch: 45/50..  Training Loss: 0.498..  Test Loss: 0.498..  Test Accuracy: 0.815\n",
      "Epoch: 46/50..  Training Loss: 0.498..  Test Loss: 0.498..  Test Accuracy: 0.815\n",
      "Epoch: 47/50..  Training Loss: 0.497..  Test Loss: 0.497..  Test Accuracy: 0.815\n",
      "Epoch: 48/50..  Training Loss: 0.497..  Test Loss: 0.497..  Test Accuracy: 0.815\n",
      "Epoch: 49/50..  Training Loss: 0.497..  Test Loss: 0.497..  Test Accuracy: 0.816\n",
      "Epoch: 50/50..  Training Loss: 0.497..  Test Loss: 0.497..  Test Accuracy: 0.816\n",
      "The length of the dataset is 22884\n",
      "Shape of X is (22884, 273) and shape of y_probs is (22884, 2)\n",
      "Epoch: 1/100..  Training Loss: 0.192..  Test Loss: 0.180.. \n",
      "Epoch: 2/100..  Training Loss: 0.170..  Test Loss: 0.160.. \n",
      "Epoch: 3/100..  Training Loss: 0.152..  Test Loss: 0.143.. \n",
      "Epoch: 4/100..  Training Loss: 0.136..  Test Loss: 0.129.. \n",
      "Epoch: 5/100..  Training Loss: 0.122..  Test Loss: 0.116.. \n",
      "Epoch: 6/100..  Training Loss: 0.111..  Test Loss: 0.105.. \n",
      "Epoch: 7/100..  Training Loss: 0.101..  Test Loss: 0.096.. \n",
      "Epoch: 8/100..  Training Loss: 0.092..  Test Loss: 0.088.. \n",
      "Epoch: 9/100..  Training Loss: 0.085..  Test Loss: 0.082.. \n",
      "Epoch: 10/100..  Training Loss: 0.079..  Test Loss: 0.076.. \n",
      "Epoch: 11/100..  Training Loss: 0.073..  Test Loss: 0.070.. \n",
      "Epoch: 12/100..  Training Loss: 0.068..  Test Loss: 0.066.. \n",
      "Epoch: 13/100..  Training Loss: 0.064..  Test Loss: 0.062.. \n",
      "Epoch: 14/100..  Training Loss: 0.060..  Test Loss: 0.058.. \n",
      "Epoch: 15/100..  Training Loss: 0.057..  Test Loss: 0.055.. \n",
      "Epoch: 16/100..  Training Loss: 0.054..  Test Loss: 0.052.. \n",
      "Epoch: 17/100..  Training Loss: 0.051..  Test Loss: 0.050.. \n",
      "Epoch: 18/100..  Training Loss: 0.048..  Test Loss: 0.047.. \n",
      "Epoch: 19/100..  Training Loss: 0.046..  Test Loss: 0.045.. \n",
      "Epoch: 20/100..  Training Loss: 0.044..  Test Loss: 0.043.. \n",
      "Epoch: 21/100..  Training Loss: 0.042..  Test Loss: 0.042.. \n",
      "Epoch: 22/100..  Training Loss: 0.041..  Test Loss: 0.040.. \n",
      "Epoch: 23/100..  Training Loss: 0.039..  Test Loss: 0.038.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/100..  Training Loss: 0.038..  Test Loss: 0.037.. \n",
      "Epoch: 25/100..  Training Loss: 0.036..  Test Loss: 0.036.. \n",
      "Epoch: 26/100..  Training Loss: 0.035..  Test Loss: 0.035.. \n",
      "Epoch: 27/100..  Training Loss: 0.034..  Test Loss: 0.034.. \n",
      "Epoch: 28/100..  Training Loss: 0.033..  Test Loss: 0.033.. \n",
      "Epoch: 29/100..  Training Loss: 0.032..  Test Loss: 0.032.. \n",
      "Epoch: 30/100..  Training Loss: 0.031..  Test Loss: 0.031.. \n",
      "Epoch: 31/100..  Training Loss: 0.030..  Test Loss: 0.030.. \n",
      "Epoch: 32/100..  Training Loss: 0.030..  Test Loss: 0.029.. \n",
      "Epoch: 33/100..  Training Loss: 0.029..  Test Loss: 0.029.. \n",
      "Epoch: 34/100..  Training Loss: 0.028..  Test Loss: 0.028.. \n",
      "Epoch: 35/100..  Training Loss: 0.028..  Test Loss: 0.027.. \n",
      "Epoch: 36/100..  Training Loss: 0.027..  Test Loss: 0.027.. \n",
      "Epoch: 37/100..  Training Loss: 0.026..  Test Loss: 0.026.. \n",
      "Epoch: 38/100..  Training Loss: 0.026..  Test Loss: 0.026.. \n",
      "Epoch: 39/100..  Training Loss: 0.025..  Test Loss: 0.025.. \n",
      "Epoch: 40/100..  Training Loss: 0.025..  Test Loss: 0.025.. \n",
      "Epoch: 41/100..  Training Loss: 0.024..  Test Loss: 0.024.. \n",
      "Epoch: 42/100..  Training Loss: 0.024..  Test Loss: 0.024.. \n",
      "Epoch: 43/100..  Training Loss: 0.024..  Test Loss: 0.023.. \n",
      "Epoch: 44/100..  Training Loss: 0.023..  Test Loss: 0.023.. \n",
      "Epoch: 45/100..  Training Loss: 0.023..  Test Loss: 0.023.. \n",
      "Epoch: 46/100..  Training Loss: 0.022..  Test Loss: 0.022.. \n",
      "Epoch: 47/100..  Training Loss: 0.022..  Test Loss: 0.022.. \n",
      "Epoch: 48/100..  Training Loss: 0.022..  Test Loss: 0.022.. \n",
      "Epoch: 49/100..  Training Loss: 0.021..  Test Loss: 0.021.. \n",
      "Epoch: 50/100..  Training Loss: 0.021..  Test Loss: 0.021.. \n",
      "Epoch: 51/100..  Training Loss: 0.021..  Test Loss: 0.021.. \n",
      "Epoch: 52/100..  Training Loss: 0.021..  Test Loss: 0.020.. \n",
      "Epoch: 53/100..  Training Loss: 0.020..  Test Loss: 0.020.. \n",
      "Epoch: 54/100..  Training Loss: 0.020..  Test Loss: 0.020.. \n",
      "Epoch: 55/100..  Training Loss: 0.020..  Test Loss: 0.020.. \n",
      "Epoch: 56/100..  Training Loss: 0.020..  Test Loss: 0.019.. \n",
      "Epoch: 57/100..  Training Loss: 0.019..  Test Loss: 0.019.. \n",
      "Epoch: 58/100..  Training Loss: 0.019..  Test Loss: 0.019.. \n",
      "Epoch: 59/100..  Training Loss: 0.019..  Test Loss: 0.019.. \n",
      "Epoch: 60/100..  Training Loss: 0.019..  Test Loss: 0.019.. \n",
      "Epoch: 61/100..  Training Loss: 0.019..  Test Loss: 0.018.. \n",
      "Epoch: 62/100..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 63/100..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 64/100..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 65/100..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 66/100..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 67/100..  Training Loss: 0.018..  Test Loss: 0.017.. \n",
      "Epoch: 68/100..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 69/100..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 70/100..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 71/100..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 72/100..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 73/100..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 74/100..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 75/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 76/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 77/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 78/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 79/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 80/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 81/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 82/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 83/100..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 84/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 85/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 86/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 87/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 88/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 89/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 90/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 91/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 92/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 93/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 94/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 95/100..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 96/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 97/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 98/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 99/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 100/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Classifier used here is : 2-layered\n",
      "Correct benign is 9582 \n",
      " correct malicious is 8773 \n",
      " converted to benign is  2669\n",
      "   bits_flipped    TP    TN    FN\n",
      "0             0  8773  9582  2669\n",
      "1             1  8773  9582  2669\n",
      "2             2  8773  9582  2669\n",
      "3             3  8773  9582  2669\n",
      "4             4  8773  9582  2669\n",
      "5             5  8773  9582  2669\n",
      "6             6  8773  9582  2669\n",
      "7             7  8773  9582  2669\n",
      "8             8  8773  9582  2669\n",
      "9             9  8773  9582  2669\n",
      "10           10  8773  9582  2669\n",
      "This is training the neural network classifier for temperature 10\n",
      "Epoch: 1/50..  Training Loss: 0.678..  Test Loss: 0.663..  Test Accuracy: 0.793\n",
      "Epoch: 2/50..  Training Loss: 0.651..  Test Loss: 0.639..  Test Accuracy: 0.801\n",
      "Epoch: 3/50..  Training Loss: 0.628..  Test Loss: 0.618..  Test Accuracy: 0.801\n",
      "Epoch: 4/50..  Training Loss: 0.610..  Test Loss: 0.601..  Test Accuracy: 0.801\n",
      "Epoch: 5/50..  Training Loss: 0.594..  Test Loss: 0.588..  Test Accuracy: 0.801\n",
      "Epoch: 6/50..  Training Loss: 0.582..  Test Loss: 0.576..  Test Accuracy: 0.802\n",
      "Epoch: 7/50..  Training Loss: 0.571..  Test Loss: 0.567..  Test Accuracy: 0.802\n",
      "Epoch: 8/50..  Training Loss: 0.562..  Test Loss: 0.559..  Test Accuracy: 0.802\n",
      "Epoch: 9/50..  Training Loss: 0.555..  Test Loss: 0.552..  Test Accuracy: 0.803\n",
      "Epoch: 10/50..  Training Loss: 0.549..  Test Loss: 0.546..  Test Accuracy: 0.802\n",
      "Epoch: 11/50..  Training Loss: 0.544..  Test Loss: 0.541..  Test Accuracy: 0.802\n",
      "Epoch: 12/50..  Training Loss: 0.539..  Test Loss: 0.537..  Test Accuracy: 0.801\n",
      "Epoch: 13/50..  Training Loss: 0.535..  Test Loss: 0.533..  Test Accuracy: 0.802\n",
      "Epoch: 14/50..  Training Loss: 0.532..  Test Loss: 0.530..  Test Accuracy: 0.803\n",
      "Epoch: 15/50..  Training Loss: 0.529..  Test Loss: 0.528..  Test Accuracy: 0.803\n",
      "Epoch: 16/50..  Training Loss: 0.526..  Test Loss: 0.526..  Test Accuracy: 0.804\n",
      "Epoch: 17/50..  Training Loss: 0.524..  Test Loss: 0.523..  Test Accuracy: 0.804\n",
      "Epoch: 18/50..  Training Loss: 0.522..  Test Loss: 0.521..  Test Accuracy: 0.805\n",
      "Epoch: 19/50..  Training Loss: 0.521..  Test Loss: 0.520..  Test Accuracy: 0.805\n",
      "Epoch: 20/50..  Training Loss: 0.519..  Test Loss: 0.519..  Test Accuracy: 0.805\n",
      "Epoch: 21/50..  Training Loss: 0.518..  Test Loss: 0.517..  Test Accuracy: 0.805\n",
      "Epoch: 22/50..  Training Loss: 0.517..  Test Loss: 0.516..  Test Accuracy: 0.806\n",
      "Epoch: 23/50..  Training Loss: 0.516..  Test Loss: 0.515..  Test Accuracy: 0.806\n",
      "Epoch: 24/50..  Training Loss: 0.515..  Test Loss: 0.514..  Test Accuracy: 0.806\n",
      "Epoch: 25/50..  Training Loss: 0.514..  Test Loss: 0.513..  Test Accuracy: 0.806\n",
      "Epoch: 26/50..  Training Loss: 0.513..  Test Loss: 0.513..  Test Accuracy: 0.806\n",
      "Epoch: 27/50..  Training Loss: 0.512..  Test Loss: 0.512..  Test Accuracy: 0.806\n",
      "Epoch: 28/50..  Training Loss: 0.512..  Test Loss: 0.511..  Test Accuracy: 0.806\n",
      "Epoch: 29/50..  Training Loss: 0.511..  Test Loss: 0.511..  Test Accuracy: 0.807\n",
      "Epoch: 30/50..  Training Loss: 0.510..  Test Loss: 0.510..  Test Accuracy: 0.807\n",
      "Epoch: 31/50..  Training Loss: 0.510..  Test Loss: 0.509..  Test Accuracy: 0.807\n",
      "Epoch: 32/50..  Training Loss: 0.509..  Test Loss: 0.509..  Test Accuracy: 0.807\n",
      "Epoch: 33/50..  Training Loss: 0.509..  Test Loss: 0.509..  Test Accuracy: 0.807\n",
      "Epoch: 34/50..  Training Loss: 0.508..  Test Loss: 0.508..  Test Accuracy: 0.808\n",
      "Epoch: 35/50..  Training Loss: 0.508..  Test Loss: 0.508..  Test Accuracy: 0.808\n",
      "Epoch: 36/50..  Training Loss: 0.508..  Test Loss: 0.507..  Test Accuracy: 0.808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37/50..  Training Loss: 0.507..  Test Loss: 0.507..  Test Accuracy: 0.808\n",
      "Epoch: 38/50..  Training Loss: 0.507..  Test Loss: 0.507..  Test Accuracy: 0.808\n",
      "Epoch: 39/50..  Training Loss: 0.506..  Test Loss: 0.506..  Test Accuracy: 0.808\n",
      "Epoch: 40/50..  Training Loss: 0.507..  Test Loss: 0.506..  Test Accuracy: 0.808\n",
      "Epoch: 41/50..  Training Loss: 0.506..  Test Loss: 0.506..  Test Accuracy: 0.808\n",
      "Epoch: 42/50..  Training Loss: 0.506..  Test Loss: 0.506..  Test Accuracy: 0.808\n",
      "Epoch: 43/50..  Training Loss: 0.505..  Test Loss: 0.505..  Test Accuracy: 0.808\n",
      "Epoch: 44/50..  Training Loss: 0.505..  Test Loss: 0.505..  Test Accuracy: 0.808\n",
      "Epoch: 45/50..  Training Loss: 0.505..  Test Loss: 0.505..  Test Accuracy: 0.808\n",
      "Epoch: 46/50..  Training Loss: 0.505..  Test Loss: 0.505..  Test Accuracy: 0.807\n",
      "Epoch: 47/50..  Training Loss: 0.504..  Test Loss: 0.504..  Test Accuracy: 0.808\n",
      "Epoch: 48/50..  Training Loss: 0.504..  Test Loss: 0.504..  Test Accuracy: 0.808\n",
      "Epoch: 49/50..  Training Loss: 0.504..  Test Loss: 0.504..  Test Accuracy: 0.808\n",
      "Epoch: 50/50..  Training Loss: 0.504..  Test Loss: 0.504..  Test Accuracy: 0.808\n",
      "The length of the dataset is 22884\n",
      "Shape of X is (22884, 273) and shape of y_probs is (22884, 2)\n",
      "Epoch: 1/100..  Training Loss: 0.187..  Test Loss: 0.184.. \n",
      "Epoch: 2/100..  Training Loss: 0.181..  Test Loss: 0.178.. \n",
      "Epoch: 3/100..  Training Loss: 0.175..  Test Loss: 0.173.. \n",
      "Epoch: 4/100..  Training Loss: 0.170..  Test Loss: 0.167.. \n",
      "Epoch: 5/100..  Training Loss: 0.165..  Test Loss: 0.162.. \n",
      "Epoch: 6/100..  Training Loss: 0.160..  Test Loss: 0.157.. \n",
      "Epoch: 7/100..  Training Loss: 0.155..  Test Loss: 0.153.. \n",
      "Epoch: 8/100..  Training Loss: 0.150..  Test Loss: 0.148.. \n",
      "Epoch: 9/100..  Training Loss: 0.146..  Test Loss: 0.144.. \n",
      "Epoch: 10/100..  Training Loss: 0.142..  Test Loss: 0.139.. \n",
      "Epoch: 11/100..  Training Loss: 0.137..  Test Loss: 0.135.. \n",
      "Epoch: 12/100..  Training Loss: 0.133..  Test Loss: 0.132.. \n",
      "Epoch: 13/100..  Training Loss: 0.130..  Test Loss: 0.128.. \n",
      "Epoch: 14/100..  Training Loss: 0.126..  Test Loss: 0.124.. \n",
      "Epoch: 15/100..  Training Loss: 0.123..  Test Loss: 0.121.. \n",
      "Epoch: 16/100..  Training Loss: 0.119..  Test Loss: 0.117.. \n",
      "Epoch: 17/100..  Training Loss: 0.116..  Test Loss: 0.114.. \n",
      "Epoch: 18/100..  Training Loss: 0.113..  Test Loss: 0.111.. \n",
      "Epoch: 19/100..  Training Loss: 0.110..  Test Loss: 0.108.. \n",
      "Epoch: 20/100..  Training Loss: 0.107..  Test Loss: 0.105.. \n",
      "Epoch: 21/100..  Training Loss: 0.104..  Test Loss: 0.103.. \n",
      "Epoch: 22/100..  Training Loss: 0.101..  Test Loss: 0.100.. \n",
      "Epoch: 23/100..  Training Loss: 0.099..  Test Loss: 0.098.. \n",
      "Epoch: 24/100..  Training Loss: 0.096..  Test Loss: 0.095.. \n",
      "Epoch: 25/100..  Training Loss: 0.094..  Test Loss: 0.093.. \n",
      "Epoch: 26/100..  Training Loss: 0.092..  Test Loss: 0.091.. \n",
      "Epoch: 27/100..  Training Loss: 0.090..  Test Loss: 0.088.. \n",
      "Epoch: 28/100..  Training Loss: 0.087..  Test Loss: 0.086.. \n",
      "Epoch: 29/100..  Training Loss: 0.085..  Test Loss: 0.084.. \n",
      "Epoch: 30/100..  Training Loss: 0.083..  Test Loss: 0.082.. \n",
      "Epoch: 31/100..  Training Loss: 0.082..  Test Loss: 0.081.. \n",
      "Epoch: 32/100..  Training Loss: 0.080..  Test Loss: 0.079.. \n",
      "Epoch: 33/100..  Training Loss: 0.078..  Test Loss: 0.077.. \n",
      "Epoch: 34/100..  Training Loss: 0.076..  Test Loss: 0.075.. \n",
      "Epoch: 35/100..  Training Loss: 0.075..  Test Loss: 0.074.. \n",
      "Epoch: 36/100..  Training Loss: 0.073..  Test Loss: 0.072.. \n",
      "Epoch: 37/100..  Training Loss: 0.071..  Test Loss: 0.071.. \n",
      "Epoch: 38/100..  Training Loss: 0.070..  Test Loss: 0.069.. \n",
      "Epoch: 39/100..  Training Loss: 0.069..  Test Loss: 0.068.. \n",
      "Epoch: 40/100..  Training Loss: 0.067..  Test Loss: 0.067.. \n",
      "Epoch: 41/100..  Training Loss: 0.066..  Test Loss: 0.065.. \n",
      "Epoch: 42/100..  Training Loss: 0.065..  Test Loss: 0.064.. \n",
      "Epoch: 43/100..  Training Loss: 0.063..  Test Loss: 0.063.. \n",
      "Epoch: 44/100..  Training Loss: 0.062..  Test Loss: 0.062.. \n",
      "Epoch: 45/100..  Training Loss: 0.061..  Test Loss: 0.060.. \n",
      "Epoch: 46/100..  Training Loss: 0.060..  Test Loss: 0.059.. \n",
      "Epoch: 47/100..  Training Loss: 0.059..  Test Loss: 0.058.. \n",
      "Epoch: 48/100..  Training Loss: 0.058..  Test Loss: 0.057.. \n",
      "Epoch: 49/100..  Training Loss: 0.057..  Test Loss: 0.056.. \n",
      "Epoch: 50/100..  Training Loss: 0.056..  Test Loss: 0.055.. \n",
      "Epoch: 51/100..  Training Loss: 0.055..  Test Loss: 0.054.. \n",
      "Epoch: 52/100..  Training Loss: 0.054..  Test Loss: 0.053.. \n",
      "Epoch: 53/100..  Training Loss: 0.053..  Test Loss: 0.052.. \n",
      "Epoch: 54/100..  Training Loss: 0.052..  Test Loss: 0.051.. \n",
      "Epoch: 55/100..  Training Loss: 0.051..  Test Loss: 0.051.. \n",
      "Epoch: 56/100..  Training Loss: 0.050..  Test Loss: 0.050.. \n",
      "Epoch: 57/100..  Training Loss: 0.049..  Test Loss: 0.049.. \n",
      "Epoch: 58/100..  Training Loss: 0.049..  Test Loss: 0.048.. \n",
      "Epoch: 59/100..  Training Loss: 0.048..  Test Loss: 0.048.. \n",
      "Epoch: 60/100..  Training Loss: 0.047..  Test Loss: 0.047.. \n",
      "Epoch: 61/100..  Training Loss: 0.046..  Test Loss: 0.046.. \n",
      "Epoch: 62/100..  Training Loss: 0.046..  Test Loss: 0.045.. \n",
      "Epoch: 63/100..  Training Loss: 0.045..  Test Loss: 0.045.. \n",
      "Epoch: 64/100..  Training Loss: 0.044..  Test Loss: 0.044.. \n",
      "Epoch: 65/100..  Training Loss: 0.044..  Test Loss: 0.043.. \n",
      "Epoch: 66/100..  Training Loss: 0.043..  Test Loss: 0.043.. \n",
      "Epoch: 67/100..  Training Loss: 0.042..  Test Loss: 0.042.. \n",
      "Epoch: 68/100..  Training Loss: 0.042..  Test Loss: 0.042.. \n",
      "Epoch: 69/100..  Training Loss: 0.041..  Test Loss: 0.041.. \n",
      "Epoch: 70/100..  Training Loss: 0.041..  Test Loss: 0.040.. \n",
      "Epoch: 71/100..  Training Loss: 0.040..  Test Loss: 0.040.. \n",
      "Epoch: 72/100..  Training Loss: 0.040..  Test Loss: 0.039.. \n",
      "Epoch: 73/100..  Training Loss: 0.039..  Test Loss: 0.039.. \n",
      "Epoch: 74/100..  Training Loss: 0.039..  Test Loss: 0.038.. \n",
      "Epoch: 75/100..  Training Loss: 0.038..  Test Loss: 0.038.. \n",
      "Epoch: 76/100..  Training Loss: 0.038..  Test Loss: 0.037.. \n",
      "Epoch: 77/100..  Training Loss: 0.037..  Test Loss: 0.037.. \n",
      "Epoch: 78/100..  Training Loss: 0.037..  Test Loss: 0.036.. \n",
      "Epoch: 79/100..  Training Loss: 0.036..  Test Loss: 0.036.. \n",
      "Epoch: 80/100..  Training Loss: 0.036..  Test Loss: 0.036.. \n",
      "Epoch: 81/100..  Training Loss: 0.035..  Test Loss: 0.035.. \n",
      "Epoch: 82/100..  Training Loss: 0.035..  Test Loss: 0.035.. \n",
      "Epoch: 83/100..  Training Loss: 0.034..  Test Loss: 0.034.. \n",
      "Epoch: 84/100..  Training Loss: 0.034..  Test Loss: 0.034.. \n",
      "Epoch: 85/100..  Training Loss: 0.034..  Test Loss: 0.034.. \n",
      "Epoch: 86/100..  Training Loss: 0.033..  Test Loss: 0.033.. \n",
      "Epoch: 87/100..  Training Loss: 0.033..  Test Loss: 0.033.. \n",
      "Epoch: 88/100..  Training Loss: 0.033..  Test Loss: 0.032.. \n",
      "Epoch: 89/100..  Training Loss: 0.032..  Test Loss: 0.032.. \n",
      "Epoch: 90/100..  Training Loss: 0.032..  Test Loss: 0.032.. \n",
      "Epoch: 91/100..  Training Loss: 0.031..  Test Loss: 0.031.. \n",
      "Epoch: 92/100..  Training Loss: 0.031..  Test Loss: 0.031.. \n",
      "Epoch: 93/100..  Training Loss: 0.031..  Test Loss: 0.031.. \n",
      "Epoch: 94/100..  Training Loss: 0.031..  Test Loss: 0.030.. \n",
      "Epoch: 95/100..  Training Loss: 0.030..  Test Loss: 0.030.. \n",
      "Epoch: 96/100..  Training Loss: 0.030..  Test Loss: 0.030.. \n",
      "Epoch: 97/100..  Training Loss: 0.030..  Test Loss: 0.029.. \n",
      "Epoch: 98/100..  Training Loss: 0.029..  Test Loss: 0.029.. \n",
      "Epoch: 99/100..  Training Loss: 0.029..  Test Loss: 0.029.. \n",
      "Epoch: 100/100..  Training Loss: 0.029..  Test Loss: 0.029.. \n",
      "Classifier used here is : 2-layered\n",
      "Correct benign is 9582 \n",
      " correct malicious is 8773 \n",
      " converted to benign is  2669\n",
      "   bits_flipped    TP    TN    FN\n",
      "0             0  8773  9582  2669\n",
      "1             1  8773  9582  2669\n",
      "2             2  8773  9582  2669\n",
      "3             3  8773  9582  2669\n",
      "4             4  8773  9582  2669\n",
      "5             5  8773  9582  2669\n",
      "6             6  8773  9582  2669\n",
      "7             7  8773  9582  2669\n",
      "8             8  8773  9582  2669\n",
      "9             9  8773  9582  2669\n",
      "10           10  8773  9582  2669\n"
     ]
    }
   ],
   "source": [
    "for t in [1, 5,10]:\n",
    "    epochs=50\n",
    "    \n",
    "    print(\"This is training the neural network classifier for temperature {}\".format(t))\n",
    "    \n",
    "    model_class= model_2(t)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model_class.parameters(), lr=0.001)\n",
    "    \n",
    "    \n",
    "    df=pd.read_csv('../Resampled_Datasets_Attack/2-Layer'+'_resamp.csv')\n",
    "    X=df.iloc[:,:-1].values\n",
    "    y=df.iloc[:,-1].values\n",
    "    \n",
    "    train_dataset = Datasetcustom(X, y)\n",
    "    test_dataset = Datasetcustom(X, y)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=20, shuffle=True)\n",
    "\n",
    "    train_losses, test_losses = [], []\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            log_ps = model_class(images)\n",
    "    #         print(log_ps)\n",
    "            loss = criterion(log_ps, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        else:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "\n",
    "            # Turn off gradients for validation, saves memory and computations\n",
    "            with torch.no_grad():\n",
    "                for images, labels in test_loader:\n",
    "                    log_ps = model_class(images)\n",
    "                    test_loss += criterion(log_ps, labels)\n",
    "\n",
    "                    top_p, top_class = log_ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "            train_losses.append(running_loss/len(train_loader))\n",
    "            test_losses.append(test_loss/len(test_loader))\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))\n",
    "            \n",
    "    print(\"The length of the dataset is {}\".format(len(train_dataset)))\n",
    "    probs_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True)\n",
    "    train_iter = iter(probs_loader)\n",
    "    images, labels = train_iter.next()\n",
    "    y_probs= model_class(images)\n",
    "    y_probs=y_probs.detach().numpy()\n",
    "    X_probs=images.detach().numpy()\n",
    "    \n",
    "    print(\"Shape of X is {} and shape of y_probs is {}\".format(X.shape, y_probs.shape))\n",
    "    X_train, X_test, y_train, y_test =X_probs,X_probs,  y_probs ,  y_probs\n",
    "    \n",
    "    train_dataset_dist = Datasetcustom(X_train, y_train)\n",
    "    test_dataset_dist= Datasetcustom(X_test, y_test)\n",
    "    train_loader_dist = DataLoader(train_dataset_dist, batch_size=20, shuffle=True)\n",
    "    test_loader_dist = DataLoader(test_dataset_dist, batch_size=20, shuffle=True)\n",
    "    \n",
    "    model_reg=model_2dist(t)\n",
    "    criterion_dist =  nn.MSELoss()\n",
    "    optimizer_dist = optim.SGD(model_reg.parameters(), lr=0.02)\n",
    "\n",
    "    epochs= 100\n",
    "    train_losses, test_losses = [], []\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        for images, labels in train_loader_dist:\n",
    "\n",
    "            optimizer_dist.zero_grad()\n",
    "            log_ps = model_reg(images)\n",
    "            loss = criterion_dist(log_ps, labels)\n",
    "            loss.backward()\n",
    "            optimizer_dist.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        else:\n",
    "            test_loss = 0\n",
    "\n",
    "            # Turn off gradients for validation, saves memory and computations\n",
    "            with torch.no_grad():\n",
    "                for images, labels in test_loader_dist:\n",
    "                    log_ps = model_reg(images)\n",
    "                    test_loss += criterion_dist(log_ps, labels)\n",
    "\n",
    "            train_losses.append(running_loss/len(train_loader_dist))\n",
    "            test_losses.append(test_loss/len(test_loader_dist))\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader_dist)),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader_dist)))\n",
    "    \n",
    "    Models={ \"2-layered\": model_reg}\n",
    "    model=torch.load('../trained_models/Train-512-256-64.pth')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    #Attack with original attacker after retraining\n",
    "    for Algorithm in Models:\n",
    "            df1=pd.DataFrame(columns = ['bits_flipped','TP', 'TN','FN'])\n",
    "            for i in range(0,11):\n",
    "                df1=df1.append(pd.Series([i, 11442, 0, 0], index= df1.columns), ignore_index=True )\n",
    "            print(\"Classifier used here is : {}\".format(Algorithm))\n",
    "            classifier= Models[Algorithm]\n",
    "            correct_benign=0\n",
    "            correct_malicious=0\n",
    "            convert_to_benign=0\n",
    "            \n",
    "            df=pd.read_csv('../Resampled_Datasets_Attack/2-Layer'+'_resamp.csv')\n",
    "            X=df.iloc[:,:-1].values\n",
    "            y=df.iloc[:,-1].values\n",
    "            \n",
    "            target_model= Models[Algorithm]\n",
    "            test_dataset= Datasetcustom(X, y)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "            for images, labels in test_loader:\n",
    "                images.requires_grad = True\n",
    "                model.zero_grad()\n",
    "                output = model(images)\n",
    "                y_pred = target_model(images)\n",
    "                loss = criterion(output, labels)\n",
    "                loss.backward()\n",
    "                data_grad = images.grad.data\n",
    "                if  y_pred[0][1]>y_pred[0][0] and labels[0]==1: #predicted malicious\n",
    "                    grad_list=[]\n",
    "                    for i in range(273):\n",
    "                        if images[0][i]==0:\n",
    "                            grad_list.append((data_grad[0][i],i))\n",
    "                    grad_list.sort(key = lambda x: x[0], reverse=True)\n",
    "                    flag=0\n",
    "                    for i in range(0,10):\n",
    "                        images[0][grad_list[i][1]]=1\n",
    "                        y_pred = target_model(images)\n",
    "                        if y_pred[0][0]>y_pred[0][1]:\n",
    "                            for j in range(i,10):  #converted in i+1 flips, hence all bits>=i+1, the FN will increase\n",
    "                                df1.iloc[j+1,3]+=1\n",
    "                                df1.iloc[j+1,1]-=1\n",
    "                            flag=1\n",
    "                            convert_to_benign+=1\n",
    "                            break\n",
    "                    if flag==0:          #Even after 10 flips, unable to convert to benignm update malicious counter\n",
    "                        correct_malicious+=1\n",
    "                elif y_pred[0][0]>y_pred[0][1] and labels[0]==1:  #If predicted as benign but is malicious\n",
    "                    for j in range(0,11):\n",
    "                        df1.iloc[j,3]+=1\n",
    "                        df1.iloc[j,1]-=1\n",
    "                    convert_to_benign+=1\n",
    "                elif  y_pred[0][0]>y_pred[0][1] and labels[0]==0:  #if predicted benign correctly\n",
    "                    for j in range(0,11):\n",
    "                        df1.iloc[j,2]+=1\n",
    "                    correct_benign+=1\n",
    "\n",
    "            print(\"Correct benign is {} \\n correct malicious is {} \\n converted to benign is  {}\".format(correct_benign, correct_malicious, convert_to_benign))\n",
    "    #         print(\"Final Accuracy is {:.3f} with max {} bits flipped\".format((correct_benign+5553-convert_benign)/11274, num_bits))\n",
    "            print(df1)\n",
    "            df1.to_csv(\"../Hybrid_Distillation/\"+str(Algorithm)+\"_Distillation_\"+str(t)+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Layered Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_3(nn.Module):\n",
    "    def __init__(self,t):\n",
    "        super(model_3, self).__init__()\n",
    "        self.t=t\n",
    "        self.l1=nn.Linear(273, 200)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.l2=nn.Linear(200, 200)\n",
    "        self.l3=nn.Linear(200, 2)\n",
    "        self.dropout= nn.Dropout(0.4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.l1(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l2(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l3(x)\n",
    "        x= nn.Softmax(dim=1)(x/self.t)\n",
    "        return x\n",
    "\n",
    "class model_3dist(nn.Module):\n",
    "    def __init__(self,t):\n",
    "        super(model_3dist, self).__init__()\n",
    "        self.t=t\n",
    "        self.l1=nn.Linear(273, 200)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.l2=nn.Linear(200, 200)\n",
    "        self.l3=nn.Linear(200, 2)\n",
    "        self.dropout= nn.Dropout(0.4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.l1(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l2(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l3(x)\n",
    "        x= nn.Softmax(dim=1)(x/self.t)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is training the neural network classifier for temperature 1\n",
      "Epoch: 1/50..  Training Loss: 0.500..  Test Loss: 0.486..  Test Accuracy: 0.826\n",
      "Epoch: 2/50..  Training Loss: 0.483..  Test Loss: 0.481..  Test Accuracy: 0.831\n",
      "Epoch: 3/50..  Training Loss: 0.479..  Test Loss: 0.475..  Test Accuracy: 0.838\n",
      "Epoch: 4/50..  Training Loss: 0.477..  Test Loss: 0.473..  Test Accuracy: 0.841\n",
      "Epoch: 5/50..  Training Loss: 0.472..  Test Loss: 0.471..  Test Accuracy: 0.842\n",
      "Epoch: 6/50..  Training Loss: 0.472..  Test Loss: 0.477..  Test Accuracy: 0.835\n",
      "Epoch: 7/50..  Training Loss: 0.471..  Test Loss: 0.467..  Test Accuracy: 0.846\n",
      "Epoch: 8/50..  Training Loss: 0.467..  Test Loss: 0.465..  Test Accuracy: 0.847\n",
      "Epoch: 9/50..  Training Loss: 0.466..  Test Loss: 0.466..  Test Accuracy: 0.846\n",
      "Epoch: 10/50..  Training Loss: 0.465..  Test Loss: 0.465..  Test Accuracy: 0.848\n",
      "Epoch: 11/50..  Training Loss: 0.465..  Test Loss: 0.463..  Test Accuracy: 0.849\n",
      "Epoch: 12/50..  Training Loss: 0.463..  Test Loss: 0.463..  Test Accuracy: 0.849\n",
      "Epoch: 13/50..  Training Loss: 0.463..  Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 14/50..  Training Loss: 0.463..  Test Loss: 0.462..  Test Accuracy: 0.850\n",
      "Epoch: 15/50..  Training Loss: 0.462..  Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 16/50..  Training Loss: 0.462..  Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 17/50..  Training Loss: 0.461..  Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 18/50..  Training Loss: 0.462..  Test Loss: 0.461..  Test Accuracy: 0.852\n",
      "Epoch: 19/50..  Training Loss: 0.462..  Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 20/50..  Training Loss: 0.460..  Test Loss: 0.459..  Test Accuracy: 0.854\n",
      "Epoch: 21/50..  Training Loss: 0.461..  Test Loss: 0.460..  Test Accuracy: 0.852\n",
      "Epoch: 22/50..  Training Loss: 0.460..  Test Loss: 0.459..  Test Accuracy: 0.854\n",
      "Epoch: 23/50..  Training Loss: 0.460..  Test Loss: 0.458..  Test Accuracy: 0.854\n",
      "Epoch: 24/50..  Training Loss: 0.458..  Test Loss: 0.458..  Test Accuracy: 0.854\n",
      "Epoch: 25/50..  Training Loss: 0.458..  Test Loss: 0.458..  Test Accuracy: 0.854\n",
      "Epoch: 26/50..  Training Loss: 0.459..  Test Loss: 0.457..  Test Accuracy: 0.854\n",
      "Epoch: 27/50..  Training Loss: 0.457..  Test Loss: 0.456..  Test Accuracy: 0.855\n",
      "Epoch: 28/50..  Training Loss: 0.458..  Test Loss: 0.456..  Test Accuracy: 0.856\n",
      "Epoch: 29/50..  Training Loss: 0.457..  Test Loss: 0.457..  Test Accuracy: 0.855\n",
      "Epoch: 30/50..  Training Loss: 0.457..  Test Loss: 0.457..  Test Accuracy: 0.855\n",
      "Epoch: 31/50..  Training Loss: 0.458..  Test Loss: 0.457..  Test Accuracy: 0.854\n",
      "Epoch: 32/50..  Training Loss: 0.458..  Test Loss: 0.455..  Test Accuracy: 0.857\n",
      "Epoch: 33/50..  Training Loss: 0.456..  Test Loss: 0.455..  Test Accuracy: 0.857\n",
      "Epoch: 34/50..  Training Loss: 0.456..  Test Loss: 0.456..  Test Accuracy: 0.856\n",
      "Epoch: 35/50..  Training Loss: 0.456..  Test Loss: 0.456..  Test Accuracy: 0.856\n",
      "Epoch: 36/50..  Training Loss: 0.457..  Test Loss: 0.457..  Test Accuracy: 0.855\n",
      "Epoch: 37/50..  Training Loss: 0.456..  Test Loss: 0.456..  Test Accuracy: 0.856\n",
      "Epoch: 38/50..  Training Loss: 0.456..  Test Loss: 0.456..  Test Accuracy: 0.856\n",
      "Epoch: 39/50..  Training Loss: 0.457..  Test Loss: 0.457..  Test Accuracy: 0.855\n",
      "Epoch: 40/50..  Training Loss: 0.457..  Test Loss: 0.456..  Test Accuracy: 0.855\n",
      "Epoch: 41/50..  Training Loss: 0.455..  Test Loss: 0.455..  Test Accuracy: 0.857\n",
      "Epoch: 42/50..  Training Loss: 0.455..  Test Loss: 0.455..  Test Accuracy: 0.857\n",
      "Epoch: 43/50..  Training Loss: 0.455..  Test Loss: 0.454..  Test Accuracy: 0.858\n",
      "Epoch: 44/50..  Training Loss: 0.454..  Test Loss: 0.456..  Test Accuracy: 0.856\n",
      "Epoch: 45/50..  Training Loss: 0.457..  Test Loss: 0.459..  Test Accuracy: 0.853\n",
      "Epoch: 46/50..  Training Loss: 0.456..  Test Loss: 0.454..  Test Accuracy: 0.858\n",
      "Epoch: 47/50..  Training Loss: 0.455..  Test Loss: 0.455..  Test Accuracy: 0.856\n",
      "Epoch: 48/50..  Training Loss: 0.455..  Test Loss: 0.454..  Test Accuracy: 0.858\n",
      "Epoch: 49/50..  Training Loss: 0.454..  Test Loss: 0.454..  Test Accuracy: 0.857\n",
      "Epoch: 50/50..  Training Loss: 0.455..  Test Loss: 0.453..  Test Accuracy: 0.859\n",
      "The length of the dataset is 22884\n",
      "Shape of X is (22884, 273) and shape of y_probs is (22884, 2)\n",
      "Epoch: 1/100..  Training Loss: 0.171..  Test Loss: 0.069.. \n",
      "Epoch: 2/100..  Training Loss: 0.057..  Test Loss: 0.053.. \n",
      "Epoch: 3/100..  Training Loss: 0.051..  Test Loss: 0.050.. \n",
      "Epoch: 4/100..  Training Loss: 0.049..  Test Loss: 0.047.. \n",
      "Epoch: 5/100..  Training Loss: 0.047..  Test Loss: 0.045.. \n",
      "Epoch: 6/100..  Training Loss: 0.044..  Test Loss: 0.043.. \n",
      "Epoch: 7/100..  Training Loss: 0.042..  Test Loss: 0.041.. \n",
      "Epoch: 8/100..  Training Loss: 0.040..  Test Loss: 0.039.. \n",
      "Epoch: 9/100..  Training Loss: 0.037..  Test Loss: 0.036.. \n",
      "Epoch: 10/100..  Training Loss: 0.035..  Test Loss: 0.034.. \n",
      "Epoch: 11/100..  Training Loss: 0.034..  Test Loss: 0.032.. \n",
      "Epoch: 12/100..  Training Loss: 0.031..  Test Loss: 0.030.. \n",
      "Epoch: 13/100..  Training Loss: 0.028..  Test Loss: 0.027.. \n",
      "Epoch: 14/100..  Training Loss: 0.027..  Test Loss: 0.025.. \n",
      "Epoch: 15/100..  Training Loss: 0.025..  Test Loss: 0.024.. \n",
      "Epoch: 16/100..  Training Loss: 0.023..  Test Loss: 0.023.. \n",
      "Epoch: 17/100..  Training Loss: 0.023..  Test Loss: 0.022.. \n",
      "Epoch: 18/100..  Training Loss: 0.022..  Test Loss: 0.020.. \n",
      "Epoch: 19/100..  Training Loss: 0.020..  Test Loss: 0.020.. \n",
      "Epoch: 20/100..  Training Loss: 0.019..  Test Loss: 0.019.. \n",
      "Epoch: 21/100..  Training Loss: 0.018..  Test Loss: 0.017.. \n",
      "Epoch: 22/100..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 23/100..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 24/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 25/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 26/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 27/100..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 28/100..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 29/100..  Training Loss: 0.013..  Test Loss: 0.014.. \n",
      "Epoch: 30/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 31/100..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 32/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 33/100..  Training Loss: 0.013..  Test Loss: 0.011.. \n",
      "Epoch: 34/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 35/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 36/100..  Training Loss: 0.012..  Test Loss: 0.011.. \n",
      "Epoch: 37/100..  Training Loss: 0.012..  Test Loss: 0.011.. \n",
      "Epoch: 38/100..  Training Loss: 0.012..  Test Loss: 0.010.. \n",
      "Epoch: 39/100..  Training Loss: 0.011..  Test Loss: 0.011.. \n",
      "Epoch: 40/100..  Training Loss: 0.011..  Test Loss: 0.010.. \n",
      "Epoch: 41/100..  Training Loss: 0.011..  Test Loss: 0.014.. \n",
      "Epoch: 42/100..  Training Loss: 0.011..  Test Loss: 0.010.. \n",
      "Epoch: 43/100..  Training Loss: 0.010..  Test Loss: 0.010.. \n",
      "Epoch: 44/100..  Training Loss: 0.011..  Test Loss: 0.010.. \n",
      "Epoch: 45/100..  Training Loss: 0.010..  Test Loss: 0.010.. \n",
      "Epoch: 46/100..  Training Loss: 0.010..  Test Loss: 0.009.. \n",
      "Epoch: 47/100..  Training Loss: 0.009..  Test Loss: 0.010.. \n",
      "Epoch: 48/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 49/100..  Training Loss: 0.010..  Test Loss: 0.009.. \n",
      "Epoch: 50/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 51/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 52/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 53/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 54/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 55/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 56/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 57/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 58/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 59/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 60/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 61/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 62/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 63/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 64/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 65/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 66/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 68/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 69/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 70/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 71/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 72/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 73/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 74/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 75/100..  Training Loss: 0.007..  Test Loss: 0.008.. \n",
      "Epoch: 76/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 77/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 78/100..  Training Loss: 0.009..  Test Loss: 0.017.. \n",
      "Epoch: 79/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 80/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 81/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 82/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 83/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 84/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 85/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 86/100..  Training Loss: 0.006..  Test Loss: 0.007.. \n",
      "Epoch: 87/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 88/100..  Training Loss: 0.006..  Test Loss: 0.005.. \n",
      "Epoch: 89/100..  Training Loss: 0.006..  Test Loss: 0.005.. \n",
      "Epoch: 90/100..  Training Loss: 0.006..  Test Loss: 0.005.. \n",
      "Epoch: 91/100..  Training Loss: 0.006..  Test Loss: 0.005.. \n",
      "Epoch: 92/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 93/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 94/100..  Training Loss: 0.006..  Test Loss: 0.005.. \n",
      "Epoch: 95/100..  Training Loss: 0.005..  Test Loss: 0.005.. \n",
      "Epoch: 96/100..  Training Loss: 0.005..  Test Loss: 0.006.. \n",
      "Epoch: 97/100..  Training Loss: 0.005..  Test Loss: 0.006.. \n",
      "Epoch: 98/100..  Training Loss: 0.005..  Test Loss: 0.006.. \n",
      "Epoch: 99/100..  Training Loss: 0.006..  Test Loss: 0.005.. \n",
      "Epoch: 100/100..  Training Loss: 0.005..  Test Loss: 0.005.. \n",
      "Classifier used here is : 3-layered\n",
      "Correct benign is 10453 \n",
      " correct malicious is 7936 \n",
      " converted to benign is  3506\n",
      "   bits_flipped    TP     TN    FN\n",
      "0             0  9120  10453  2322\n",
      "1             1  9013  10453  2429\n",
      "2             2  8802  10453  2640\n",
      "3             3  8646  10453  2796\n",
      "4             4  8557  10453  2885\n",
      "5             5  8456  10453  2986\n",
      "6             6  8330  10453  3112\n",
      "7             7  8219  10453  3223\n",
      "8             8  8129  10453  3313\n",
      "9             9  8025  10453  3417\n",
      "10           10  7936  10453  3506\n",
      "This is training the neural network classifier for temperature 5\n",
      "Epoch: 1/50..  Training Loss: 0.504..  Test Loss: 0.482..  Test Accuracy: 0.831\n",
      "Epoch: 2/50..  Training Loss: 0.482..  Test Loss: 0.483..  Test Accuracy: 0.830\n",
      "Epoch: 3/50..  Training Loss: 0.478..  Test Loss: 0.476..  Test Accuracy: 0.837\n",
      "Epoch: 4/50..  Training Loss: 0.476..  Test Loss: 0.473..  Test Accuracy: 0.840\n",
      "Epoch: 5/50..  Training Loss: 0.473..  Test Loss: 0.475..  Test Accuracy: 0.838\n",
      "Epoch: 6/50..  Training Loss: 0.471..  Test Loss: 0.469..  Test Accuracy: 0.843\n",
      "Epoch: 7/50..  Training Loss: 0.469..  Test Loss: 0.468..  Test Accuracy: 0.845\n",
      "Epoch: 8/50..  Training Loss: 0.468..  Test Loss: 0.469..  Test Accuracy: 0.843\n",
      "Epoch: 9/50..  Training Loss: 0.466..  Test Loss: 0.465..  Test Accuracy: 0.848\n",
      "Epoch: 10/50..  Training Loss: 0.464..  Test Loss: 0.464..  Test Accuracy: 0.848\n",
      "Epoch: 11/50..  Training Loss: 0.464..  Test Loss: 0.463..  Test Accuracy: 0.848\n",
      "Epoch: 12/50..  Training Loss: 0.463..  Test Loss: 0.462..  Test Accuracy: 0.850\n",
      "Epoch: 13/50..  Training Loss: 0.462..  Test Loss: 0.462..  Test Accuracy: 0.851\n",
      "Epoch: 14/50..  Training Loss: 0.463..  Test Loss: 0.460..  Test Accuracy: 0.852\n",
      "Epoch: 15/50..  Training Loss: 0.461..  Test Loss: 0.461..  Test Accuracy: 0.852\n",
      "Epoch: 16/50..  Training Loss: 0.461..  Test Loss: 0.460..  Test Accuracy: 0.852\n",
      "Epoch: 17/50..  Training Loss: 0.461..  Test Loss: 0.459..  Test Accuracy: 0.852\n",
      "Epoch: 18/50..  Training Loss: 0.461..  Test Loss: 0.458..  Test Accuracy: 0.853\n",
      "Epoch: 19/50..  Training Loss: 0.460..  Test Loss: 0.459..  Test Accuracy: 0.853\n",
      "Epoch: 20/50..  Training Loss: 0.459..  Test Loss: 0.460..  Test Accuracy: 0.853\n",
      "Epoch: 21/50..  Training Loss: 0.459..  Test Loss: 0.458..  Test Accuracy: 0.853\n",
      "Epoch: 22/50..  Training Loss: 0.459..  Test Loss: 0.459..  Test Accuracy: 0.853\n",
      "Epoch: 23/50..  Training Loss: 0.459..  Test Loss: 0.459..  Test Accuracy: 0.853\n",
      "Epoch: 24/50..  Training Loss: 0.459..  Test Loss: 0.458..  Test Accuracy: 0.854\n",
      "Epoch: 25/50..  Training Loss: 0.459..  Test Loss: 0.458..  Test Accuracy: 0.854\n",
      "Epoch: 26/50..  Training Loss: 0.459..  Test Loss: 0.460..  Test Accuracy: 0.852\n",
      "Epoch: 27/50..  Training Loss: 0.458..  Test Loss: 0.457..  Test Accuracy: 0.855\n",
      "Epoch: 28/50..  Training Loss: 0.457..  Test Loss: 0.456..  Test Accuracy: 0.856\n",
      "Epoch: 29/50..  Training Loss: 0.456..  Test Loss: 0.456..  Test Accuracy: 0.856\n",
      "Epoch: 30/50..  Training Loss: 0.457..  Test Loss: 0.457..  Test Accuracy: 0.855\n",
      "Epoch: 31/50..  Training Loss: 0.456..  Test Loss: 0.455..  Test Accuracy: 0.857\n",
      "Epoch: 32/50..  Training Loss: 0.455..  Test Loss: 0.455..  Test Accuracy: 0.858\n",
      "Epoch: 33/50..  Training Loss: 0.455..  Test Loss: 0.455..  Test Accuracy: 0.857\n",
      "Epoch: 34/50..  Training Loss: 0.455..  Test Loss: 0.455..  Test Accuracy: 0.857\n",
      "Epoch: 35/50..  Training Loss: 0.456..  Test Loss: 0.455..  Test Accuracy: 0.857\n",
      "Epoch: 36/50..  Training Loss: 0.455..  Test Loss: 0.453..  Test Accuracy: 0.859\n",
      "Epoch: 37/50..  Training Loss: 0.455..  Test Loss: 0.456..  Test Accuracy: 0.855\n",
      "Epoch: 38/50..  Training Loss: 0.455..  Test Loss: 0.454..  Test Accuracy: 0.856\n",
      "Epoch: 39/50..  Training Loss: 0.454..  Test Loss: 0.454..  Test Accuracy: 0.858\n",
      "Epoch: 40/50..  Training Loss: 0.455..  Test Loss: 0.454..  Test Accuracy: 0.858\n",
      "Epoch: 41/50..  Training Loss: 0.455..  Test Loss: 0.454..  Test Accuracy: 0.858\n",
      "Epoch: 42/50..  Training Loss: 0.454..  Test Loss: 0.453..  Test Accuracy: 0.859\n",
      "Epoch: 43/50..  Training Loss: 0.454..  Test Loss: 0.452..  Test Accuracy: 0.860\n",
      "Epoch: 44/50..  Training Loss: 0.454..  Test Loss: 0.455..  Test Accuracy: 0.857\n",
      "Epoch: 45/50..  Training Loss: 0.454..  Test Loss: 0.455..  Test Accuracy: 0.857\n",
      "Epoch: 46/50..  Training Loss: 0.454..  Test Loss: 0.454..  Test Accuracy: 0.858\n",
      "Epoch: 47/50..  Training Loss: 0.454..  Test Loss: 0.453..  Test Accuracy: 0.859\n",
      "Epoch: 48/50..  Training Loss: 0.454..  Test Loss: 0.453..  Test Accuracy: 0.859\n",
      "Epoch: 49/50..  Training Loss: 0.453..  Test Loss: 0.454..  Test Accuracy: 0.859\n",
      "Epoch: 50/50..  Training Loss: 0.454..  Test Loss: 0.453..  Test Accuracy: 0.860\n",
      "The length of the dataset is 22884\n",
      "Shape of X is (22884, 273) and shape of y_probs is (22884, 2)\n",
      "Epoch: 1/100..  Training Loss: 0.242..  Test Loss: 0.240.. \n",
      "Epoch: 2/100..  Training Loss: 0.236..  Test Loss: 0.231.. \n",
      "Epoch: 3/100..  Training Loss: 0.219..  Test Loss: 0.201.. \n",
      "Epoch: 4/100..  Training Loss: 0.160..  Test Loss: 0.113.. \n",
      "Epoch: 5/100..  Training Loss: 0.087..  Test Loss: 0.071.. \n",
      "Epoch: 6/100..  Training Loss: 0.066..  Test Loss: 0.063.. \n",
      "Epoch: 7/100..  Training Loss: 0.061..  Test Loss: 0.060.. \n",
      "Epoch: 8/100..  Training Loss: 0.060..  Test Loss: 0.059.. \n",
      "Epoch: 9/100..  Training Loss: 0.058..  Test Loss: 0.057.. \n",
      "Epoch: 10/100..  Training Loss: 0.057..  Test Loss: 0.057.. \n",
      "Epoch: 11/100..  Training Loss: 0.056..  Test Loss: 0.055.. \n",
      "Epoch: 12/100..  Training Loss: 0.055..  Test Loss: 0.055.. \n",
      "Epoch: 13/100..  Training Loss: 0.054..  Test Loss: 0.054.. \n",
      "Epoch: 14/100..  Training Loss: 0.053..  Test Loss: 0.053.. \n",
      "Epoch: 15/100..  Training Loss: 0.052..  Test Loss: 0.052.. \n",
      "Epoch: 16/100..  Training Loss: 0.051..  Test Loss: 0.051.. \n",
      "Epoch: 17/100..  Training Loss: 0.050..  Test Loss: 0.050.. \n",
      "Epoch: 18/100..  Training Loss: 0.049..  Test Loss: 0.049.. \n",
      "Epoch: 19/100..  Training Loss: 0.048..  Test Loss: 0.048.. \n",
      "Epoch: 20/100..  Training Loss: 0.047..  Test Loss: 0.047.. \n",
      "Epoch: 21/100..  Training Loss: 0.047..  Test Loss: 0.046.. \n",
      "Epoch: 22/100..  Training Loss: 0.046..  Test Loss: 0.045.. \n",
      "Epoch: 23/100..  Training Loss: 0.045..  Test Loss: 0.044.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/100..  Training Loss: 0.044..  Test Loss: 0.043.. \n",
      "Epoch: 25/100..  Training Loss: 0.043..  Test Loss: 0.042.. \n",
      "Epoch: 26/100..  Training Loss: 0.042..  Test Loss: 0.042.. \n",
      "Epoch: 27/100..  Training Loss: 0.041..  Test Loss: 0.040.. \n",
      "Epoch: 28/100..  Training Loss: 0.040..  Test Loss: 0.039.. \n",
      "Epoch: 29/100..  Training Loss: 0.039..  Test Loss: 0.038.. \n",
      "Epoch: 30/100..  Training Loss: 0.038..  Test Loss: 0.037.. \n",
      "Epoch: 31/100..  Training Loss: 0.037..  Test Loss: 0.036.. \n",
      "Epoch: 32/100..  Training Loss: 0.036..  Test Loss: 0.035.. \n",
      "Epoch: 33/100..  Training Loss: 0.035..  Test Loss: 0.034.. \n",
      "Epoch: 34/100..  Training Loss: 0.034..  Test Loss: 0.033.. \n",
      "Epoch: 35/100..  Training Loss: 0.033..  Test Loss: 0.032.. \n",
      "Epoch: 36/100..  Training Loss: 0.032..  Test Loss: 0.031.. \n",
      "Epoch: 37/100..  Training Loss: 0.031..  Test Loss: 0.030.. \n",
      "Epoch: 38/100..  Training Loss: 0.030..  Test Loss: 0.029.. \n",
      "Epoch: 39/100..  Training Loss: 0.029..  Test Loss: 0.029.. \n",
      "Epoch: 40/100..  Training Loss: 0.029..  Test Loss: 0.028.. \n",
      "Epoch: 41/100..  Training Loss: 0.028..  Test Loss: 0.028.. \n",
      "Epoch: 42/100..  Training Loss: 0.027..  Test Loss: 0.027.. \n",
      "Epoch: 43/100..  Training Loss: 0.026..  Test Loss: 0.027.. \n",
      "Epoch: 44/100..  Training Loss: 0.026..  Test Loss: 0.025.. \n",
      "Epoch: 45/100..  Training Loss: 0.026..  Test Loss: 0.026.. \n",
      "Epoch: 46/100..  Training Loss: 0.025..  Test Loss: 0.024.. \n",
      "Epoch: 47/100..  Training Loss: 0.025..  Test Loss: 0.023.. \n",
      "Epoch: 48/100..  Training Loss: 0.024..  Test Loss: 0.023.. \n",
      "Epoch: 49/100..  Training Loss: 0.023..  Test Loss: 0.025.. \n",
      "Epoch: 50/100..  Training Loss: 0.023..  Test Loss: 0.022.. \n",
      "Epoch: 51/100..  Training Loss: 0.022..  Test Loss: 0.023.. \n",
      "Epoch: 52/100..  Training Loss: 0.022..  Test Loss: 0.022.. \n",
      "Epoch: 53/100..  Training Loss: 0.022..  Test Loss: 0.021.. \n",
      "Epoch: 54/100..  Training Loss: 0.021..  Test Loss: 0.021.. \n",
      "Epoch: 55/100..  Training Loss: 0.021..  Test Loss: 0.020.. \n",
      "Epoch: 56/100..  Training Loss: 0.020..  Test Loss: 0.021.. \n",
      "Epoch: 57/100..  Training Loss: 0.021..  Test Loss: 0.020.. \n",
      "Epoch: 58/100..  Training Loss: 0.020..  Test Loss: 0.020.. \n",
      "Epoch: 59/100..  Training Loss: 0.020..  Test Loss: 0.019.. \n",
      "Epoch: 60/100..  Training Loss: 0.019..  Test Loss: 0.019.. \n",
      "Epoch: 61/100..  Training Loss: 0.019..  Test Loss: 0.019.. \n",
      "Epoch: 62/100..  Training Loss: 0.019..  Test Loss: 0.018.. \n",
      "Epoch: 63/100..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 64/100..  Training Loss: 0.019..  Test Loss: 0.018.. \n",
      "Epoch: 65/100..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 66/100..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 67/100..  Training Loss: 0.018..  Test Loss: 0.017.. \n",
      "Epoch: 68/100..  Training Loss: 0.018..  Test Loss: 0.017.. \n",
      "Epoch: 69/100..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 70/100..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 71/100..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 72/100..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 73/100..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 74/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 75/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 76/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 77/100..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 78/100..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 79/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 80/100..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 81/100..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 82/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 83/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 84/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 85/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 86/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 87/100..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 88/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 89/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 90/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 91/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 92/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 93/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 94/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 95/100..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 96/100..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 97/100..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 98/100..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 99/100..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 100/100..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Classifier used here is : 3-layered\n",
      "Correct benign is 10419 \n",
      " correct malicious is 7615 \n",
      " converted to benign is  3827\n",
      "   bits_flipped    TP     TN    FN\n",
      "0             0  9031  10419  2411\n",
      "1             1  8856  10419  2586\n",
      "2             2  8665  10419  2777\n",
      "3             3  8487  10419  2955\n",
      "4             4  8345  10419  3097\n",
      "5             5  8189  10419  3253\n",
      "6             6  8055  10419  3387\n",
      "7             7  7938  10419  3504\n",
      "8             8  7826  10419  3616\n",
      "9             9  7716  10419  3726\n",
      "10           10  7615  10419  3827\n",
      "This is training the neural network classifier for temperature 10\n",
      "Epoch: 1/50..  Training Loss: 0.509..  Test Loss: 0.488..  Test Accuracy: 0.826\n",
      "Epoch: 2/50..  Training Loss: 0.486..  Test Loss: 0.482..  Test Accuracy: 0.832\n",
      "Epoch: 3/50..  Training Loss: 0.483..  Test Loss: 0.480..  Test Accuracy: 0.833\n",
      "Epoch: 4/50..  Training Loss: 0.480..  Test Loss: 0.484..  Test Accuracy: 0.828\n",
      "Epoch: 5/50..  Training Loss: 0.477..  Test Loss: 0.475..  Test Accuracy: 0.838\n",
      "Epoch: 6/50..  Training Loss: 0.474..  Test Loss: 0.473..  Test Accuracy: 0.840\n",
      "Epoch: 7/50..  Training Loss: 0.473..  Test Loss: 0.471..  Test Accuracy: 0.842\n",
      "Epoch: 8/50..  Training Loss: 0.472..  Test Loss: 0.473..  Test Accuracy: 0.840\n",
      "Epoch: 9/50..  Training Loss: 0.471..  Test Loss: 0.469..  Test Accuracy: 0.844\n",
      "Epoch: 10/50..  Training Loss: 0.470..  Test Loss: 0.469..  Test Accuracy: 0.844\n",
      "Epoch: 11/50..  Training Loss: 0.469..  Test Loss: 0.468..  Test Accuracy: 0.845\n",
      "Epoch: 12/50..  Training Loss: 0.466..  Test Loss: 0.466..  Test Accuracy: 0.847\n",
      "Epoch: 13/50..  Training Loss: 0.466..  Test Loss: 0.465..  Test Accuracy: 0.848\n",
      "Epoch: 14/50..  Training Loss: 0.466..  Test Loss: 0.464..  Test Accuracy: 0.849\n",
      "Epoch: 15/50..  Training Loss: 0.464..  Test Loss: 0.464..  Test Accuracy: 0.849\n",
      "Epoch: 16/50..  Training Loss: 0.464..  Test Loss: 0.463..  Test Accuracy: 0.850\n",
      "Epoch: 17/50..  Training Loss: 0.464..  Test Loss: 0.463..  Test Accuracy: 0.850\n",
      "Epoch: 18/50..  Training Loss: 0.462..  Test Loss: 0.462..  Test Accuracy: 0.851\n",
      "Epoch: 19/50..  Training Loss: 0.462..  Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 20/50..  Training Loss: 0.462..  Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 21/50..  Training Loss: 0.461..  Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 22/50..  Training Loss: 0.461..  Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 23/50..  Training Loss: 0.461..  Test Loss: 0.462..  Test Accuracy: 0.851\n",
      "Epoch: 24/50..  Training Loss: 0.461..  Test Loss: 0.460..  Test Accuracy: 0.852\n",
      "Epoch: 25/50..  Training Loss: 0.461..  Test Loss: 0.459..  Test Accuracy: 0.853\n",
      "Epoch: 26/50..  Training Loss: 0.459..  Test Loss: 0.460..  Test Accuracy: 0.852\n",
      "Epoch: 27/50..  Training Loss: 0.459..  Test Loss: 0.458..  Test Accuracy: 0.854\n",
      "Epoch: 28/50..  Training Loss: 0.459..  Test Loss: 0.458..  Test Accuracy: 0.855\n",
      "Epoch: 29/50..  Training Loss: 0.459..  Test Loss: 0.458..  Test Accuracy: 0.853\n",
      "Epoch: 30/50..  Training Loss: 0.458..  Test Loss: 0.457..  Test Accuracy: 0.855\n",
      "Epoch: 31/50..  Training Loss: 0.458..  Test Loss: 0.457..  Test Accuracy: 0.856\n",
      "Epoch: 32/50..  Training Loss: 0.457..  Test Loss: 0.457..  Test Accuracy: 0.855\n",
      "Epoch: 33/50..  Training Loss: 0.457..  Test Loss: 0.456..  Test Accuracy: 0.856\n",
      "Epoch: 34/50..  Training Loss: 0.457..  Test Loss: 0.456..  Test Accuracy: 0.857\n",
      "Epoch: 35/50..  Training Loss: 0.456..  Test Loss: 0.457..  Test Accuracy: 0.855\n",
      "Epoch: 36/50..  Training Loss: 0.457..  Test Loss: 0.455..  Test Accuracy: 0.857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37/50..  Training Loss: 0.456..  Test Loss: 0.455..  Test Accuracy: 0.857\n",
      "Epoch: 38/50..  Training Loss: 0.455..  Test Loss: 0.455..  Test Accuracy: 0.857\n",
      "Epoch: 39/50..  Training Loss: 0.457..  Test Loss: 0.455..  Test Accuracy: 0.858\n",
      "Epoch: 40/50..  Training Loss: 0.455..  Test Loss: 0.456..  Test Accuracy: 0.856\n",
      "Epoch: 41/50..  Training Loss: 0.456..  Test Loss: 0.457..  Test Accuracy: 0.855\n",
      "Epoch: 42/50..  Training Loss: 0.456..  Test Loss: 0.455..  Test Accuracy: 0.857\n",
      "Epoch: 43/50..  Training Loss: 0.456..  Test Loss: 0.454..  Test Accuracy: 0.858\n",
      "Epoch: 44/50..  Training Loss: 0.455..  Test Loss: 0.454..  Test Accuracy: 0.858\n",
      "Epoch: 45/50..  Training Loss: 0.454..  Test Loss: 0.454..  Test Accuracy: 0.858\n",
      "Epoch: 46/50..  Training Loss: 0.455..  Test Loss: 0.454..  Test Accuracy: 0.858\n",
      "Epoch: 47/50..  Training Loss: 0.455..  Test Loss: 0.455..  Test Accuracy: 0.857\n",
      "Epoch: 48/50..  Training Loss: 0.455..  Test Loss: 0.454..  Test Accuracy: 0.858\n",
      "Epoch: 49/50..  Training Loss: 0.455..  Test Loss: 0.454..  Test Accuracy: 0.858\n",
      "Epoch: 50/50..  Training Loss: 0.454..  Test Loss: 0.453..  Test Accuracy: 0.859\n",
      "The length of the dataset is 22884\n",
      "Shape of X is (22884, 273) and shape of y_probs is (22884, 2)\n",
      "Epoch: 1/100..  Training Loss: 0.245..  Test Loss: 0.244.. \n",
      "Epoch: 2/100..  Training Loss: 0.244..  Test Loss: 0.243.. \n",
      "Epoch: 3/100..  Training Loss: 0.242..  Test Loss: 0.241.. \n",
      "Epoch: 4/100..  Training Loss: 0.239..  Test Loss: 0.237.. \n",
      "Epoch: 5/100..  Training Loss: 0.234..  Test Loss: 0.230.. \n",
      "Epoch: 6/100..  Training Loss: 0.223..  Test Loss: 0.214.. \n",
      "Epoch: 7/100..  Training Loss: 0.199..  Test Loss: 0.180.. \n",
      "Epoch: 8/100..  Training Loss: 0.153..  Test Loss: 0.123.. \n",
      "Epoch: 9/100..  Training Loss: 0.099..  Test Loss: 0.081.. \n",
      "Epoch: 10/100..  Training Loss: 0.072..  Test Loss: 0.066.. \n",
      "Epoch: 11/100..  Training Loss: 0.063..  Test Loss: 0.061.. \n",
      "Epoch: 12/100..  Training Loss: 0.060..  Test Loss: 0.058.. \n",
      "Epoch: 13/100..  Training Loss: 0.058..  Test Loss: 0.056.. \n",
      "Epoch: 14/100..  Training Loss: 0.056..  Test Loss: 0.055.. \n",
      "Epoch: 15/100..  Training Loss: 0.055..  Test Loss: 0.055.. \n",
      "Epoch: 16/100..  Training Loss: 0.054..  Test Loss: 0.054.. \n",
      "Epoch: 17/100..  Training Loss: 0.054..  Test Loss: 0.053.. \n",
      "Epoch: 18/100..  Training Loss: 0.053..  Test Loss: 0.053.. \n",
      "Epoch: 19/100..  Training Loss: 0.053..  Test Loss: 0.053.. \n",
      "Epoch: 20/100..  Training Loss: 0.052..  Test Loss: 0.052.. \n",
      "Epoch: 21/100..  Training Loss: 0.052..  Test Loss: 0.051.. \n",
      "Epoch: 22/100..  Training Loss: 0.051..  Test Loss: 0.051.. \n",
      "Epoch: 23/100..  Training Loss: 0.051..  Test Loss: 0.050.. \n",
      "Epoch: 24/100..  Training Loss: 0.050..  Test Loss: 0.050.. \n",
      "Epoch: 25/100..  Training Loss: 0.050..  Test Loss: 0.049.. \n",
      "Epoch: 26/100..  Training Loss: 0.049..  Test Loss: 0.049.. \n",
      "Epoch: 27/100..  Training Loss: 0.049..  Test Loss: 0.048.. \n",
      "Epoch: 28/100..  Training Loss: 0.048..  Test Loss: 0.048.. \n",
      "Epoch: 29/100..  Training Loss: 0.047..  Test Loss: 0.047.. \n",
      "Epoch: 30/100..  Training Loss: 0.046..  Test Loss: 0.046.. \n",
      "Epoch: 31/100..  Training Loss: 0.046..  Test Loss: 0.046.. \n",
      "Epoch: 32/100..  Training Loss: 0.045..  Test Loss: 0.045.. \n",
      "Epoch: 33/100..  Training Loss: 0.045..  Test Loss: 0.045.. \n",
      "Epoch: 34/100..  Training Loss: 0.045..  Test Loss: 0.044.. \n",
      "Epoch: 35/100..  Training Loss: 0.044..  Test Loss: 0.043.. \n",
      "Epoch: 36/100..  Training Loss: 0.043..  Test Loss: 0.043.. \n",
      "Epoch: 37/100..  Training Loss: 0.042..  Test Loss: 0.042.. \n",
      "Epoch: 38/100..  Training Loss: 0.042..  Test Loss: 0.042.. \n",
      "Epoch: 39/100..  Training Loss: 0.042..  Test Loss: 0.041.. \n",
      "Epoch: 40/100..  Training Loss: 0.041..  Test Loss: 0.040.. \n",
      "Epoch: 41/100..  Training Loss: 0.040..  Test Loss: 0.040.. \n",
      "Epoch: 42/100..  Training Loss: 0.040..  Test Loss: 0.040.. \n",
      "Epoch: 43/100..  Training Loss: 0.040..  Test Loss: 0.039.. \n",
      "Epoch: 44/100..  Training Loss: 0.039..  Test Loss: 0.038.. \n",
      "Epoch: 45/100..  Training Loss: 0.038..  Test Loss: 0.038.. \n",
      "Epoch: 46/100..  Training Loss: 0.038..  Test Loss: 0.038.. \n",
      "Epoch: 47/100..  Training Loss: 0.038..  Test Loss: 0.037.. \n",
      "Epoch: 48/100..  Training Loss: 0.037..  Test Loss: 0.037.. \n",
      "Epoch: 49/100..  Training Loss: 0.037..  Test Loss: 0.037.. \n",
      "Epoch: 50/100..  Training Loss: 0.036..  Test Loss: 0.036.. \n",
      "Epoch: 51/100..  Training Loss: 0.036..  Test Loss: 0.035.. \n",
      "Epoch: 52/100..  Training Loss: 0.035..  Test Loss: 0.035.. \n",
      "Epoch: 53/100..  Training Loss: 0.035..  Test Loss: 0.035.. \n",
      "Epoch: 54/100..  Training Loss: 0.034..  Test Loss: 0.034.. \n",
      "Epoch: 55/100..  Training Loss: 0.034..  Test Loss: 0.033.. \n",
      "Epoch: 56/100..  Training Loss: 0.033..  Test Loss: 0.033.. \n",
      "Epoch: 57/100..  Training Loss: 0.033..  Test Loss: 0.033.. \n",
      "Epoch: 58/100..  Training Loss: 0.032..  Test Loss: 0.032.. \n",
      "Epoch: 59/100..  Training Loss: 0.032..  Test Loss: 0.031.. \n",
      "Epoch: 60/100..  Training Loss: 0.031..  Test Loss: 0.031.. \n",
      "Epoch: 61/100..  Training Loss: 0.031..  Test Loss: 0.031.. \n",
      "Epoch: 62/100..  Training Loss: 0.031..  Test Loss: 0.030.. \n",
      "Epoch: 63/100..  Training Loss: 0.030..  Test Loss: 0.030.. \n",
      "Epoch: 64/100..  Training Loss: 0.029..  Test Loss: 0.029.. \n",
      "Epoch: 65/100..  Training Loss: 0.029..  Test Loss: 0.029.. \n",
      "Epoch: 66/100..  Training Loss: 0.029..  Test Loss: 0.028.. \n",
      "Epoch: 67/100..  Training Loss: 0.028..  Test Loss: 0.028.. \n",
      "Epoch: 68/100..  Training Loss: 0.027..  Test Loss: 0.027.. \n",
      "Epoch: 69/100..  Training Loss: 0.027..  Test Loss: 0.026.. \n",
      "Epoch: 70/100..  Training Loss: 0.026..  Test Loss: 0.026.. \n",
      "Epoch: 71/100..  Training Loss: 0.026..  Test Loss: 0.026.. \n",
      "Epoch: 72/100..  Training Loss: 0.026..  Test Loss: 0.025.. \n",
      "Epoch: 73/100..  Training Loss: 0.025..  Test Loss: 0.024.. \n",
      "Epoch: 74/100..  Training Loss: 0.025..  Test Loss: 0.025.. \n",
      "Epoch: 75/100..  Training Loss: 0.024..  Test Loss: 0.024.. \n",
      "Epoch: 76/100..  Training Loss: 0.024..  Test Loss: 0.023.. \n",
      "Epoch: 77/100..  Training Loss: 0.023..  Test Loss: 0.023.. \n",
      "Epoch: 78/100..  Training Loss: 0.023..  Test Loss: 0.023.. \n",
      "Epoch: 79/100..  Training Loss: 0.023..  Test Loss: 0.023.. \n",
      "Epoch: 80/100..  Training Loss: 0.022..  Test Loss: 0.022.. \n",
      "Epoch: 81/100..  Training Loss: 0.022..  Test Loss: 0.022.. \n",
      "Epoch: 82/100..  Training Loss: 0.022..  Test Loss: 0.022.. \n",
      "Epoch: 83/100..  Training Loss: 0.022..  Test Loss: 0.022.. \n",
      "Epoch: 84/100..  Training Loss: 0.021..  Test Loss: 0.021.. \n",
      "Epoch: 85/100..  Training Loss: 0.021..  Test Loss: 0.021.. \n",
      "Epoch: 86/100..  Training Loss: 0.021..  Test Loss: 0.021.. \n",
      "Epoch: 87/100..  Training Loss: 0.021..  Test Loss: 0.021.. \n",
      "Epoch: 88/100..  Training Loss: 0.021..  Test Loss: 0.020.. \n",
      "Epoch: 89/100..  Training Loss: 0.020..  Test Loss: 0.020.. \n",
      "Epoch: 90/100..  Training Loss: 0.021..  Test Loss: 0.020.. \n",
      "Epoch: 91/100..  Training Loss: 0.020..  Test Loss: 0.020.. \n",
      "Epoch: 92/100..  Training Loss: 0.020..  Test Loss: 0.020.. \n",
      "Epoch: 93/100..  Training Loss: 0.019..  Test Loss: 0.020.. \n",
      "Epoch: 94/100..  Training Loss: 0.020..  Test Loss: 0.020.. \n",
      "Epoch: 95/100..  Training Loss: 0.019..  Test Loss: 0.019.. \n",
      "Epoch: 96/100..  Training Loss: 0.019..  Test Loss: 0.019.. \n",
      "Epoch: 97/100..  Training Loss: 0.019..  Test Loss: 0.019.. \n",
      "Epoch: 98/100..  Training Loss: 0.019..  Test Loss: 0.019.. \n",
      "Epoch: 99/100..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 100/100..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Classifier used here is : 3-layered\n",
      "Correct benign is 10204 \n",
      " correct malicious is 7114 \n",
      " converted to benign is  4328\n",
      "   bits_flipped    TP     TN    FN\n",
      "0             0  9090  10204  2352\n",
      "1             1  8829  10204  2613\n",
      "2             2  8441  10204  3001\n",
      "3             3  8229  10204  3213\n",
      "4             4  8052  10204  3390\n",
      "5             5  7894  10204  3548\n",
      "6             6  7733  10204  3709\n",
      "7             7  7557  10204  3885\n",
      "8             8  7423  10204  4019\n",
      "9             9  7274  10204  4168\n",
      "10           10  7114  10204  4328\n"
     ]
    }
   ],
   "source": [
    "for t in [1, 5,10]:\n",
    "    epochs=50\n",
    "    \n",
    "    print(\"This is training the neural network classifier for temperature {}\".format(t))\n",
    "    \n",
    "    model_class= model_3(t)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model_class.parameters(), lr=0.001)\n",
    "    \n",
    "    df=pd.read_csv('../Resampled_Datasets_Attack/3-layered'+'_resamp.csv')\n",
    "    X=df.iloc[:,:-1].values\n",
    "    y=df.iloc[:,-1].values\n",
    "            \n",
    "    train_dataset = Datasetcustom(X, y)\n",
    "    test_dataset = Datasetcustom(X, y)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=20, shuffle=True)\n",
    "\n",
    "    train_losses, test_losses = [], []\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            log_ps = model_class(images)\n",
    "    #         print(log_ps)\n",
    "            loss = criterion(log_ps, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        else:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "\n",
    "            # Turn off gradients for validation, saves memory and computations\n",
    "            with torch.no_grad():\n",
    "                for images, labels in test_loader:\n",
    "                    log_ps = model_class(images)\n",
    "                    test_loss += criterion(log_ps, labels)\n",
    "\n",
    "                    top_p, top_class = log_ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "            train_losses.append(running_loss/len(train_loader))\n",
    "            test_losses.append(test_loss/len(test_loader))\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))\n",
    "            \n",
    "    print(\"The length of the dataset is {}\".format(len(train_dataset)))\n",
    "    probs_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True)\n",
    "    train_iter = iter(probs_loader)\n",
    "    images, labels = train_iter.next()\n",
    "    y_probs= model_class(images)\n",
    "    y_probs=y_probs.detach().numpy()\n",
    "    X_probs=images.detach().numpy()\n",
    "    \n",
    "    print(\"Shape of X is {} and shape of y_probs is {}\".format(X.shape, y_probs.shape))\n",
    "    X_train, X_test, y_train, y_test =X_probs,X_probs,  y_probs ,  y_probs\n",
    "    \n",
    "    train_dataset_dist = Datasetcustom(X_train, y_train)\n",
    "    test_dataset_dist= Datasetcustom(X_test, y_test)\n",
    "    train_loader_dist = DataLoader(train_dataset_dist, batch_size=20, shuffle=True)\n",
    "    test_loader_dist = DataLoader(test_dataset_dist, batch_size=20, shuffle=True)\n",
    "    \n",
    "    model_reg=model_3dist(t)\n",
    "    criterion_dist =  nn.MSELoss()\n",
    "    optimizer_dist = optim.SGD(model_reg.parameters(), lr=0.02)\n",
    "\n",
    "    epochs= 100\n",
    "    train_losses, test_losses = [], []\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        for images, labels in train_loader_dist:\n",
    "\n",
    "            optimizer_dist.zero_grad()\n",
    "            log_ps = model_reg(images)\n",
    "            loss = criterion_dist(log_ps, labels)\n",
    "            loss.backward()\n",
    "            optimizer_dist.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        else:\n",
    "            test_loss = 0\n",
    "\n",
    "            # Turn off gradients for validation, saves memory and computations\n",
    "            with torch.no_grad():\n",
    "                for images, labels in test_loader_dist:\n",
    "                    log_ps = model_reg(images)\n",
    "                    test_loss += criterion_dist(log_ps, labels)\n",
    "\n",
    "            train_losses.append(running_loss/len(train_loader_dist))\n",
    "            test_losses.append(test_loss/len(test_loader_dist))\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader_dist)),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader_dist)))\n",
    "    \n",
    "    Models={ \"3-layered\": model_reg}\n",
    "    model=torch.load('../trained_models/Train-512-256-64.pth')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    #Attack with original attacker after retraining\n",
    "    for Algorithm in Models:\n",
    "            df1=pd.DataFrame(columns = ['bits_flipped','TP', 'TN','FN'])\n",
    "            for i in range(0,11):\n",
    "                df1=df1.append(pd.Series([i, 11442, 0, 0], index= df1.columns), ignore_index=True )\n",
    "            print(\"Classifier used here is : {}\".format(Algorithm))\n",
    "            classifier= Models[Algorithm]\n",
    "            correct_benign=0\n",
    "            correct_malicious=0\n",
    "            convert_to_benign=0\n",
    "            \n",
    "            df=pd.read_csv('../Resampled_Datasets_Attack/3-layered'+'_resamp.csv')\n",
    "            X=df.iloc[:,:-1].values\n",
    "            y=df.iloc[:,-1].values\n",
    "            \n",
    "            target_model= Models[Algorithm]\n",
    "            test_dataset= Datasetcustom(X, y)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "            for images, labels in test_loader:\n",
    "                images.requires_grad = True\n",
    "                model.zero_grad()\n",
    "                output = model(images)\n",
    "                y_pred = target_model(images)\n",
    "                loss = criterion(output, labels)\n",
    "                loss.backward()\n",
    "                data_grad = images.grad.data\n",
    "                if  y_pred[0][1]>y_pred[0][0] and labels[0]==1: #predicted malicious\n",
    "                    grad_list=[]\n",
    "                    for i in range(273):\n",
    "                        if images[0][i]==0:\n",
    "                            grad_list.append((data_grad[0][i],i))\n",
    "                    grad_list.sort(key = lambda x: x[0], reverse=True)\n",
    "                    flag=0\n",
    "                    for i in range(0,10):\n",
    "                        images[0][grad_list[i][1]]=1\n",
    "                        y_pred = target_model(images)\n",
    "                        if y_pred[0][0]>y_pred[0][1]:\n",
    "                            for j in range(i,10):  #converted in i+1 flips, hence all bits>=i+1, the FN will increase\n",
    "                                df1.iloc[j+1,3]+=1\n",
    "                                df1.iloc[j+1,1]-=1\n",
    "                            flag=1\n",
    "                            convert_to_benign+=1\n",
    "                            break\n",
    "                    if flag==0:          #Even after 10 flips, unable to convert to benignm update malicious counter\n",
    "                        correct_malicious+=1\n",
    "                elif y_pred[0][0]>y_pred[0][1] and labels[0]==1:  #If predicted as benign but is malicious\n",
    "                    for j in range(0,11):\n",
    "                        df1.iloc[j,3]+=1\n",
    "                        df1.iloc[j,1]-=1\n",
    "                    convert_to_benign+=1\n",
    "                elif  y_pred[0][0]>y_pred[0][1] and labels[0]==0:  #if predicted benign correctly\n",
    "                    for j in range(0,11):\n",
    "                        df1.iloc[j,2]+=1\n",
    "                    correct_benign+=1\n",
    "\n",
    "            print(\"Correct benign is {} \\n correct malicious is {} \\n converted to benign is  {}\".format(correct_benign, correct_malicious, convert_to_benign))\n",
    "    #         print(\"Final Accuracy is {:.3f} with max {} bits flipped\".format((correct_benign+5553-convert_benign)/11274, num_bits))\n",
    "            print(df1)\n",
    "            df1.to_csv(\"../Hybrid_Distillation/\"+str(Algorithm)+\"_Distillation_\"+str(t)+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-Layered Neural Nteworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_5(nn.Module):\n",
    "    def __init__(self,t):\n",
    "        super(model_5, self).__init__()\n",
    "        self.t=t\n",
    "        self.l1=nn.Linear(273, 512)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.l2=nn.Linear(512, 256)\n",
    "        self.l3= nn.Linear(256, 64)\n",
    "        self.l4=nn.Linear(64, 32)\n",
    "        self.l5=nn.Linear(32, 2)\n",
    "        self.dropout= nn.Dropout(0.4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.l1(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l2(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l3(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l4(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l5(x)\n",
    "        x= nn.Softmax(dim=1)(x/self.t)\n",
    "        return x\n",
    "    \n",
    "class model_5dist(nn.Module):\n",
    "    def __init__(self,t):\n",
    "        super(model_5dist, self).__init__()\n",
    "        self.t=t\n",
    "        self.l1=nn.Linear(273, 512)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.l2=nn.Linear(512, 256)\n",
    "        self.l3= nn.Linear(256, 64)\n",
    "        self.l4=nn.Linear(64, 32)\n",
    "        self.l5=nn.Linear(32, 2)\n",
    "        self.dropout= nn.Dropout(0.4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.l1(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l2(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l3(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l4(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l5(x)\n",
    "        x= nn.Softmax(dim=1)(x/self.t)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is training the neural network classifier for temperature 1\n",
      "Epoch: 1/50..  Training Loss: 0.506..  Test Loss: 0.490..  Test Accuracy: 0.823\n",
      "Epoch: 2/50..  Training Loss: 0.490..  Test Loss: 0.485..  Test Accuracy: 0.828\n",
      "Epoch: 3/50..  Training Loss: 0.489..  Test Loss: 0.483..  Test Accuracy: 0.830\n",
      "Epoch: 4/50..  Training Loss: 0.486..  Test Loss: 0.485..  Test Accuracy: 0.828\n",
      "Epoch: 5/50..  Training Loss: 0.485..  Test Loss: 0.482..  Test Accuracy: 0.831\n",
      "Epoch: 6/50..  Training Loss: 0.482..  Test Loss: 0.481..  Test Accuracy: 0.832\n",
      "Epoch: 7/50..  Training Loss: 0.480..  Test Loss: 0.478..  Test Accuracy: 0.835\n",
      "Epoch: 8/50..  Training Loss: 0.483..  Test Loss: 0.480..  Test Accuracy: 0.833\n",
      "Epoch: 9/50..  Training Loss: 0.487..  Test Loss: 0.480..  Test Accuracy: 0.833\n",
      "Epoch: 10/50..  Training Loss: 0.484..  Test Loss: 0.481..  Test Accuracy: 0.832\n",
      "Epoch: 11/50..  Training Loss: 0.485..  Test Loss: 0.482..  Test Accuracy: 0.831\n",
      "Epoch: 12/50..  Training Loss: 0.482..  Test Loss: 0.485..  Test Accuracy: 0.828\n",
      "Epoch: 13/50..  Training Loss: 0.484..  Test Loss: 0.481..  Test Accuracy: 0.832\n",
      "Epoch: 14/50..  Training Loss: 0.482..  Test Loss: 0.485..  Test Accuracy: 0.828\n",
      "Epoch: 15/50..  Training Loss: 0.490..  Test Loss: 0.482..  Test Accuracy: 0.831\n",
      "Epoch: 16/50..  Training Loss: 0.482..  Test Loss: 0.484..  Test Accuracy: 0.829\n",
      "Epoch: 17/50..  Training Loss: 0.484..  Test Loss: 0.485..  Test Accuracy: 0.828\n",
      "Epoch: 18/50..  Training Loss: 0.481..  Test Loss: 0.479..  Test Accuracy: 0.834\n",
      "Epoch: 19/50..  Training Loss: 0.482..  Test Loss: 0.481..  Test Accuracy: 0.832\n",
      "Epoch: 20/50..  Training Loss: 0.482..  Test Loss: 0.482..  Test Accuracy: 0.832\n",
      "Epoch: 21/50..  Training Loss: 0.481..  Test Loss: 0.481..  Test Accuracy: 0.832\n",
      "Epoch: 22/50..  Training Loss: 0.483..  Test Loss: 0.484..  Test Accuracy: 0.829\n",
      "Epoch: 23/50..  Training Loss: 0.482..  Test Loss: 0.483..  Test Accuracy: 0.830\n",
      "Epoch: 24/50..  Training Loss: 0.479..  Test Loss: 0.480..  Test Accuracy: 0.833\n",
      "Epoch: 25/50..  Training Loss: 0.483..  Test Loss: 0.482..  Test Accuracy: 0.831\n",
      "Epoch: 26/50..  Training Loss: 0.479..  Test Loss: 0.481..  Test Accuracy: 0.832\n",
      "Epoch: 27/50..  Training Loss: 0.479..  Test Loss: 0.479..  Test Accuracy: 0.834\n",
      "Epoch: 28/50..  Training Loss: 0.480..  Test Loss: 0.479..  Test Accuracy: 0.834\n",
      "Epoch: 29/50..  Training Loss: 0.482..  Test Loss: 0.482..  Test Accuracy: 0.831\n",
      "Epoch: 30/50..  Training Loss: 0.481..  Test Loss: 0.482..  Test Accuracy: 0.831\n",
      "Epoch: 31/50..  Training Loss: 0.483..  Test Loss: 0.481..  Test Accuracy: 0.833\n",
      "Epoch: 32/50..  Training Loss: 0.481..  Test Loss: 0.478..  Test Accuracy: 0.835\n",
      "Epoch: 33/50..  Training Loss: 0.479..  Test Loss: 0.480..  Test Accuracy: 0.834\n",
      "Epoch: 34/50..  Training Loss: 0.485..  Test Loss: 0.489..  Test Accuracy: 0.825\n",
      "Epoch: 35/50..  Training Loss: 0.494..  Test Loss: 0.485..  Test Accuracy: 0.829\n",
      "Epoch: 36/50..  Training Loss: 0.482..  Test Loss: 0.480..  Test Accuracy: 0.833\n",
      "Epoch: 37/50..  Training Loss: 0.480..  Test Loss: 0.479..  Test Accuracy: 0.835\n",
      "Epoch: 38/50..  Training Loss: 0.482..  Test Loss: 0.488..  Test Accuracy: 0.826\n",
      "Epoch: 39/50..  Training Loss: 0.492..  Test Loss: 0.483..  Test Accuracy: 0.830\n",
      "Epoch: 40/50..  Training Loss: 0.490..  Test Loss: 0.482..  Test Accuracy: 0.831\n",
      "Epoch: 41/50..  Training Loss: 0.482..  Test Loss: 0.484..  Test Accuracy: 0.830\n",
      "Epoch: 42/50..  Training Loss: 0.492..  Test Loss: 0.495..  Test Accuracy: 0.818\n",
      "Epoch: 43/50..  Training Loss: 0.494..  Test Loss: 0.496..  Test Accuracy: 0.818\n",
      "Epoch: 44/50..  Training Loss: 0.494..  Test Loss: 0.490..  Test Accuracy: 0.823\n",
      "Epoch: 45/50..  Training Loss: 0.503..  Test Loss: 0.492..  Test Accuracy: 0.821\n",
      "Epoch: 46/50..  Training Loss: 0.506..  Test Loss: 0.489..  Test Accuracy: 0.825\n",
      "Epoch: 47/50..  Training Loss: 0.489..  Test Loss: 0.493..  Test Accuracy: 0.820\n",
      "Epoch: 48/50..  Training Loss: 0.491..  Test Loss: 0.488..  Test Accuracy: 0.825\n",
      "Epoch: 49/50..  Training Loss: 0.489..  Test Loss: 0.494..  Test Accuracy: 0.820\n",
      "Epoch: 50/50..  Training Loss: 0.485..  Test Loss: 0.483..  Test Accuracy: 0.830\n",
      "The length of the dataset is 22884\n",
      "Shape of X is (22884, 273) and shape of y_probs is (22884, 2)\n",
      "Epoch: 1/100..  Training Loss: 0.242..  Test Loss: 0.214.. \n",
      "Epoch: 2/100..  Training Loss: 0.088..  Test Loss: 0.039.. \n",
      "Epoch: 3/100..  Training Loss: 0.034..  Test Loss: 0.031.. \n",
      "Epoch: 4/100..  Training Loss: 0.028..  Test Loss: 0.027.. \n",
      "Epoch: 5/100..  Training Loss: 0.026..  Test Loss: 0.025.. \n",
      "Epoch: 6/100..  Training Loss: 0.024..  Test Loss: 0.025.. \n",
      "Epoch: 7/100..  Training Loss: 0.023..  Test Loss: 0.022.. \n",
      "Epoch: 8/100..  Training Loss: 0.023..  Test Loss: 0.021.. \n",
      "Epoch: 9/100..  Training Loss: 0.021..  Test Loss: 0.019.. \n",
      "Epoch: 10/100..  Training Loss: 0.019..  Test Loss: 0.017.. \n",
      "Epoch: 11/100..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 12/100..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 13/100..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 14/100..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 15/100..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 16/100..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 17/100..  Training Loss: 0.013..  Test Loss: 0.012.. \n",
      "Epoch: 18/100..  Training Loss: 0.013..  Test Loss: 0.011.. \n",
      "Epoch: 19/100..  Training Loss: 0.011..  Test Loss: 0.010.. \n",
      "Epoch: 20/100..  Training Loss: 0.013..  Test Loss: 0.012.. \n",
      "Epoch: 21/100..  Training Loss: 0.010..  Test Loss: 0.010.. \n",
      "Epoch: 22/100..  Training Loss: 0.010..  Test Loss: 0.010.. \n",
      "Epoch: 23/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 24/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 25/100..  Training Loss: 0.010..  Test Loss: 0.010.. \n",
      "Epoch: 26/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 27/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 28/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 29/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 30/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 31/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 32/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 33/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 34/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 35/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 36/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 37/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 38/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 39/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 40/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 41/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 42/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 43/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 44/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 45/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 46/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 47/100..  Training Loss: 0.007..  Test Loss: 0.008.. \n",
      "Epoch: 48/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 49/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 50/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 51/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 52/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 53/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 54/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 55/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 56/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 57/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 58/100..  Training Loss: 0.006..  Test Loss: 0.007.. \n",
      "Epoch: 59/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 60/100..  Training Loss: 0.006..  Test Loss: 0.007.. \n",
      "Epoch: 61/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 62/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 63/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 64/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 65/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 66/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 68/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 69/100..  Training Loss: 0.006..  Test Loss: 0.005.. \n",
      "Epoch: 70/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 71/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 72/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 73/100..  Training Loss: 0.005..  Test Loss: 0.006.. \n",
      "Epoch: 74/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 75/100..  Training Loss: 0.006..  Test Loss: 0.005.. \n",
      "Epoch: 76/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 77/100..  Training Loss: 0.005..  Test Loss: 0.006.. \n",
      "Epoch: 78/100..  Training Loss: 0.005..  Test Loss: 0.007.. \n",
      "Epoch: 79/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 80/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 81/100..  Training Loss: 0.006..  Test Loss: 0.005.. \n",
      "Epoch: 82/100..  Training Loss: 0.006..  Test Loss: 0.005.. \n",
      "Epoch: 83/100..  Training Loss: 0.006..  Test Loss: 0.005.. \n",
      "Epoch: 84/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 85/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 86/100..  Training Loss: 0.005..  Test Loss: 0.005.. \n",
      "Epoch: 87/100..  Training Loss: 0.005..  Test Loss: 0.005.. \n",
      "Epoch: 88/100..  Training Loss: 0.005..  Test Loss: 0.005.. \n",
      "Epoch: 89/100..  Training Loss: 0.006..  Test Loss: 0.005.. \n",
      "Epoch: 90/100..  Training Loss: 0.005..  Test Loss: 0.005.. \n",
      "Epoch: 91/100..  Training Loss: 0.006..  Test Loss: 0.005.. \n",
      "Epoch: 92/100..  Training Loss: 0.006..  Test Loss: 0.005.. \n",
      "Epoch: 93/100..  Training Loss: 0.005..  Test Loss: 0.006.. \n",
      "Epoch: 94/100..  Training Loss: 0.006..  Test Loss: 0.005.. \n",
      "Epoch: 95/100..  Training Loss: 0.005..  Test Loss: 0.005.. \n",
      "Epoch: 96/100..  Training Loss: 0.005..  Test Loss: 0.005.. \n",
      "Epoch: 97/100..  Training Loss: 0.005..  Test Loss: 0.005.. \n",
      "Epoch: 98/100..  Training Loss: 0.005..  Test Loss: 0.005.. \n",
      "Epoch: 99/100..  Training Loss: 0.005..  Test Loss: 0.005.. \n",
      "Epoch: 100/100..  Training Loss: 0.005..  Test Loss: 0.005.. \n",
      "Classifier used here is : 5-layered\n",
      "Correct benign is 10007 \n",
      " correct malicious is 7984 \n",
      " converted to benign is  3458\n",
      "   bits_flipped    TP     TN    FN\n",
      "0             0  9020  10007  2422\n",
      "1             1  8947  10007  2495\n",
      "2             2  8832  10007  2610\n",
      "3             3  8716  10007  2726\n",
      "4             4  8635  10007  2807\n",
      "5             5  8534  10007  2908\n",
      "6             6  8442  10007  3000\n",
      "7             7  8337  10007  3105\n",
      "8             8  8213  10007  3229\n",
      "9             9  8093  10007  3349\n",
      "10           10  7984  10007  3458\n",
      "This is training the neural network classifier for temperature 5\n",
      "Epoch: 1/50..  Training Loss: 0.506..  Test Loss: 0.491..  Test Accuracy: 0.822\n",
      "Epoch: 2/50..  Training Loss: 0.490..  Test Loss: 0.489..  Test Accuracy: 0.824\n",
      "Epoch: 3/50..  Training Loss: 0.485..  Test Loss: 0.485..  Test Accuracy: 0.827\n",
      "Epoch: 4/50..  Training Loss: 0.482..  Test Loss: 0.478..  Test Accuracy: 0.835\n",
      "Epoch: 5/50..  Training Loss: 0.479..  Test Loss: 0.477..  Test Accuracy: 0.836\n",
      "Epoch: 6/50..  Training Loss: 0.478..  Test Loss: 0.477..  Test Accuracy: 0.837\n",
      "Epoch: 7/50..  Training Loss: 0.479..  Test Loss: 0.477..  Test Accuracy: 0.836\n",
      "Epoch: 8/50..  Training Loss: 0.479..  Test Loss: 0.481..  Test Accuracy: 0.832\n",
      "Epoch: 9/50..  Training Loss: 0.475..  Test Loss: 0.473..  Test Accuracy: 0.840\n",
      "Epoch: 10/50..  Training Loss: 0.475..  Test Loss: 0.474..  Test Accuracy: 0.839\n",
      "Epoch: 11/50..  Training Loss: 0.474..  Test Loss: 0.472..  Test Accuracy: 0.841\n",
      "Epoch: 12/50..  Training Loss: 0.471..  Test Loss: 0.469..  Test Accuracy: 0.844\n",
      "Epoch: 13/50..  Training Loss: 0.469..  Test Loss: 0.468..  Test Accuracy: 0.845\n",
      "Epoch: 14/50..  Training Loss: 0.471..  Test Loss: 0.470..  Test Accuracy: 0.842\n",
      "Epoch: 15/50..  Training Loss: 0.471..  Test Loss: 0.468..  Test Accuracy: 0.845\n",
      "Epoch: 16/50..  Training Loss: 0.470..  Test Loss: 0.466..  Test Accuracy: 0.847\n",
      "Epoch: 17/50..  Training Loss: 0.468..  Test Loss: 0.466..  Test Accuracy: 0.847\n",
      "Epoch: 18/50..  Training Loss: 0.469..  Test Loss: 0.467..  Test Accuracy: 0.847\n",
      "Epoch: 19/50..  Training Loss: 0.467..  Test Loss: 0.467..  Test Accuracy: 0.846\n",
      "Epoch: 20/50..  Training Loss: 0.468..  Test Loss: 0.470..  Test Accuracy: 0.843\n",
      "Epoch: 21/50..  Training Loss: 0.467..  Test Loss: 0.465..  Test Accuracy: 0.848\n",
      "Epoch: 22/50..  Training Loss: 0.466..  Test Loss: 0.465..  Test Accuracy: 0.848\n",
      "Epoch: 23/50..  Training Loss: 0.466..  Test Loss: 0.465..  Test Accuracy: 0.848\n",
      "Epoch: 24/50..  Training Loss: 0.466..  Test Loss: 0.465..  Test Accuracy: 0.848\n",
      "Epoch: 25/50..  Training Loss: 0.465..  Test Loss: 0.465..  Test Accuracy: 0.847\n",
      "Epoch: 26/50..  Training Loss: 0.465..  Test Loss: 0.463..  Test Accuracy: 0.850\n",
      "Epoch: 27/50..  Training Loss: 0.464..  Test Loss: 0.465..  Test Accuracy: 0.848\n",
      "Epoch: 28/50..  Training Loss: 0.463..  Test Loss: 0.463..  Test Accuracy: 0.850\n",
      "Epoch: 29/50..  Training Loss: 0.464..  Test Loss: 0.464..  Test Accuracy: 0.849\n",
      "Epoch: 30/50..  Training Loss: 0.463..  Test Loss: 0.464..  Test Accuracy: 0.849\n",
      "Epoch: 31/50..  Training Loss: 0.464..  Test Loss: 0.463..  Test Accuracy: 0.849\n",
      "Epoch: 32/50..  Training Loss: 0.464..  Test Loss: 0.463..  Test Accuracy: 0.849\n",
      "Epoch: 33/50..  Training Loss: 0.464..  Test Loss: 0.462..  Test Accuracy: 0.850\n",
      "Epoch: 34/50..  Training Loss: 0.462..  Test Loss: 0.466..  Test Accuracy: 0.846\n",
      "Epoch: 35/50..  Training Loss: 0.462..  Test Loss: 0.460..  Test Accuracy: 0.851\n",
      "Epoch: 36/50..  Training Loss: 0.461..  Test Loss: 0.460..  Test Accuracy: 0.852\n",
      "Epoch: 37/50..  Training Loss: 0.461..  Test Loss: 0.464..  Test Accuracy: 0.848\n",
      "Epoch: 38/50..  Training Loss: 0.461..  Test Loss: 0.460..  Test Accuracy: 0.852\n",
      "Epoch: 39/50..  Training Loss: 0.461..  Test Loss: 0.462..  Test Accuracy: 0.850\n",
      "Epoch: 40/50..  Training Loss: 0.461..  Test Loss: 0.460..  Test Accuracy: 0.852\n",
      "Epoch: 41/50..  Training Loss: 0.461..  Test Loss: 0.460..  Test Accuracy: 0.852\n",
      "Epoch: 42/50..  Training Loss: 0.459..  Test Loss: 0.461..  Test Accuracy: 0.852\n",
      "Epoch: 43/50..  Training Loss: 0.460..  Test Loss: 0.462..  Test Accuracy: 0.851\n",
      "Epoch: 44/50..  Training Loss: 0.460..  Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 45/50..  Training Loss: 0.460..  Test Loss: 0.462..  Test Accuracy: 0.850\n",
      "Epoch: 46/50..  Training Loss: 0.460..  Test Loss: 0.460..  Test Accuracy: 0.852\n",
      "Epoch: 47/50..  Training Loss: 0.460..  Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 48/50..  Training Loss: 0.461..  Test Loss: 0.460..  Test Accuracy: 0.852\n",
      "Epoch: 49/50..  Training Loss: 0.460..  Test Loss: 0.461..  Test Accuracy: 0.852\n",
      "Epoch: 50/50..  Training Loss: 0.462..  Test Loss: 0.459..  Test Accuracy: 0.853\n",
      "The length of the dataset is 22884\n",
      "Shape of X is (22884, 273) and shape of y_probs is (22884, 2)\n",
      "Epoch: 1/100..  Training Loss: 0.246..  Test Loss: 0.245.. \n",
      "Epoch: 2/100..  Training Loss: 0.244..  Test Loss: 0.244.. \n",
      "Epoch: 3/100..  Training Loss: 0.243..  Test Loss: 0.243.. \n",
      "Epoch: 4/100..  Training Loss: 0.242..  Test Loss: 0.242.. \n",
      "Epoch: 5/100..  Training Loss: 0.241..  Test Loss: 0.240.. \n",
      "Epoch: 6/100..  Training Loss: 0.237..  Test Loss: 0.233.. \n",
      "Epoch: 7/100..  Training Loss: 0.220..  Test Loss: 0.194.. \n",
      "Epoch: 8/100..  Training Loss: 0.132..  Test Loss: 0.078.. \n",
      "Epoch: 9/100..  Training Loss: 0.065..  Test Loss: 0.057.. \n",
      "Epoch: 10/100..  Training Loss: 0.056..  Test Loss: 0.054.. \n",
      "Epoch: 11/100..  Training Loss: 0.052..  Test Loss: 0.051.. \n",
      "Epoch: 12/100..  Training Loss: 0.049..  Test Loss: 0.048.. \n",
      "Epoch: 13/100..  Training Loss: 0.046..  Test Loss: 0.045.. \n",
      "Epoch: 14/100..  Training Loss: 0.045..  Test Loss: 0.043.. \n",
      "Epoch: 15/100..  Training Loss: 0.043..  Test Loss: 0.042.. \n",
      "Epoch: 16/100..  Training Loss: 0.042..  Test Loss: 0.042.. \n",
      "Epoch: 17/100..  Training Loss: 0.041..  Test Loss: 0.040.. \n",
      "Epoch: 18/100..  Training Loss: 0.039..  Test Loss: 0.040.. \n",
      "Epoch: 19/100..  Training Loss: 0.039..  Test Loss: 0.037.. \n",
      "Epoch: 20/100..  Training Loss: 0.037..  Test Loss: 0.037.. \n",
      "Epoch: 21/100..  Training Loss: 0.036..  Test Loss: 0.035.. \n",
      "Epoch: 22/100..  Training Loss: 0.035..  Test Loss: 0.034.. \n",
      "Epoch: 23/100..  Training Loss: 0.033..  Test Loss: 0.032.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/100..  Training Loss: 0.032..  Test Loss: 0.030.. \n",
      "Epoch: 25/100..  Training Loss: 0.031..  Test Loss: 0.029.. \n",
      "Epoch: 26/100..  Training Loss: 0.029..  Test Loss: 0.028.. \n",
      "Epoch: 27/100..  Training Loss: 0.028..  Test Loss: 0.027.. \n",
      "Epoch: 28/100..  Training Loss: 0.027..  Test Loss: 0.026.. \n",
      "Epoch: 29/100..  Training Loss: 0.026..  Test Loss: 0.025.. \n",
      "Epoch: 30/100..  Training Loss: 0.026..  Test Loss: 0.025.. \n",
      "Epoch: 31/100..  Training Loss: 0.024..  Test Loss: 0.025.. \n",
      "Epoch: 32/100..  Training Loss: 0.024..  Test Loss: 0.023.. \n",
      "Epoch: 33/100..  Training Loss: 0.023..  Test Loss: 0.023.. \n",
      "Epoch: 34/100..  Training Loss: 0.022..  Test Loss: 0.022.. \n",
      "Epoch: 35/100..  Training Loss: 0.021..  Test Loss: 0.020.. \n",
      "Epoch: 36/100..  Training Loss: 0.020..  Test Loss: 0.020.. \n",
      "Epoch: 37/100..  Training Loss: 0.020..  Test Loss: 0.020.. \n",
      "Epoch: 38/100..  Training Loss: 0.020..  Test Loss: 0.020.. \n",
      "Epoch: 39/100..  Training Loss: 0.019..  Test Loss: 0.018.. \n",
      "Epoch: 40/100..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 41/100..  Training Loss: 0.018..  Test Loss: 0.017.. \n",
      "Epoch: 42/100..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 43/100..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 44/100..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 45/100..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 46/100..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 47/100..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 48/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 49/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 50/100..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 51/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 52/100..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 53/100..  Training Loss: 0.014..  Test Loss: 0.012.. \n",
      "Epoch: 54/100..  Training Loss: 0.012..  Test Loss: 0.011.. \n",
      "Epoch: 55/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 56/100..  Training Loss: 0.013..  Test Loss: 0.012.. \n",
      "Epoch: 57/100..  Training Loss: 0.012..  Test Loss: 0.010.. \n",
      "Epoch: 58/100..  Training Loss: 0.010..  Test Loss: 0.010.. \n",
      "Epoch: 59/100..  Training Loss: 0.010..  Test Loss: 0.010.. \n",
      "Epoch: 60/100..  Training Loss: 0.010..  Test Loss: 0.010.. \n",
      "Epoch: 61/100..  Training Loss: 0.010..  Test Loss: 0.010.. \n",
      "Epoch: 62/100..  Training Loss: 0.010..  Test Loss: 0.009.. \n",
      "Epoch: 63/100..  Training Loss: 0.010..  Test Loss: 0.008.. \n",
      "Epoch: 64/100..  Training Loss: 0.010..  Test Loss: 0.009.. \n",
      "Epoch: 65/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 66/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 67/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 68/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 69/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 70/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 71/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 72/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 73/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 74/100..  Training Loss: 0.007..  Test Loss: 0.008.. \n",
      "Epoch: 75/100..  Training Loss: 0.008..  Test Loss: 0.009.. \n",
      "Epoch: 76/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 77/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 78/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 79/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 80/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 81/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 82/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 83/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 84/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 85/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 86/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 87/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 88/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 89/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 90/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 91/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 92/100..  Training Loss: 0.011..  Test Loss: 0.007.. \n",
      "Epoch: 93/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 94/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 95/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 96/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 97/100..  Training Loss: 0.006..  Test Loss: 0.007.. \n",
      "Epoch: 98/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 99/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 100/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Classifier used here is : 5-layered\n",
      "Correct benign is 10307 \n",
      " correct malicious is 7780 \n",
      " converted to benign is  3662\n",
      "   bits_flipped    TP     TN    FN\n",
      "0             0  9146  10307  2296\n",
      "1             1  9002  10307  2440\n",
      "2             2  8758  10307  2684\n",
      "3             3  8610  10307  2832\n",
      "4             4  8515  10307  2927\n",
      "5             5  8411  10307  3031\n",
      "6             6  8325  10307  3117\n",
      "7             7  8196  10307  3246\n",
      "8             8  8078  10307  3364\n",
      "9             9  7931  10307  3511\n",
      "10           10  7780  10307  3662\n",
      "This is training the neural network classifier for temperature 10\n",
      "Epoch: 1/50..  Training Loss: 0.508..  Test Loss: 0.492..  Test Accuracy: 0.821\n",
      "Epoch: 2/50..  Training Loss: 0.491..  Test Loss: 0.490..  Test Accuracy: 0.823\n",
      "Epoch: 3/50..  Training Loss: 0.488..  Test Loss: 0.485..  Test Accuracy: 0.827\n",
      "Epoch: 4/50..  Training Loss: 0.487..  Test Loss: 0.486..  Test Accuracy: 0.827\n",
      "Epoch: 5/50..  Training Loss: 0.485..  Test Loss: 0.483..  Test Accuracy: 0.830\n",
      "Epoch: 6/50..  Training Loss: 0.487..  Test Loss: 0.481..  Test Accuracy: 0.832\n",
      "Epoch: 7/50..  Training Loss: 0.483..  Test Loss: 0.484..  Test Accuracy: 0.829\n",
      "Epoch: 8/50..  Training Loss: 0.482..  Test Loss: 0.484..  Test Accuracy: 0.829\n",
      "Epoch: 9/50..  Training Loss: 0.482..  Test Loss: 0.480..  Test Accuracy: 0.833\n",
      "Epoch: 10/50..  Training Loss: 0.480..  Test Loss: 0.484..  Test Accuracy: 0.829\n",
      "Epoch: 11/50..  Training Loss: 0.479..  Test Loss: 0.481..  Test Accuracy: 0.832\n",
      "Epoch: 12/50..  Training Loss: 0.479..  Test Loss: 0.477..  Test Accuracy: 0.836\n",
      "Epoch: 13/50..  Training Loss: 0.478..  Test Loss: 0.476..  Test Accuracy: 0.837\n",
      "Epoch: 14/50..  Training Loss: 0.478..  Test Loss: 0.476..  Test Accuracy: 0.837\n",
      "Epoch: 15/50..  Training Loss: 0.477..  Test Loss: 0.475..  Test Accuracy: 0.838\n",
      "Epoch: 16/50..  Training Loss: 0.477..  Test Loss: 0.473..  Test Accuracy: 0.840\n",
      "Epoch: 17/50..  Training Loss: 0.475..  Test Loss: 0.478..  Test Accuracy: 0.835\n",
      "Epoch: 18/50..  Training Loss: 0.477..  Test Loss: 0.477..  Test Accuracy: 0.836\n",
      "Epoch: 19/50..  Training Loss: 0.473..  Test Loss: 0.471..  Test Accuracy: 0.842\n",
      "Epoch: 20/50..  Training Loss: 0.474..  Test Loss: 0.472..  Test Accuracy: 0.841\n",
      "Epoch: 21/50..  Training Loss: 0.472..  Test Loss: 0.475..  Test Accuracy: 0.838\n",
      "Epoch: 22/50..  Training Loss: 0.471..  Test Loss: 0.469..  Test Accuracy: 0.844\n",
      "Epoch: 23/50..  Training Loss: 0.471..  Test Loss: 0.470..  Test Accuracy: 0.843\n",
      "Epoch: 24/50..  Training Loss: 0.470..  Test Loss: 0.470..  Test Accuracy: 0.843\n",
      "Epoch: 25/50..  Training Loss: 0.471..  Test Loss: 0.468..  Test Accuracy: 0.845\n",
      "Epoch: 26/50..  Training Loss: 0.473..  Test Loss: 0.476..  Test Accuracy: 0.837\n",
      "Epoch: 27/50..  Training Loss: 0.472..  Test Loss: 0.469..  Test Accuracy: 0.844\n",
      "Epoch: 28/50..  Training Loss: 0.470..  Test Loss: 0.469..  Test Accuracy: 0.844\n",
      "Epoch: 29/50..  Training Loss: 0.469..  Test Loss: 0.468..  Test Accuracy: 0.846\n",
      "Epoch: 30/50..  Training Loss: 0.468..  Test Loss: 0.469..  Test Accuracy: 0.844\n",
      "Epoch: 31/50..  Training Loss: 0.468..  Test Loss: 0.469..  Test Accuracy: 0.844\n",
      "Epoch: 32/50..  Training Loss: 0.467..  Test Loss: 0.469..  Test Accuracy: 0.844\n",
      "Epoch: 33/50..  Training Loss: 0.470..  Test Loss: 0.467..  Test Accuracy: 0.846\n",
      "Epoch: 34/50..  Training Loss: 0.467..  Test Loss: 0.466..  Test Accuracy: 0.847\n",
      "Epoch: 35/50..  Training Loss: 0.467..  Test Loss: 0.466..  Test Accuracy: 0.847\n",
      "Epoch: 36/50..  Training Loss: 0.467..  Test Loss: 0.467..  Test Accuracy: 0.845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37/50..  Training Loss: 0.467..  Test Loss: 0.467..  Test Accuracy: 0.846\n",
      "Epoch: 38/50..  Training Loss: 0.466..  Test Loss: 0.465..  Test Accuracy: 0.848\n",
      "Epoch: 39/50..  Training Loss: 0.465..  Test Loss: 0.465..  Test Accuracy: 0.848\n",
      "Epoch: 40/50..  Training Loss: 0.466..  Test Loss: 0.465..  Test Accuracy: 0.848\n",
      "Epoch: 41/50..  Training Loss: 0.466..  Test Loss: 0.466..  Test Accuracy: 0.847\n",
      "Epoch: 42/50..  Training Loss: 0.464..  Test Loss: 0.464..  Test Accuracy: 0.850\n",
      "Epoch: 43/50..  Training Loss: 0.464..  Test Loss: 0.464..  Test Accuracy: 0.849\n",
      "Epoch: 44/50..  Training Loss: 0.464..  Test Loss: 0.464..  Test Accuracy: 0.849\n",
      "Epoch: 45/50..  Training Loss: 0.465..  Test Loss: 0.463..  Test Accuracy: 0.850\n",
      "Epoch: 46/50..  Training Loss: 0.463..  Test Loss: 0.463..  Test Accuracy: 0.850\n",
      "Epoch: 47/50..  Training Loss: 0.463..  Test Loss: 0.462..  Test Accuracy: 0.851\n",
      "Epoch: 48/50..  Training Loss: 0.463..  Test Loss: 0.462..  Test Accuracy: 0.851\n",
      "Epoch: 49/50..  Training Loss: 0.463..  Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 50/50..  Training Loss: 0.463..  Test Loss: 0.463..  Test Accuracy: 0.851\n",
      "The length of the dataset is 22884\n",
      "Shape of X is (22884, 273) and shape of y_probs is (22884, 2)\n",
      "Epoch: 1/100..  Training Loss: 0.247..  Test Loss: 0.247.. \n",
      "Epoch: 2/100..  Training Loss: 0.247..  Test Loss: 0.247.. \n",
      "Epoch: 3/100..  Training Loss: 0.247..  Test Loss: 0.247.. \n",
      "Epoch: 4/100..  Training Loss: 0.247..  Test Loss: 0.246.. \n",
      "Epoch: 5/100..  Training Loss: 0.246..  Test Loss: 0.246.. \n",
      "Epoch: 6/100..  Training Loss: 0.246..  Test Loss: 0.246.. \n",
      "Epoch: 7/100..  Training Loss: 0.246..  Test Loss: 0.245.. \n",
      "Epoch: 8/100..  Training Loss: 0.245..  Test Loss: 0.245.. \n",
      "Epoch: 9/100..  Training Loss: 0.245..  Test Loss: 0.244.. \n",
      "Epoch: 10/100..  Training Loss: 0.244..  Test Loss: 0.243.. \n",
      "Epoch: 11/100..  Training Loss: 0.242..  Test Loss: 0.241.. \n",
      "Epoch: 12/100..  Training Loss: 0.239..  Test Loss: 0.235.. \n",
      "Epoch: 13/100..  Training Loss: 0.226..  Test Loss: 0.212.. \n",
      "Epoch: 14/100..  Training Loss: 0.182..  Test Loss: 0.151.. \n",
      "Epoch: 15/100..  Training Loss: 0.119..  Test Loss: 0.086.. \n",
      "Epoch: 16/100..  Training Loss: 0.069..  Test Loss: 0.061.. \n",
      "Epoch: 17/100..  Training Loss: 0.056..  Test Loss: 0.052.. \n",
      "Epoch: 18/100..  Training Loss: 0.051..  Test Loss: 0.049.. \n",
      "Epoch: 19/100..  Training Loss: 0.047..  Test Loss: 0.046.. \n",
      "Epoch: 20/100..  Training Loss: 0.044..  Test Loss: 0.043.. \n",
      "Epoch: 21/100..  Training Loss: 0.043..  Test Loss: 0.041.. \n",
      "Epoch: 22/100..  Training Loss: 0.040..  Test Loss: 0.040.. \n",
      "Epoch: 23/100..  Training Loss: 0.039..  Test Loss: 0.039.. \n",
      "Epoch: 24/100..  Training Loss: 0.038..  Test Loss: 0.037.. \n",
      "Epoch: 25/100..  Training Loss: 0.037..  Test Loss: 0.036.. \n",
      "Epoch: 26/100..  Training Loss: 0.035..  Test Loss: 0.035.. \n",
      "Epoch: 27/100..  Training Loss: 0.035..  Test Loss: 0.035.. \n",
      "Epoch: 28/100..  Training Loss: 0.034..  Test Loss: 0.034.. \n",
      "Epoch: 29/100..  Training Loss: 0.033..  Test Loss: 0.033.. \n",
      "Epoch: 30/100..  Training Loss: 0.032..  Test Loss: 0.031.. \n",
      "Epoch: 31/100..  Training Loss: 0.031..  Test Loss: 0.031.. \n",
      "Epoch: 32/100..  Training Loss: 0.031..  Test Loss: 0.031.. \n",
      "Epoch: 33/100..  Training Loss: 0.031..  Test Loss: 0.030.. \n",
      "Epoch: 34/100..  Training Loss: 0.030..  Test Loss: 0.029.. \n",
      "Epoch: 35/100..  Training Loss: 0.028..  Test Loss: 0.027.. \n",
      "Epoch: 36/100..  Training Loss: 0.027..  Test Loss: 0.026.. \n",
      "Epoch: 37/100..  Training Loss: 0.025..  Test Loss: 0.024.. \n",
      "Epoch: 38/100..  Training Loss: 0.024..  Test Loss: 0.023.. \n",
      "Epoch: 39/100..  Training Loss: 0.022..  Test Loss: 0.023.. \n",
      "Epoch: 40/100..  Training Loss: 0.022..  Test Loss: 0.021.. \n",
      "Epoch: 41/100..  Training Loss: 0.021..  Test Loss: 0.021.. \n",
      "Epoch: 42/100..  Training Loss: 0.021..  Test Loss: 0.021.. \n",
      "Epoch: 43/100..  Training Loss: 0.020..  Test Loss: 0.020.. \n",
      "Epoch: 44/100..  Training Loss: 0.020..  Test Loss: 0.020.. \n",
      "Epoch: 45/100..  Training Loss: 0.019..  Test Loss: 0.019.. \n",
      "Epoch: 46/100..  Training Loss: 0.019..  Test Loss: 0.018.. \n",
      "Epoch: 47/100..  Training Loss: 0.018..  Test Loss: 0.017.. \n",
      "Epoch: 48/100..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 49/100..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 50/100..  Training Loss: 0.018..  Test Loss: 0.017.. \n",
      "Epoch: 51/100..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 52/100..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 53/100..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 54/100..  Training Loss: 0.013..  Test Loss: 0.012.. \n",
      "Epoch: 55/100..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 56/100..  Training Loss: 0.012..  Test Loss: 0.011.. \n",
      "Epoch: 57/100..  Training Loss: 0.011..  Test Loss: 0.011.. \n",
      "Epoch: 58/100..  Training Loss: 0.012..  Test Loss: 0.011.. \n",
      "Epoch: 59/100..  Training Loss: 0.011..  Test Loss: 0.010.. \n",
      "Epoch: 60/100..  Training Loss: 0.011..  Test Loss: 0.010.. \n",
      "Epoch: 61/100..  Training Loss: 0.010..  Test Loss: 0.010.. \n",
      "Epoch: 62/100..  Training Loss: 0.010..  Test Loss: 0.010.. \n",
      "Epoch: 63/100..  Training Loss: 0.010..  Test Loss: 0.011.. \n",
      "Epoch: 64/100..  Training Loss: 0.010..  Test Loss: 0.009.. \n",
      "Epoch: 65/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 66/100..  Training Loss: 0.009..  Test Loss: 0.012.. \n",
      "Epoch: 67/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 68/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 69/100..  Training Loss: 0.009..  Test Loss: 0.009.. \n",
      "Epoch: 70/100..  Training Loss: 0.008..  Test Loss: 0.009.. \n",
      "Epoch: 71/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 72/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 73/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 74/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 75/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 76/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 77/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 78/100..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 79/100..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 80/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 81/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 82/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 83/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 84/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 85/100..  Training Loss: 0.007..  Test Loss: 0.008.. \n",
      "Epoch: 86/100..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 87/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 88/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 89/100..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 90/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 91/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 92/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 93/100..  Training Loss: 0.006..  Test Loss: 0.007.. \n",
      "Epoch: 94/100..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 95/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 96/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 97/100..  Training Loss: 0.006..  Test Loss: 0.007.. \n",
      "Epoch: 98/100..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 99/100..  Training Loss: 0.006..  Test Loss: 0.007.. \n",
      "Epoch: 100/100..  Training Loss: 0.006..  Test Loss: 0.005.. \n",
      "Classifier used here is : 5-layered\n",
      "Correct benign is 10322 \n",
      " correct malicious is 7459 \n",
      " converted to benign is  3983\n",
      "   bits_flipped    TP     TN    FN\n",
      "0             0  9065  10322  2377\n",
      "1             1  8869  10322  2573\n",
      "2             2  8582  10322  2860\n",
      "3             3  8406  10322  3036\n",
      "4             4  8245  10322  3197\n",
      "5             5  8106  10322  3336\n",
      "6             6  7959  10322  3483\n",
      "7             7  7822  10322  3620\n",
      "8             8  7700  10322  3742\n",
      "9             9  7569  10322  3873\n",
      "10           10  7459  10322  3983\n"
     ]
    }
   ],
   "source": [
    "for t in [1, 5,10]:\n",
    "    epochs=50\n",
    "    \n",
    "    print(\"This is training the neural network classifier for temperature {}\".format(t))\n",
    "    \n",
    "    model_class= model_5(t)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model_class.parameters(), lr=0.001)\n",
    "    \n",
    "    df=pd.read_csv('../Resampled_Datasets_Attack/5-layered'+'_resamp.csv')\n",
    "    X=df.iloc[:,:-1].values\n",
    "    y=df.iloc[:,-1].values\n",
    "            \n",
    "    train_dataset = Datasetcustom(X, y)\n",
    "    test_dataset = Datasetcustom(X, y)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=20, shuffle=True)\n",
    "\n",
    "    train_losses, test_losses = [], []\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            log_ps = model_class(images)\n",
    "    #         print(log_ps)\n",
    "            loss = criterion(log_ps, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        else:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "\n",
    "            # Turn off gradients for validation, saves memory and computations\n",
    "            with torch.no_grad():\n",
    "                for images, labels in test_loader:\n",
    "                    log_ps = model_class(images)\n",
    "                    test_loss += criterion(log_ps, labels)\n",
    "\n",
    "                    top_p, top_class = log_ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "            train_losses.append(running_loss/len(train_loader))\n",
    "            test_losses.append(test_loss/len(test_loader))\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))\n",
    "            \n",
    "    print(\"The length of the dataset is {}\".format(len(train_dataset)))\n",
    "    probs_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True)\n",
    "    train_iter = iter(probs_loader)\n",
    "    images, labels = train_iter.next()\n",
    "    y_probs= model_class(images)\n",
    "    y_probs=y_probs.detach().numpy()\n",
    "    X_probs=images.detach().numpy()\n",
    "    \n",
    "    print(\"Shape of X is {} and shape of y_probs is {}\".format(X.shape, y_probs.shape))\n",
    "    X_train, X_test, y_train, y_test =X_probs,X_probs,  y_probs ,  y_probs\n",
    "    \n",
    "    train_dataset_dist = Datasetcustom(X_train, y_train)\n",
    "    test_dataset_dist= Datasetcustom(X_test, y_test)\n",
    "    train_loader_dist = DataLoader(train_dataset_dist, batch_size=20, shuffle=True)\n",
    "    test_loader_dist = DataLoader(test_dataset_dist, batch_size=20, shuffle=True)\n",
    "    \n",
    "    model_reg=model_5dist(t)\n",
    "    criterion_dist =  nn.MSELoss()\n",
    "    optimizer_dist = optim.SGD(model_reg.parameters(), lr=0.02)\n",
    "\n",
    "    epochs= 100\n",
    "    train_losses, test_losses = [], []\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        for images, labels in train_loader_dist:\n",
    "\n",
    "            optimizer_dist.zero_grad()\n",
    "            log_ps = model_reg(images)\n",
    "            loss = criterion_dist(log_ps, labels)\n",
    "            loss.backward()\n",
    "            optimizer_dist.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        else:\n",
    "            test_loss = 0\n",
    "\n",
    "            # Turn off gradients for validation, saves memory and computations\n",
    "            with torch.no_grad():\n",
    "                for images, labels in test_loader_dist:\n",
    "                    log_ps = model_reg(images)\n",
    "                    test_loss += criterion_dist(log_ps, labels)\n",
    "\n",
    "            train_losses.append(running_loss/len(train_loader_dist))\n",
    "            test_losses.append(test_loss/len(test_loader_dist))\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader_dist)),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader_dist)))\n",
    "    \n",
    "    Models={ \"5-layered\": model_reg}\n",
    "    model=torch.load('../trained_models/Train-512-256-64.pth')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    #Attack with original attacker after retraining\n",
    "    for Algorithm in Models:\n",
    "            df1=pd.DataFrame(columns = ['bits_flipped','TP', 'TN','FN'])\n",
    "            for i in range(0,11):\n",
    "                df1=df1.append(pd.Series([i, 11442, 0, 0], index= df1.columns), ignore_index=True )\n",
    "            print(\"Classifier used here is : {}\".format(Algorithm))\n",
    "            classifier= Models[Algorithm]\n",
    "            correct_benign=0\n",
    "            correct_malicious=0\n",
    "            convert_to_benign=0\n",
    "            \n",
    "            df=pd.read_csv('../Resampled_Datasets_Attack/5-layered'+'_resamp.csv')\n",
    "            X=df.iloc[:,:-1].values\n",
    "            y=df.iloc[:,-1].values\n",
    "            \n",
    "            target_model= Models[Algorithm]\n",
    "            test_dataset= Datasetcustom(X, y)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "            for images, labels in test_loader:\n",
    "                images.requires_grad = True\n",
    "                model.zero_grad()\n",
    "                output = model(images)\n",
    "                y_pred = target_model(images)\n",
    "                loss = criterion(output, labels)\n",
    "                loss.backward()\n",
    "                data_grad = images.grad.data\n",
    "                if  y_pred[0][1]>y_pred[0][0] and labels[0]==1: #predicted malicious\n",
    "                    grad_list=[]\n",
    "                    for i in range(273):\n",
    "                        if images[0][i]==0:\n",
    "                            grad_list.append((data_grad[0][i],i))\n",
    "                    grad_list.sort(key = lambda x: x[0], reverse=True)\n",
    "                    flag=0\n",
    "                    for i in range(0,10):\n",
    "                        images[0][grad_list[i][1]]=1\n",
    "                        y_pred = target_model(images)\n",
    "                        if y_pred[0][0]>y_pred[0][1]:\n",
    "                            for j in range(i,10):  #converted in i+1 flips, hence all bits>=i+1, the FN will increase\n",
    "                                df1.iloc[j+1,3]+=1\n",
    "                                df1.iloc[j+1,1]-=1\n",
    "                            flag=1\n",
    "                            convert_to_benign+=1\n",
    "                            break\n",
    "                    if flag==0:          #Even after 10 flips, unable to convert to benignm update malicious counter\n",
    "                        correct_malicious+=1\n",
    "                elif y_pred[0][0]>y_pred[0][1] and labels[0]==1:  #If predicted as benign but is malicious\n",
    "                    for j in range(0,11):\n",
    "                        df1.iloc[j,3]+=1\n",
    "                        df1.iloc[j,1]-=1\n",
    "                    convert_to_benign+=1\n",
    "                elif  y_pred[0][0]>y_pred[0][1] and labels[0]==0:  #if predicted benign correctly\n",
    "                    for j in range(0,11):\n",
    "                        df1.iloc[j,2]+=1\n",
    "                    correct_benign+=1\n",
    "\n",
    "            print(\"Correct benign is {} \\n correct malicious is {} \\n converted to benign is  {}\".format(correct_benign, correct_malicious, convert_to_benign))\n",
    "    #         print(\"Final Accuracy is {:.3f} with max {} bits flipped\".format((correct_benign+5553-convert_benign)/11274, num_bits))\n",
    "            print(df1)\n",
    "            df1.to_csv(\"../Hybrid_Distillation/\"+str(Algorithm)+\"_Distillation_\"+str(t)+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = nn.Sequential(nn.Linear(195, 512),\n",
    "#                       nn.ReLU(),\n",
    "#                       nn.Dropout(0.4),\n",
    "#                       nn.Linear(512, 256),\n",
    "#                       nn.ReLU(),\n",
    "#                       nn.Dropout(0.4),\n",
    "#                       nn.Linear(256, 64),\n",
    "#                       nn.ReLU(),\n",
    "#                       nn.Dropout(0.4),\n",
    "#                       nn.Linear(64, 2),\n",
    "#                       nn.Softmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self,t):\n",
    "        super(model, self).__init__()\n",
    "        self.t=t\n",
    "        self.l1=nn.Linear(195, 512)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.l2=nn.Linear(512, 256)\n",
    "        self.l3=nn.Linear(256, 64)\n",
    "        self.l4=nn.Linear(64, 2)\n",
    "        self.dropout= nn.Dropout(0.4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.l1(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l2(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l3(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l4(x)\n",
    "        x= nn.Softmax(dim=1)(x/self.t)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= model(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/150..  Training Loss: 0.693..  Test Loss: 0.693..  Test Accuracy: 0.502\n",
      "Epoch: 2/150..  Training Loss: 0.693..  Test Loss: 0.693..  Test Accuracy: 0.510\n",
      "Epoch: 3/150..  Training Loss: 0.693..  Test Loss: 0.693..  Test Accuracy: 0.547\n",
      "Epoch: 4/150..  Training Loss: 0.693..  Test Loss: 0.692..  Test Accuracy: 0.625\n",
      "Epoch: 5/150..  Training Loss: 0.692..  Test Loss: 0.692..  Test Accuracy: 0.688\n",
      "Epoch: 6/150..  Training Loss: 0.692..  Test Loss: 0.691..  Test Accuracy: 0.707\n",
      "Epoch: 7/150..  Training Loss: 0.691..  Test Loss: 0.690..  Test Accuracy: 0.678\n",
      "Epoch: 8/150..  Training Loss: 0.688..  Test Loss: 0.687..  Test Accuracy: 0.627\n",
      "Epoch: 9/150..  Training Loss: 0.683..  Test Loss: 0.678..  Test Accuracy: 0.598\n",
      "Epoch: 10/150..  Training Loss: 0.668..  Test Loss: 0.652..  Test Accuracy: 0.655\n",
      "Epoch: 11/150..  Training Loss: 0.629..  Test Loss: 0.604..  Test Accuracy: 0.779\n",
      "Epoch: 12/150..  Training Loss: 0.584..  Test Loss: 0.563..  Test Accuracy: 0.844\n",
      "Epoch: 13/150..  Training Loss: 0.541..  Test Loss: 0.519..  Test Accuracy: 0.876\n",
      "Epoch: 14/150..  Training Loss: 0.495..  Test Loss: 0.473..  Test Accuracy: 0.884\n",
      "Epoch: 15/150..  Training Loss: 0.460..  Test Loss: 0.449..  Test Accuracy: 0.884\n",
      "Epoch: 16/150..  Training Loss: 0.441..  Test Loss: 0.436..  Test Accuracy: 0.890\n",
      "Epoch: 17/150..  Training Loss: 0.432..  Test Loss: 0.427..  Test Accuracy: 0.893\n",
      "Epoch: 18/150..  Training Loss: 0.426..  Test Loss: 0.422..  Test Accuracy: 0.896\n",
      "Epoch: 19/150..  Training Loss: 0.421..  Test Loss: 0.419..  Test Accuracy: 0.898\n",
      "Epoch: 20/150..  Training Loss: 0.418..  Test Loss: 0.415..  Test Accuracy: 0.901\n",
      "Epoch: 21/150..  Training Loss: 0.414..  Test Loss: 0.413..  Test Accuracy: 0.903\n",
      "Epoch: 22/150..  Training Loss: 0.411..  Test Loss: 0.411..  Test Accuracy: 0.904\n",
      "Epoch: 23/150..  Training Loss: 0.410..  Test Loss: 0.409..  Test Accuracy: 0.906\n",
      "Epoch: 24/150..  Training Loss: 0.407..  Test Loss: 0.407..  Test Accuracy: 0.908\n",
      "Epoch: 25/150..  Training Loss: 0.407..  Test Loss: 0.406..  Test Accuracy: 0.908\n",
      "Epoch: 26/150..  Training Loss: 0.404..  Test Loss: 0.405..  Test Accuracy: 0.908\n",
      "Epoch: 27/150..  Training Loss: 0.405..  Test Loss: 0.403..  Test Accuracy: 0.910\n",
      "Epoch: 28/150..  Training Loss: 0.401..  Test Loss: 0.401..  Test Accuracy: 0.913\n",
      "Epoch: 29/150..  Training Loss: 0.401..  Test Loss: 0.401..  Test Accuracy: 0.912\n",
      "Epoch: 30/150..  Training Loss: 0.401..  Test Loss: 0.400..  Test Accuracy: 0.915\n",
      "Epoch: 31/150..  Training Loss: 0.400..  Test Loss: 0.400..  Test Accuracy: 0.913\n",
      "Epoch: 32/150..  Training Loss: 0.399..  Test Loss: 0.398..  Test Accuracy: 0.915\n",
      "Epoch: 33/150..  Training Loss: 0.399..  Test Loss: 0.397..  Test Accuracy: 0.916\n",
      "Epoch: 34/150..  Training Loss: 0.397..  Test Loss: 0.396..  Test Accuracy: 0.918\n",
      "Epoch: 35/150..  Training Loss: 0.397..  Test Loss: 0.396..  Test Accuracy: 0.918\n",
      "Epoch: 36/150..  Training Loss: 0.396..  Test Loss: 0.396..  Test Accuracy: 0.916\n",
      "Epoch: 37/150..  Training Loss: 0.394..  Test Loss: 0.394..  Test Accuracy: 0.919\n",
      "Epoch: 38/150..  Training Loss: 0.393..  Test Loss: 0.393..  Test Accuracy: 0.921\n",
      "Epoch: 39/150..  Training Loss: 0.393..  Test Loss: 0.392..  Test Accuracy: 0.920\n",
      "Epoch: 40/150..  Training Loss: 0.392..  Test Loss: 0.391..  Test Accuracy: 0.922\n",
      "Epoch: 41/150..  Training Loss: 0.391..  Test Loss: 0.390..  Test Accuracy: 0.924\n",
      "Epoch: 42/150..  Training Loss: 0.390..  Test Loss: 0.389..  Test Accuracy: 0.924\n",
      "Epoch: 43/150..  Training Loss: 0.390..  Test Loss: 0.388..  Test Accuracy: 0.925\n",
      "Epoch: 44/150..  Training Loss: 0.388..  Test Loss: 0.388..  Test Accuracy: 0.925\n",
      "Epoch: 45/150..  Training Loss: 0.388..  Test Loss: 0.387..  Test Accuracy: 0.927\n",
      "Epoch: 46/150..  Training Loss: 0.387..  Test Loss: 0.387..  Test Accuracy: 0.928\n",
      "Epoch: 47/150..  Training Loss: 0.386..  Test Loss: 0.386..  Test Accuracy: 0.928\n",
      "Epoch: 48/150..  Training Loss: 0.385..  Test Loss: 0.385..  Test Accuracy: 0.930\n",
      "Epoch: 49/150..  Training Loss: 0.385..  Test Loss: 0.385..  Test Accuracy: 0.929\n",
      "Epoch: 50/150..  Training Loss: 0.383..  Test Loss: 0.384..  Test Accuracy: 0.930\n",
      "Epoch: 51/150..  Training Loss: 0.382..  Test Loss: 0.383..  Test Accuracy: 0.931\n",
      "Epoch: 52/150..  Training Loss: 0.382..  Test Loss: 0.381..  Test Accuracy: 0.932\n",
      "Epoch: 53/150..  Training Loss: 0.381..  Test Loss: 0.381..  Test Accuracy: 0.933\n",
      "Epoch: 54/150..  Training Loss: 0.381..  Test Loss: 0.379..  Test Accuracy: 0.935\n",
      "Epoch: 55/150..  Training Loss: 0.380..  Test Loss: 0.379..  Test Accuracy: 0.934\n",
      "Epoch: 56/150..  Training Loss: 0.379..  Test Loss: 0.378..  Test Accuracy: 0.937\n",
      "Epoch: 57/150..  Training Loss: 0.378..  Test Loss: 0.378..  Test Accuracy: 0.937\n",
      "Epoch: 58/150..  Training Loss: 0.377..  Test Loss: 0.377..  Test Accuracy: 0.937\n",
      "Epoch: 59/150..  Training Loss: 0.377..  Test Loss: 0.376..  Test Accuracy: 0.939\n",
      "Epoch: 60/150..  Training Loss: 0.376..  Test Loss: 0.375..  Test Accuracy: 0.938\n",
      "Epoch: 61/150..  Training Loss: 0.375..  Test Loss: 0.374..  Test Accuracy: 0.941\n",
      "Epoch: 62/150..  Training Loss: 0.374..  Test Loss: 0.373..  Test Accuracy: 0.942\n",
      "Epoch: 63/150..  Training Loss: 0.373..  Test Loss: 0.373..  Test Accuracy: 0.942\n",
      "Epoch: 64/150..  Training Loss: 0.373..  Test Loss: 0.372..  Test Accuracy: 0.943\n",
      "Epoch: 65/150..  Training Loss: 0.372..  Test Loss: 0.371..  Test Accuracy: 0.944\n",
      "Epoch: 66/150..  Training Loss: 0.372..  Test Loss: 0.371..  Test Accuracy: 0.944\n",
      "Epoch: 67/150..  Training Loss: 0.370..  Test Loss: 0.371..  Test Accuracy: 0.944\n",
      "Epoch: 68/150..  Training Loss: 0.372..  Test Loss: 0.370..  Test Accuracy: 0.944\n",
      "Epoch: 69/150..  Training Loss: 0.370..  Test Loss: 0.370..  Test Accuracy: 0.946\n",
      "Epoch: 70/150..  Training Loss: 0.370..  Test Loss: 0.370..  Test Accuracy: 0.945\n",
      "Epoch: 71/150..  Training Loss: 0.369..  Test Loss: 0.369..  Test Accuracy: 0.946\n",
      "Epoch: 72/150..  Training Loss: 0.369..  Test Loss: 0.368..  Test Accuracy: 0.947\n",
      "Epoch: 73/150..  Training Loss: 0.368..  Test Loss: 0.367..  Test Accuracy: 0.949\n",
      "Epoch: 74/150..  Training Loss: 0.368..  Test Loss: 0.368..  Test Accuracy: 0.947\n",
      "Epoch: 75/150..  Training Loss: 0.367..  Test Loss: 0.367..  Test Accuracy: 0.949\n",
      "Epoch: 76/150..  Training Loss: 0.367..  Test Loss: 0.367..  Test Accuracy: 0.949\n",
      "Epoch: 77/150..  Training Loss: 0.367..  Test Loss: 0.365..  Test Accuracy: 0.949\n",
      "Epoch: 78/150..  Training Loss: 0.365..  Test Loss: 0.366..  Test Accuracy: 0.949\n",
      "Epoch: 79/150..  Training Loss: 0.366..  Test Loss: 0.365..  Test Accuracy: 0.949\n",
      "Epoch: 80/150..  Training Loss: 0.365..  Test Loss: 0.365..  Test Accuracy: 0.950\n",
      "Epoch: 81/150..  Training Loss: 0.365..  Test Loss: 0.365..  Test Accuracy: 0.950\n",
      "Epoch: 82/150..  Training Loss: 0.364..  Test Loss: 0.364..  Test Accuracy: 0.951\n",
      "Epoch: 83/150..  Training Loss: 0.364..  Test Loss: 0.364..  Test Accuracy: 0.951\n",
      "Epoch: 84/150..  Training Loss: 0.364..  Test Loss: 0.364..  Test Accuracy: 0.951\n",
      "Epoch: 85/150..  Training Loss: 0.364..  Test Loss: 0.363..  Test Accuracy: 0.952\n",
      "Epoch: 86/150..  Training Loss: 0.363..  Test Loss: 0.363..  Test Accuracy: 0.953\n",
      "Epoch: 87/150..  Training Loss: 0.363..  Test Loss: 0.363..  Test Accuracy: 0.951\n",
      "Epoch: 88/150..  Training Loss: 0.363..  Test Loss: 0.363..  Test Accuracy: 0.952\n",
      "Epoch: 89/150..  Training Loss: 0.363..  Test Loss: 0.363..  Test Accuracy: 0.952\n",
      "Epoch: 90/150..  Training Loss: 0.362..  Test Loss: 0.363..  Test Accuracy: 0.952\n",
      "Epoch: 91/150..  Training Loss: 0.362..  Test Loss: 0.362..  Test Accuracy: 0.953\n",
      "Epoch: 92/150..  Training Loss: 0.362..  Test Loss: 0.361..  Test Accuracy: 0.953\n",
      "Epoch: 93/150..  Training Loss: 0.361..  Test Loss: 0.361..  Test Accuracy: 0.953\n",
      "Epoch: 94/150..  Training Loss: 0.361..  Test Loss: 0.362..  Test Accuracy: 0.953\n",
      "Epoch: 95/150..  Training Loss: 0.362..  Test Loss: 0.361..  Test Accuracy: 0.955\n",
      "Epoch: 96/150..  Training Loss: 0.361..  Test Loss: 0.361..  Test Accuracy: 0.954\n",
      "Epoch: 97/150..  Training Loss: 0.360..  Test Loss: 0.360..  Test Accuracy: 0.955\n",
      "Epoch: 98/150..  Training Loss: 0.360..  Test Loss: 0.360..  Test Accuracy: 0.955\n",
      "Epoch: 99/150..  Training Loss: 0.360..  Test Loss: 0.360..  Test Accuracy: 0.955\n",
      "Epoch: 100/150..  Training Loss: 0.361..  Test Loss: 0.360..  Test Accuracy: 0.955\n",
      "Epoch: 101/150..  Training Loss: 0.360..  Test Loss: 0.359..  Test Accuracy: 0.956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 102/150..  Training Loss: 0.360..  Test Loss: 0.359..  Test Accuracy: 0.955\n",
      "Epoch: 103/150..  Training Loss: 0.360..  Test Loss: 0.359..  Test Accuracy: 0.956\n",
      "Epoch: 104/150..  Training Loss: 0.360..  Test Loss: 0.359..  Test Accuracy: 0.956\n",
      "Epoch: 105/150..  Training Loss: 0.359..  Test Loss: 0.358..  Test Accuracy: 0.956\n",
      "Epoch: 106/150..  Training Loss: 0.359..  Test Loss: 0.359..  Test Accuracy: 0.956\n",
      "Epoch: 107/150..  Training Loss: 0.358..  Test Loss: 0.359..  Test Accuracy: 0.955\n",
      "Epoch: 108/150..  Training Loss: 0.359..  Test Loss: 0.358..  Test Accuracy: 0.957\n",
      "Epoch: 109/150..  Training Loss: 0.359..  Test Loss: 0.359..  Test Accuracy: 0.956\n",
      "Epoch: 110/150..  Training Loss: 0.358..  Test Loss: 0.358..  Test Accuracy: 0.957\n",
      "Epoch: 111/150..  Training Loss: 0.358..  Test Loss: 0.358..  Test Accuracy: 0.956\n",
      "Epoch: 112/150..  Training Loss: 0.358..  Test Loss: 0.358..  Test Accuracy: 0.957\n",
      "Epoch: 113/150..  Training Loss: 0.358..  Test Loss: 0.357..  Test Accuracy: 0.957\n",
      "Epoch: 114/150..  Training Loss: 0.357..  Test Loss: 0.358..  Test Accuracy: 0.957\n",
      "Epoch: 115/150..  Training Loss: 0.358..  Test Loss: 0.356..  Test Accuracy: 0.958\n",
      "Epoch: 116/150..  Training Loss: 0.357..  Test Loss: 0.357..  Test Accuracy: 0.957\n",
      "Epoch: 117/150..  Training Loss: 0.357..  Test Loss: 0.357..  Test Accuracy: 0.958\n",
      "Epoch: 118/150..  Training Loss: 0.358..  Test Loss: 0.357..  Test Accuracy: 0.958\n",
      "Epoch: 119/150..  Training Loss: 0.357..  Test Loss: 0.357..  Test Accuracy: 0.958\n",
      "Epoch: 120/150..  Training Loss: 0.357..  Test Loss: 0.356..  Test Accuracy: 0.958\n",
      "Epoch: 121/150..  Training Loss: 0.357..  Test Loss: 0.356..  Test Accuracy: 0.959\n",
      "Epoch: 122/150..  Training Loss: 0.356..  Test Loss: 0.357..  Test Accuracy: 0.958\n",
      "Epoch: 123/150..  Training Loss: 0.356..  Test Loss: 0.355..  Test Accuracy: 0.959\n",
      "Epoch: 124/150..  Training Loss: 0.356..  Test Loss: 0.356..  Test Accuracy: 0.959\n",
      "Epoch: 125/150..  Training Loss: 0.356..  Test Loss: 0.355..  Test Accuracy: 0.959\n",
      "Epoch: 126/150..  Training Loss: 0.357..  Test Loss: 0.356..  Test Accuracy: 0.958\n",
      "Epoch: 127/150..  Training Loss: 0.356..  Test Loss: 0.355..  Test Accuracy: 0.959\n",
      "Epoch: 128/150..  Training Loss: 0.357..  Test Loss: 0.356..  Test Accuracy: 0.959\n",
      "Epoch: 129/150..  Training Loss: 0.355..  Test Loss: 0.355..  Test Accuracy: 0.960\n",
      "Epoch: 130/150..  Training Loss: 0.356..  Test Loss: 0.355..  Test Accuracy: 0.959\n",
      "Epoch: 131/150..  Training Loss: 0.355..  Test Loss: 0.356..  Test Accuracy: 0.959\n",
      "Epoch: 132/150..  Training Loss: 0.355..  Test Loss: 0.355..  Test Accuracy: 0.960\n",
      "Epoch: 133/150..  Training Loss: 0.355..  Test Loss: 0.355..  Test Accuracy: 0.960\n",
      "Epoch: 134/150..  Training Loss: 0.355..  Test Loss: 0.355..  Test Accuracy: 0.960\n",
      "Epoch: 135/150..  Training Loss: 0.355..  Test Loss: 0.355..  Test Accuracy: 0.959\n",
      "Epoch: 136/150..  Training Loss: 0.355..  Test Loss: 0.354..  Test Accuracy: 0.960\n",
      "Epoch: 137/150..  Training Loss: 0.355..  Test Loss: 0.354..  Test Accuracy: 0.960\n",
      "Epoch: 138/150..  Training Loss: 0.355..  Test Loss: 0.355..  Test Accuracy: 0.959\n",
      "Epoch: 139/150..  Training Loss: 0.354..  Test Loss: 0.355..  Test Accuracy: 0.960\n",
      "Epoch: 140/150..  Training Loss: 0.355..  Test Loss: 0.354..  Test Accuracy: 0.960\n",
      "Epoch: 141/150..  Training Loss: 0.355..  Test Loss: 0.354..  Test Accuracy: 0.961\n",
      "Epoch: 142/150..  Training Loss: 0.354..  Test Loss: 0.354..  Test Accuracy: 0.960\n",
      "Epoch: 143/150..  Training Loss: 0.354..  Test Loss: 0.354..  Test Accuracy: 0.960\n",
      "Epoch: 144/150..  Training Loss: 0.354..  Test Loss: 0.354..  Test Accuracy: 0.960\n",
      "Epoch: 145/150..  Training Loss: 0.354..  Test Loss: 0.354..  Test Accuracy: 0.960\n",
      "Epoch: 146/150..  Training Loss: 0.354..  Test Loss: 0.354..  Test Accuracy: 0.961\n",
      "Epoch: 147/150..  Training Loss: 0.354..  Test Loss: 0.354..  Test Accuracy: 0.960\n",
      "Epoch: 148/150..  Training Loss: 0.353..  Test Loss: 0.353..  Test Accuracy: 0.961\n",
      "Epoch: 149/150..  Training Loss: 0.354..  Test Loss: 0.354..  Test Accuracy: 0.961\n",
      "Epoch: 150/150..  Training Loss: 0.353..  Test Loss: 0.353..  Test Accuracy: 0.961\n"
     ]
    }
   ],
   "source": [
    "print_every = 40\n",
    "steps = 0\n",
    "epochs=150\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        log_ps = model(images)\n",
    "#         print(log_ps)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        # Turn off gradients for validation, saves memory and computations\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                log_ps = model(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                \n",
    "                top_p, top_class = log_ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                \n",
    "        train_losses.append(running_loss/len(train_loader))\n",
    "        test_losses.append(test_loss/len(test_loader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22884"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True)\n",
    "train_iter = iter(probs_loader)\n",
    "images, labels = train_iter.next()\n",
    "y_probs= model(images)\n",
    "y_probs=y_probs.detach().numpy()\n",
    "X_probs=images.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_probs=y_probs*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 2.8426713e-08],\n",
       "       [9.9999535e-01, 4.6982209e-06],\n",
       "       [9.9997330e-01, 2.6684507e-05],\n",
       "       [1.0025277e-03, 9.9899751e-01],\n",
       "       [1.4501101e-03, 9.9854988e-01],\n",
       "       [9.8613435e-01, 1.3865709e-02],\n",
       "       [7.0478147e-21, 1.0000000e+00],\n",
       "       [2.2800923e-07, 9.9999976e-01],\n",
       "       [9.9742079e-01, 2.5792010e-03],\n",
       "       [1.0000000e+00, 3.3603684e-09],\n",
       "       [8.1502325e-09, 1.0000000e+00],\n",
       "       [9.6177840e-01, 3.8221590e-02],\n",
       "       [1.8926028e-02, 9.8107392e-01],\n",
       "       [1.9067625e-07, 9.9999976e-01],\n",
       "       [9.9810481e-01, 1.8951703e-03],\n",
       "       [9.7716534e-01, 2.2834606e-02],\n",
       "       [1.0000000e+00, 4.1998034e-11],\n",
       "       [4.2117558e-02, 9.5788246e-01],\n",
       "       [2.7843312e-06, 9.9999726e-01],\n",
       "       [9.9960488e-01, 3.9517437e-04],\n",
       "       [1.0000000e+00, 4.1651380e-09],\n",
       "       [9.8969114e-01, 1.0308835e-02],\n",
       "       [2.7097034e-04, 9.9972898e-01],\n",
       "       [9.9302191e-01, 6.9781644e-03],\n",
       "       [9.6672332e-01, 3.3276655e-02],\n",
       "       [8.4123558e-06, 9.9999154e-01],\n",
       "       [1.0000000e+00, 8.4944665e-09],\n",
       "       [6.4908963e-05, 9.9993503e-01],\n",
       "       [1.0000000e+00, 2.0576273e-08],\n",
       "       [6.8336743e-01, 3.1663257e-01]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probs[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22884, 195)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22884, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =train_test_split(X_probs, y_probs, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_dist = Datasetcustom(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_dist= Datasetcustom(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_dist = DataLoader(train_dataset_dist, batch_size=20, shuffle=True)\n",
    "test_loader_dist = DataLoader(test_dataset_dist, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_dist(nn.Module):\n",
    "    def __init__(self,t):\n",
    "        super(model_dist, self).__init__()\n",
    "        self.t=t\n",
    "        self.l1=nn.Linear(195, 512)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.l2=nn.Linear(512, 256)\n",
    "        self.l3=nn.Linear(256, 64)\n",
    "        self.l4=nn.Linear(64, 2)\n",
    "        self.dropout= nn.Dropout(0.4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.l1(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l2(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l3(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l4(x)\n",
    "        x= nn.Softmax(dim=1)(x/self.t)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = nn.Sequential(nn.Linear(195, 512),\n",
    "#                       nn.ReLU(),\n",
    "#                       nn.Dropout(0.4),\n",
    "#                       nn.Linear(512, 256),\n",
    "#                       nn.ReLU(),\n",
    "#                       nn.Dropout(0.4),\n",
    "#                       nn.Linear(256, 64),\n",
    "#                       nn.ReLU(),\n",
    "#                       nn.Dropout(0.4),\n",
    "#                       nn.Linear(64, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=model_dist(5)\n",
    "criterion_dist =  nn.MSELoss()\n",
    "optimizer_dist = optim.SGD(model1.parameters(), lr=0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "916\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader._SingleProcessDataLoaderIter'>\n",
      "torch.float32\n",
      "images shape on batch size = torch.Size([20, 195])\n",
      "labels shape on batch size = torch.Size([20, 2])\n",
      "tensor([[2.1158e-03, 9.9788e-01],\n",
      "        [1.0000e+00, 3.4200e-09],\n",
      "        [1.0000e+00, 1.3287e-06],\n",
      "        [1.3147e-14, 1.0000e+00],\n",
      "        [1.7510e-05, 9.9998e-01],\n",
      "        [8.3498e-04, 9.9917e-01],\n",
      "        [1.8738e-03, 9.9813e-01],\n",
      "        [9.9999e-01, 8.0162e-06],\n",
      "        [9.9728e-01, 2.7164e-03],\n",
      "        [8.2245e-04, 9.9918e-01],\n",
      "        [1.1956e-17, 1.0000e+00],\n",
      "        [9.9983e-01, 1.7338e-04],\n",
      "        [9.9990e-01, 9.5843e-05],\n",
      "        [2.4578e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6909e-11],\n",
      "        [2.3488e-13, 1.0000e+00],\n",
      "        [2.4351e-06, 1.0000e+00],\n",
      "        [1.0000e+00, 3.7039e-08],\n",
      "        [1.0000e+00, 8.5875e-07],\n",
      "        [1.0000e+00, 5.4714e-08]])\n"
     ]
    }
   ],
   "source": [
    "train_iter_dist = iter(train_loader_dist)\n",
    "print(type(train_iter_dist))\n",
    "\n",
    "images, labels = train_iter_dist.next()\n",
    "print(images.dtype)\n",
    "print('images shape on batch size = {}'.format(images.size()))\n",
    "print('labels shape on batch size = {}'.format(labels.size()))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/40..  Training Loss: 0.241..  Test Loss: 0.234.. \n",
      "Epoch: 2/40..  Training Loss: 0.155..  Test Loss: 0.075.. \n",
      "Epoch: 3/40..  Training Loss: 0.059..  Test Loss: 0.051.. \n",
      "Epoch: 4/40..  Training Loss: 0.045..  Test Loss: 0.042.. \n",
      "Epoch: 5/40..  Training Loss: 0.039..  Test Loss: 0.036.. \n",
      "Epoch: 6/40..  Training Loss: 0.033..  Test Loss: 0.033.. \n",
      "Epoch: 7/40..  Training Loss: 0.029..  Test Loss: 0.030.. \n",
      "Epoch: 8/40..  Training Loss: 0.024..  Test Loss: 0.022.. \n",
      "Epoch: 9/40..  Training Loss: 0.020..  Test Loss: 0.019.. \n",
      "Epoch: 10/40..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 11/40..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 12/40..  Training Loss: 0.013..  Test Loss: 0.014.. \n",
      "Epoch: 13/40..  Training Loss: 0.012..  Test Loss: 0.014.. \n",
      "Epoch: 14/40..  Training Loss: 0.011..  Test Loss: 0.013.. \n",
      "Epoch: 15/40..  Training Loss: 0.010..  Test Loss: 0.011.. \n",
      "Epoch: 16/40..  Training Loss: 0.009..  Test Loss: 0.011.. \n",
      "Epoch: 17/40..  Training Loss: 0.009..  Test Loss: 0.013.. \n",
      "Epoch: 18/40..  Training Loss: 0.008..  Test Loss: 0.009.. \n",
      "Epoch: 19/40..  Training Loss: 0.008..  Test Loss: 0.009.. \n",
      "Epoch: 20/40..  Training Loss: 0.007..  Test Loss: 0.009.. \n",
      "Epoch: 21/40..  Training Loss: 0.007..  Test Loss: 0.009.. \n",
      "Epoch: 22/40..  Training Loss: 0.006..  Test Loss: 0.009.. \n",
      "Epoch: 23/40..  Training Loss: 0.006..  Test Loss: 0.010.. \n",
      "Epoch: 24/40..  Training Loss: 0.005..  Test Loss: 0.009.. \n",
      "Epoch: 25/40..  Training Loss: 0.006..  Test Loss: 0.008.. \n",
      "Epoch: 26/40..  Training Loss: 0.005..  Test Loss: 0.008.. \n",
      "Epoch: 27/40..  Training Loss: 0.005..  Test Loss: 0.007.. \n",
      "Epoch: 28/40..  Training Loss: 0.005..  Test Loss: 0.008.. \n",
      "Epoch: 29/40..  Training Loss: 0.005..  Test Loss: 0.007.. \n",
      "Epoch: 30/40..  Training Loss: 0.005..  Test Loss: 0.007.. \n",
      "Epoch: 31/40..  Training Loss: 0.005..  Test Loss: 0.007.. \n",
      "Epoch: 32/40..  Training Loss: 0.005..  Test Loss: 0.009.. \n",
      "Epoch: 33/40..  Training Loss: 0.004..  Test Loss: 0.007.. \n",
      "Epoch: 34/40..  Training Loss: 0.004..  Test Loss: 0.007.. \n",
      "Epoch: 35/40..  Training Loss: 0.004..  Test Loss: 0.008.. \n",
      "Epoch: 36/40..  Training Loss: 0.004..  Test Loss: 0.007.. \n",
      "Epoch: 37/40..  Training Loss: 0.004..  Test Loss: 0.007.. \n",
      "Epoch: 38/40..  Training Loss: 0.004..  Test Loss: 0.007.. \n",
      "Epoch: 39/40..  Training Loss: 0.004..  Test Loss: 0.007.. \n",
      "Epoch: 40/40..  Training Loss: 0.003..  Test Loss: 0.006.. \n"
     ]
    }
   ],
   "source": [
    "print_every = 40\n",
    "steps = 0\n",
    "epochs=40\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader_dist:\n",
    "        \n",
    "        optimizer_dist.zero_grad()\n",
    "#         print(labels)\n",
    "        log_ps = model1(images)\n",
    "#         print(log_ps)\n",
    "        loss = criterion_dist(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer_dist.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "#         accuracy = 0\n",
    "        \n",
    "        # Turn off gradients for validation, saves memory and computations\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader_dist:\n",
    "                log_ps = model1(images)\n",
    "                test_loss += criterion_dist(log_ps, labels)\n",
    "                \n",
    "#                 top_p, top_class = log_ps.topk(1, dim=1)\n",
    "#                 equals = top_class == labels.view(*top_class.shape)\n",
    "#                 accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                \n",
    "        train_losses.append(running_loss/len(train_loader_dist))\n",
    "        test_losses.append(test_loss/len(test_loader_dist))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader_dist)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader_dist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=torch.load('Train-512-256-64.pth')\n",
    "Models={ \"4-layered\": (model1,5620) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load('Train-512-256-64.pth')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier used here is : 4-layered\n",
      "Correct benign is 11102 \n",
      " correct malicious is 4412 \n",
      " converted to benign is  7030\n",
      "   bits_flipped     TP     TN    FN\n",
      "0             0  10855  11102   587\n",
      "1             1  10617  11102   825\n",
      "2             2  10366  11102  1076\n",
      "3             3  10032  11102  1410\n",
      "4             4   9452  11102  1990\n",
      "5             5   8692  11102  2750\n",
      "6             6   7800  11102  3642\n",
      "7             7   6898  11102  4544\n",
      "8             8   5999  11102  5443\n",
      "9             9   5168  11102  6274\n",
      "10           10   4412  11102  7030\n"
     ]
    }
   ],
   "source": [
    "#Attack with original attacker after retraining\n",
    "for Algorithm in Models:\n",
    "        df1=pd.DataFrame(columns = ['bits_flipped','TP', 'TN','FN'])\n",
    "        for i in range(0,11):\n",
    "            df1=df1.append(pd.Series([i, 11442, 0, 0], index= df1.columns), ignore_index=True )\n",
    "        print(\"Classifier used here is : {}\".format(Algorithm))\n",
    "        classifier= Models[Algorithm][0]\n",
    "        correct_benign=0\n",
    "        correct_malicious=0\n",
    "        convert_to_benign=0\n",
    "#         df=pd.read_csv(Algorithm+'_distillation.csv')\n",
    "#         X=df.iloc[:,:-1].values\n",
    "#         y=df.iloc[:,-1].values\n",
    "        target_model= Models[Algorithm][0]\n",
    "        test_dataset= Datasetcustom(X, y)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "        for images, labels in test_loader:\n",
    "            images.requires_grad = True\n",
    "            model.zero_grad()\n",
    "            output = model(images)\n",
    "            y_pred = target_model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            data_grad = images.grad.data\n",
    "            if  y_pred[0][1]>y_pred[0][0] and labels[0]==1: #predicted malicious\n",
    "                grad_list=[]\n",
    "                for i in range(195):\n",
    "                    if images[0][i]==0:\n",
    "                        grad_list.append((data_grad[0][i],i))\n",
    "                grad_list.sort(key = lambda x: x[0], reverse=True)\n",
    "                flag=0\n",
    "                for i in range(0,10):\n",
    "                    images[0][grad_list[i][1]]=1\n",
    "                    y_pred = target_model(images)\n",
    "                    if y_pred[0][0]>y_pred[0][1]:\n",
    "                        for j in range(i,10):  #converted in i+1 flips, hence all bits>=i+1, the FN will increase\n",
    "                            df1.iloc[j+1,3]+=1\n",
    "                            df1.iloc[j+1,1]-=1\n",
    "                        flag=1\n",
    "                        convert_to_benign+=1\n",
    "                        break\n",
    "                if flag==0:          #Even after 10 flips, unable to convert to benignm update malicious counter\n",
    "                    correct_malicious+=1\n",
    "            elif y_pred[0][0]>y_pred[0][1] and labels[0]==1:  #If predicted as benign but is malicious\n",
    "                for j in range(0,11):\n",
    "                    df1.iloc[j,3]+=1\n",
    "                    df1.iloc[j,1]-=1\n",
    "                convert_to_benign+=1\n",
    "            elif  y_pred[0][0]>y_pred[0][1] and labels[0]==0:  #if predicted benign correctly\n",
    "                for j in range(0,11):\n",
    "                    df1.iloc[j,2]+=1\n",
    "                correct_benign+=1\n",
    "        \n",
    "        print(\"Correct benign is {} \\n correct malicious is {} \\n converted to benign is  {}\".format(correct_benign, correct_malicious, convert_to_benign))\n",
    "#         print(\"Final Accuracy is {:.3f} with max {} bits flipped\".format((correct_benign+5553-convert_benign)/11274, num_bits))\n",
    "        print(df1)\n",
    "        df1.to_csv(str(Algorithm)+\"_HybridDistillation_5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  For 2 Layered Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Datasetcustom(X, y)\n",
    "test_dataset = Datasetcustom(X, y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=True)\n",
    "mal_loader=DataLoader(mal_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_2(nn.Module):\n",
    "    def __init__(self,t):\n",
    "        super(model_2, self).__init__()\n",
    "        self.t=t\n",
    "        self.l1=nn.Linear(195, 2)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.dropout= nn.Dropout(0.4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.l1(x)\n",
    "        x= nn.Softmax(dim=1)(x/self.t)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2= model_2(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_2.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100..  Training Loss: 0.681..  Test Loss: 0.672..  Test Accuracy: 0.673\n",
      "Epoch: 2/100..  Training Loss: 0.664..  Test Loss: 0.656..  Test Accuracy: 0.752\n",
      "Epoch: 3/100..  Training Loss: 0.650..  Test Loss: 0.643..  Test Accuracy: 0.776\n",
      "Epoch: 4/100..  Training Loss: 0.637..  Test Loss: 0.632..  Test Accuracy: 0.798\n",
      "Epoch: 5/100..  Training Loss: 0.627..  Test Loss: 0.622..  Test Accuracy: 0.817\n",
      "Epoch: 6/100..  Training Loss: 0.617..  Test Loss: 0.612..  Test Accuracy: 0.831\n",
      "Epoch: 7/100..  Training Loss: 0.608..  Test Loss: 0.604..  Test Accuracy: 0.849\n",
      "Epoch: 8/100..  Training Loss: 0.600..  Test Loss: 0.596..  Test Accuracy: 0.855\n",
      "Epoch: 9/100..  Training Loss: 0.592..  Test Loss: 0.588..  Test Accuracy: 0.861\n",
      "Epoch: 10/100..  Training Loss: 0.585..  Test Loss: 0.582..  Test Accuracy: 0.863\n",
      "Epoch: 11/100..  Training Loss: 0.578..  Test Loss: 0.575..  Test Accuracy: 0.866\n",
      "Epoch: 12/100..  Training Loss: 0.572..  Test Loss: 0.570..  Test Accuracy: 0.866\n",
      "Epoch: 13/100..  Training Loss: 0.567..  Test Loss: 0.564..  Test Accuracy: 0.867\n",
      "Epoch: 14/100..  Training Loss: 0.562..  Test Loss: 0.559..  Test Accuracy: 0.868\n",
      "Epoch: 15/100..  Training Loss: 0.557..  Test Loss: 0.555..  Test Accuracy: 0.869\n",
      "Epoch: 16/100..  Training Loss: 0.553..  Test Loss: 0.550..  Test Accuracy: 0.870\n",
      "Epoch: 17/100..  Training Loss: 0.549..  Test Loss: 0.547..  Test Accuracy: 0.870\n",
      "Epoch: 18/100..  Training Loss: 0.545..  Test Loss: 0.543..  Test Accuracy: 0.871\n",
      "Epoch: 19/100..  Training Loss: 0.541..  Test Loss: 0.539..  Test Accuracy: 0.873\n",
      "Epoch: 20/100..  Training Loss: 0.538..  Test Loss: 0.536..  Test Accuracy: 0.874\n",
      "Epoch: 21/100..  Training Loss: 0.534..  Test Loss: 0.533..  Test Accuracy: 0.874\n",
      "Epoch: 22/100..  Training Loss: 0.531..  Test Loss: 0.530..  Test Accuracy: 0.874\n",
      "Epoch: 23/100..  Training Loss: 0.529..  Test Loss: 0.527..  Test Accuracy: 0.875\n",
      "Epoch: 24/100..  Training Loss: 0.526..  Test Loss: 0.525..  Test Accuracy: 0.875\n",
      "Epoch: 25/100..  Training Loss: 0.523..  Test Loss: 0.522..  Test Accuracy: 0.876\n",
      "Epoch: 26/100..  Training Loss: 0.521..  Test Loss: 0.520..  Test Accuracy: 0.876\n",
      "Epoch: 27/100..  Training Loss: 0.519..  Test Loss: 0.518..  Test Accuracy: 0.877\n",
      "Epoch: 28/100..  Training Loss: 0.516..  Test Loss: 0.515..  Test Accuracy: 0.877\n",
      "Epoch: 29/100..  Training Loss: 0.514..  Test Loss: 0.513..  Test Accuracy: 0.877\n",
      "Epoch: 30/100..  Training Loss: 0.512..  Test Loss: 0.511..  Test Accuracy: 0.878\n",
      "Epoch: 31/100..  Training Loss: 0.511..  Test Loss: 0.510..  Test Accuracy: 0.879\n",
      "Epoch: 32/100..  Training Loss: 0.509..  Test Loss: 0.508..  Test Accuracy: 0.878\n",
      "Epoch: 33/100..  Training Loss: 0.507..  Test Loss: 0.506..  Test Accuracy: 0.879\n",
      "Epoch: 34/100..  Training Loss: 0.505..  Test Loss: 0.504..  Test Accuracy: 0.879\n",
      "Epoch: 35/100..  Training Loss: 0.504..  Test Loss: 0.503..  Test Accuracy: 0.880\n",
      "Epoch: 36/100..  Training Loss: 0.502..  Test Loss: 0.501..  Test Accuracy: 0.880\n",
      "Epoch: 37/100..  Training Loss: 0.501..  Test Loss: 0.500..  Test Accuracy: 0.879\n",
      "Epoch: 38/100..  Training Loss: 0.499..  Test Loss: 0.499..  Test Accuracy: 0.880\n",
      "Epoch: 39/100..  Training Loss: 0.498..  Test Loss: 0.497..  Test Accuracy: 0.880\n",
      "Epoch: 40/100..  Training Loss: 0.497..  Test Loss: 0.496..  Test Accuracy: 0.880\n",
      "Epoch: 41/100..  Training Loss: 0.495..  Test Loss: 0.495..  Test Accuracy: 0.880\n",
      "Epoch: 42/100..  Training Loss: 0.494..  Test Loss: 0.494..  Test Accuracy: 0.881\n",
      "Epoch: 43/100..  Training Loss: 0.493..  Test Loss: 0.493..  Test Accuracy: 0.881\n",
      "Epoch: 44/100..  Training Loss: 0.492..  Test Loss: 0.492..  Test Accuracy: 0.881\n",
      "Epoch: 45/100..  Training Loss: 0.491..  Test Loss: 0.490..  Test Accuracy: 0.881\n",
      "Epoch: 46/100..  Training Loss: 0.490..  Test Loss: 0.489..  Test Accuracy: 0.881\n",
      "Epoch: 47/100..  Training Loss: 0.489..  Test Loss: 0.488..  Test Accuracy: 0.881\n",
      "Epoch: 48/100..  Training Loss: 0.488..  Test Loss: 0.487..  Test Accuracy: 0.881\n",
      "Epoch: 49/100..  Training Loss: 0.487..  Test Loss: 0.486..  Test Accuracy: 0.881\n",
      "Epoch: 50/100..  Training Loss: 0.486..  Test Loss: 0.485..  Test Accuracy: 0.881\n",
      "Epoch: 51/100..  Training Loss: 0.485..  Test Loss: 0.484..  Test Accuracy: 0.881\n",
      "Epoch: 52/100..  Training Loss: 0.484..  Test Loss: 0.484..  Test Accuracy: 0.881\n",
      "Epoch: 53/100..  Training Loss: 0.483..  Test Loss: 0.483..  Test Accuracy: 0.882\n",
      "Epoch: 54/100..  Training Loss: 0.482..  Test Loss: 0.482..  Test Accuracy: 0.882\n",
      "Epoch: 55/100..  Training Loss: 0.482..  Test Loss: 0.481..  Test Accuracy: 0.882\n",
      "Epoch: 56/100..  Training Loss: 0.481..  Test Loss: 0.480..  Test Accuracy: 0.883\n",
      "Epoch: 57/100..  Training Loss: 0.480..  Test Loss: 0.480..  Test Accuracy: 0.883\n",
      "Epoch: 58/100..  Training Loss: 0.479..  Test Loss: 0.479..  Test Accuracy: 0.883\n",
      "Epoch: 59/100..  Training Loss: 0.478..  Test Loss: 0.478..  Test Accuracy: 0.883\n",
      "Epoch: 60/100..  Training Loss: 0.478..  Test Loss: 0.477..  Test Accuracy: 0.883\n",
      "Epoch: 61/100..  Training Loss: 0.477..  Test Loss: 0.477..  Test Accuracy: 0.884\n",
      "Epoch: 62/100..  Training Loss: 0.476..  Test Loss: 0.476..  Test Accuracy: 0.884\n",
      "Epoch: 63/100..  Training Loss: 0.476..  Test Loss: 0.475..  Test Accuracy: 0.884\n",
      "Epoch: 64/100..  Training Loss: 0.475..  Test Loss: 0.475..  Test Accuracy: 0.884\n",
      "Epoch: 65/100..  Training Loss: 0.475..  Test Loss: 0.474..  Test Accuracy: 0.884\n",
      "Epoch: 66/100..  Training Loss: 0.474..  Test Loss: 0.474..  Test Accuracy: 0.885\n",
      "Epoch: 67/100..  Training Loss: 0.473..  Test Loss: 0.473..  Test Accuracy: 0.885\n",
      "Epoch: 68/100..  Training Loss: 0.473..  Test Loss: 0.472..  Test Accuracy: 0.885\n",
      "Epoch: 69/100..  Training Loss: 0.472..  Test Loss: 0.472..  Test Accuracy: 0.885\n",
      "Epoch: 70/100..  Training Loss: 0.471..  Test Loss: 0.471..  Test Accuracy: 0.886\n",
      "Epoch: 71/100..  Training Loss: 0.471..  Test Loss: 0.471..  Test Accuracy: 0.886\n",
      "Epoch: 72/100..  Training Loss: 0.470..  Test Loss: 0.470..  Test Accuracy: 0.886\n",
      "Epoch: 73/100..  Training Loss: 0.470..  Test Loss: 0.470..  Test Accuracy: 0.886\n",
      "Epoch: 74/100..  Training Loss: 0.469..  Test Loss: 0.469..  Test Accuracy: 0.887\n",
      "Epoch: 75/100..  Training Loss: 0.469..  Test Loss: 0.469..  Test Accuracy: 0.887\n",
      "Epoch: 76/100..  Training Loss: 0.468..  Test Loss: 0.468..  Test Accuracy: 0.887\n",
      "Epoch: 77/100..  Training Loss: 0.468..  Test Loss: 0.468..  Test Accuracy: 0.887\n",
      "Epoch: 78/100..  Training Loss: 0.467..  Test Loss: 0.467..  Test Accuracy: 0.887\n",
      "Epoch: 79/100..  Training Loss: 0.467..  Test Loss: 0.467..  Test Accuracy: 0.887\n",
      "Epoch: 80/100..  Training Loss: 0.467..  Test Loss: 0.466..  Test Accuracy: 0.887\n",
      "Epoch: 81/100..  Training Loss: 0.466..  Test Loss: 0.466..  Test Accuracy: 0.887\n",
      "Epoch: 82/100..  Training Loss: 0.465..  Test Loss: 0.465..  Test Accuracy: 0.887\n",
      "Epoch: 83/100..  Training Loss: 0.465..  Test Loss: 0.465..  Test Accuracy: 0.889\n",
      "Epoch: 84/100..  Training Loss: 0.465..  Test Loss: 0.464..  Test Accuracy: 0.888\n",
      "Epoch: 85/100..  Training Loss: 0.464..  Test Loss: 0.464..  Test Accuracy: 0.889\n",
      "Epoch: 86/100..  Training Loss: 0.464..  Test Loss: 0.464..  Test Accuracy: 0.888\n",
      "Epoch: 87/100..  Training Loss: 0.463..  Test Loss: 0.463..  Test Accuracy: 0.888\n",
      "Epoch: 88/100..  Training Loss: 0.463..  Test Loss: 0.463..  Test Accuracy: 0.888\n",
      "Epoch: 89/100..  Training Loss: 0.463..  Test Loss: 0.463..  Test Accuracy: 0.888\n",
      "Epoch: 90/100..  Training Loss: 0.462..  Test Loss: 0.462..  Test Accuracy: 0.888\n",
      "Epoch: 91/100..  Training Loss: 0.462..  Test Loss: 0.462..  Test Accuracy: 0.888\n",
      "Epoch: 92/100..  Training Loss: 0.461..  Test Loss: 0.461..  Test Accuracy: 0.889\n",
      "Epoch: 93/100..  Training Loss: 0.461..  Test Loss: 0.461..  Test Accuracy: 0.889\n",
      "Epoch: 94/100..  Training Loss: 0.461..  Test Loss: 0.461..  Test Accuracy: 0.889\n",
      "Epoch: 95/100..  Training Loss: 0.460..  Test Loss: 0.460..  Test Accuracy: 0.889\n",
      "Epoch: 96/100..  Training Loss: 0.460..  Test Loss: 0.460..  Test Accuracy: 0.888\n",
      "Epoch: 97/100..  Training Loss: 0.460..  Test Loss: 0.459..  Test Accuracy: 0.889\n",
      "Epoch: 98/100..  Training Loss: 0.459..  Test Loss: 0.459..  Test Accuracy: 0.889\n",
      "Epoch: 99/100..  Training Loss: 0.459..  Test Loss: 0.459..  Test Accuracy: 0.889\n",
      "Epoch: 100/100..  Training Loss: 0.459..  Test Loss: 0.458..  Test Accuracy: 0.889\n"
     ]
    }
   ],
   "source": [
    "print_every = 40\n",
    "steps = 0\n",
    "epochs=100\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        log_ps = model_2(images)\n",
    "#         print(log_ps)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        # Turn off gradients for validation, saves memory and computations\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                log_ps = model_2(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                \n",
    "                top_p, top_class = log_ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                \n",
    "        train_losses.append(running_loss/len(train_loader))\n",
    "        test_losses.append(test_loss/len(test_loader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True)\n",
    "train_iter = iter(probs_loader)\n",
    "images, labels = train_iter.next()\n",
    "y_probs= model_2(images)\n",
    "y_probs=y_probs.detach().numpy()\n",
    "X_probs=images.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.676145  , 0.32385498],\n",
       "       [0.01731766, 0.98268235],\n",
       "       [0.922822  , 0.07717799],\n",
       "       [0.81566644, 0.18433353],\n",
       "       [0.3913577 , 0.60864234]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22884, 195)\n",
      "(22884, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y_probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =train_test_split(X_probs, y_probs, test_size = 0.2, random_state = 0)\n",
    "train_dataset_dist = Datasetcustom(X_train, y_train)\n",
    "test_dataset_dist= Datasetcustom(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_dist = DataLoader(train_dataset_dist, batch_size=20, shuffle=True)\n",
    "test_loader_dist = DataLoader(test_dataset_dist, batch_size=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_2dist(nn.Module):\n",
    "    def __init__(self,t):\n",
    "        super(model_2dist, self).__init__()\n",
    "        self.t=t\n",
    "        self.l1=nn.Linear(195, 2)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.dropout= nn.Dropout(0.4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.l1(x)\n",
    "        x= nn.Softmax(dim=1)(x/self.t)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2dist=model_2dist(5)\n",
    "criterion_dist =  nn.MSELoss()\n",
    "optimizer_dist = optim.SGD(model_2dist.parameters(), lr=0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "916\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader._SingleProcessDataLoaderIter'>\n",
      "torch.float32\n",
      "images shape on batch size = torch.Size([20, 195])\n",
      "labels shape on batch size = torch.Size([20, 2])\n",
      "tensor([[0.0084, 0.9916],\n",
      "        [0.7245, 0.2755],\n",
      "        [0.9353, 0.0647],\n",
      "        [0.9610, 0.0390],\n",
      "        [0.0054, 0.9946],\n",
      "        [0.1541, 0.8459],\n",
      "        [0.9395, 0.0605],\n",
      "        [0.7046, 0.2954],\n",
      "        [0.0162, 0.9838],\n",
      "        [0.0123, 0.9877],\n",
      "        [0.0113, 0.9887],\n",
      "        [0.0579, 0.9421],\n",
      "        [0.6294, 0.3706],\n",
      "        [0.8132, 0.1868],\n",
      "        [0.7866, 0.2134],\n",
      "        [0.0133, 0.9867],\n",
      "        [0.0039, 0.9961],\n",
      "        [0.1720, 0.8280],\n",
      "        [0.4281, 0.5719],\n",
      "        [0.0824, 0.9176]])\n"
     ]
    }
   ],
   "source": [
    "train_iter_dist = iter(train_loader_dist)\n",
    "print(type(train_iter_dist))\n",
    "\n",
    "images, labels = train_iter_dist.next()\n",
    "print(images.dtype)\n",
    "print('images shape on batch size = {}'.format(images.size()))\n",
    "print('labels shape on batch size = {}'.format(labels.size()))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/40..  Training Loss: 0.104..  Test Loss: 0.078.. \n",
      "Epoch: 2/40..  Training Loss: 0.064..  Test Loss: 0.051.. \n",
      "Epoch: 3/40..  Training Loss: 0.044..  Test Loss: 0.037.. \n",
      "Epoch: 4/40..  Training Loss: 0.033..  Test Loss: 0.028.. \n",
      "Epoch: 5/40..  Training Loss: 0.026..  Test Loss: 0.023.. \n",
      "Epoch: 6/40..  Training Loss: 0.021..  Test Loss: 0.019.. \n",
      "Epoch: 7/40..  Training Loss: 0.018..  Test Loss: 0.016.. \n",
      "Epoch: 8/40..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 9/40..  Training Loss: 0.013..  Test Loss: 0.012.. \n",
      "Epoch: 10/40..  Training Loss: 0.011..  Test Loss: 0.010.. \n",
      "Epoch: 11/40..  Training Loss: 0.010..  Test Loss: 0.009.. \n",
      "Epoch: 12/40..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 13/40..  Training Loss: 0.008..  Test Loss: 0.007.. \n",
      "Epoch: 14/40..  Training Loss: 0.007..  Test Loss: 0.006.. \n",
      "Epoch: 15/40..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 16/40..  Training Loss: 0.006..  Test Loss: 0.005.. \n",
      "Epoch: 17/40..  Training Loss: 0.005..  Test Loss: 0.005.. \n",
      "Epoch: 18/40..  Training Loss: 0.005..  Test Loss: 0.004.. \n",
      "Epoch: 19/40..  Training Loss: 0.004..  Test Loss: 0.004.. \n",
      "Epoch: 20/40..  Training Loss: 0.004..  Test Loss: 0.004.. \n",
      "Epoch: 21/40..  Training Loss: 0.004..  Test Loss: 0.003.. \n",
      "Epoch: 22/40..  Training Loss: 0.003..  Test Loss: 0.003.. \n",
      "Epoch: 23/40..  Training Loss: 0.003..  Test Loss: 0.003.. \n",
      "Epoch: 24/40..  Training Loss: 0.003..  Test Loss: 0.003.. \n",
      "Epoch: 25/40..  Training Loss: 0.003..  Test Loss: 0.003.. \n",
      "Epoch: 26/40..  Training Loss: 0.003..  Test Loss: 0.002.. \n",
      "Epoch: 27/40..  Training Loss: 0.002..  Test Loss: 0.002.. \n",
      "Epoch: 28/40..  Training Loss: 0.002..  Test Loss: 0.002.. \n",
      "Epoch: 29/40..  Training Loss: 0.002..  Test Loss: 0.002.. \n",
      "Epoch: 30/40..  Training Loss: 0.002..  Test Loss: 0.002.. \n",
      "Epoch: 31/40..  Training Loss: 0.002..  Test Loss: 0.002.. \n",
      "Epoch: 32/40..  Training Loss: 0.002..  Test Loss: 0.002.. \n",
      "Epoch: 33/40..  Training Loss: 0.002..  Test Loss: 0.002.. \n",
      "Epoch: 34/40..  Training Loss: 0.002..  Test Loss: 0.001.. \n",
      "Epoch: 35/40..  Training Loss: 0.001..  Test Loss: 0.001.. \n",
      "Epoch: 36/40..  Training Loss: 0.001..  Test Loss: 0.001.. \n",
      "Epoch: 37/40..  Training Loss: 0.001..  Test Loss: 0.001.. \n",
      "Epoch: 38/40..  Training Loss: 0.001..  Test Loss: 0.001.. \n",
      "Epoch: 39/40..  Training Loss: 0.001..  Test Loss: 0.001.. \n",
      "Epoch: 40/40..  Training Loss: 0.001..  Test Loss: 0.001.. \n"
     ]
    }
   ],
   "source": [
    "print_every = 40\n",
    "steps = 0\n",
    "epochs=40\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader_dist:\n",
    "        \n",
    "        optimizer_dist.zero_grad()\n",
    "#         print(labels)\n",
    "        log_ps = model_2dist(images)\n",
    "#         print(log_ps)\n",
    "        loss = criterion_dist(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer_dist.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader_dist:\n",
    "                log_ps = model_2dist(images)\n",
    "                test_loss += criterion_dist(log_ps, labels)   \n",
    "                \n",
    "        train_losses.append(running_loss/len(train_loader_dist))\n",
    "        test_losses.append(test_loss/len(test_loader_dist))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader_dist)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader_dist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=torch.load('Train-512-256-64.pth')\n",
    "Models={ \"2-layered\": (model_2dist,5620) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load('Train-512-256-64.pth')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier used here is : 2-layered\n",
      "Correct benign is 10122 \n",
      " correct malicious is 9852 \n",
      " converted to benign is  1590\n",
      "   bits_flipped     TP     TN    FN\n",
      "0             0  10080  10122  1362\n",
      "1             1   9984  10122  1458\n",
      "2             2   9946  10122  1496\n",
      "3             3   9928  10122  1514\n",
      "4             4   9912  10122  1530\n",
      "5             5   9899  10122  1543\n",
      "6             6   9889  10122  1553\n",
      "7             7   9885  10122  1557\n",
      "8             8   9874  10122  1568\n",
      "9             9   9865  10122  1577\n",
      "10           10   9852  10122  1590\n"
     ]
    }
   ],
   "source": [
    "#Attack with original attacker after retraining\n",
    "for Algorithm in Models:\n",
    "        df1=pd.DataFrame(columns = ['bits_flipped','TP', 'TN','FN'])\n",
    "        for i in range(0,11):\n",
    "            df1=df1.append(pd.Series([i,  11442, 0, 0], index= df1.columns), ignore_index=True )\n",
    "        print(\"Classifier used here is : {}\".format(Algorithm))\n",
    "        classifier= Models[Algorithm][0]\n",
    "        correct_benign=0\n",
    "        correct_malicious=0\n",
    "        convert_to_benign=0\n",
    "#         df=pd.read_csv(Algorithm+'_distillation.csv')\n",
    "#         X=df.iloc[:,:-1].values\n",
    "#         y=df.iloc[:,-1].values\n",
    "        target_model= Models[Algorithm][0]\n",
    "        test_dataset= Datasetcustom(X, y)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "        for images, labels in test_loader:\n",
    "            images.requires_grad = True\n",
    "            model.zero_grad()\n",
    "            output = model(images)\n",
    "            y_pred = target_model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            data_grad = images.grad.data\n",
    "            if  y_pred[0][1]>y_pred[0][0] and labels[0]==1: #predicted malicious\n",
    "                grad_list=[]\n",
    "                for i in range(195):\n",
    "                    if images[0][i]==0:\n",
    "                        grad_list.append((data_grad[0][i],i))\n",
    "                grad_list.sort(key = lambda x: x[0], reverse=True)\n",
    "                flag=0\n",
    "                for i in range(0,10):\n",
    "                    images[0][grad_list[i][1]]=1\n",
    "                    y_pred = target_model(images)\n",
    "                    if y_pred[0][0]>y_pred[0][1]:\n",
    "                        for j in range(i,10):  #converted in i+1 flips, hence all bits>=i+1, the FN will increase\n",
    "                            df1.iloc[j+1,3]+=1\n",
    "                            df1.iloc[j+1,1]-=1\n",
    "                        flag=1\n",
    "                        convert_to_benign+=1\n",
    "                        break\n",
    "                if flag==0:          #Even after 10 flips, unable to convert to benignm update malicious counter\n",
    "                    correct_malicious+=1\n",
    "            elif y_pred[0][0]>y_pred[0][1] and labels[0]==1:  #If predicted as benign but is malicious\n",
    "                for j in range(0,11):\n",
    "                    df1.iloc[j,3]+=1\n",
    "                    df1.iloc[j,1]-=1\n",
    "                convert_to_benign+=1\n",
    "            elif  y_pred[0][0]>y_pred[0][1] and labels[0]==0:  #if predicted benign correctly\n",
    "                for j in range(0,11):\n",
    "                    df1.iloc[j,2]+=1\n",
    "                correct_benign+=1\n",
    "        \n",
    "        print(\"Correct benign is {} \\n correct malicious is {} \\n converted to benign is  {}\".format(correct_benign, correct_malicious, convert_to_benign))\n",
    "#         print(\"Final Accuracy is {:.3f} with max {} bits flipped\".format((correct_benign+5553-convert_benign)/11274, num_bits))\n",
    "        print(df1)\n",
    "        df1.to_csv(str(Algorithm)+\"_HybridDistillation_5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is for 3 Layered Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Datasetcustom(X, y)\n",
    "test_dataset = Datasetcustom(X, y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=True)\n",
    "mal_loader=DataLoader(mal_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_3(nn.Module):\n",
    "    def __init__(self,t):\n",
    "        super(model_3, self).__init__()\n",
    "        self.t=t\n",
    "        self.l1=nn.Linear(195, 200)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.l2=nn.Linear(200, 200)\n",
    "        self.l3=nn.Linear(200, 2)\n",
    "        self.dropout= nn.Dropout(0.4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.l1(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l2(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l3(x)\n",
    "        x= nn.Softmax(dim=1)(x/self.t)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3= model_3(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_3.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100..  Training Loss: 0.692..  Test Loss: 0.692..  Test Accuracy: 0.665\n",
      "Epoch: 2/100..  Training Loss: 0.690..  Test Loss: 0.689..  Test Accuracy: 0.633\n",
      "Epoch: 3/100..  Training Loss: 0.686..  Test Loss: 0.683..  Test Accuracy: 0.589\n",
      "Epoch: 4/100..  Training Loss: 0.677..  Test Loss: 0.668..  Test Accuracy: 0.595\n",
      "Epoch: 5/100..  Training Loss: 0.653..  Test Loss: 0.636..  Test Accuracy: 0.701\n",
      "Epoch: 6/100..  Training Loss: 0.616..  Test Loss: 0.597..  Test Accuracy: 0.795\n",
      "Epoch: 7/100..  Training Loss: 0.579..  Test Loss: 0.560..  Test Accuracy: 0.851\n",
      "Epoch: 8/100..  Training Loss: 0.541..  Test Loss: 0.519..  Test Accuracy: 0.875\n",
      "Epoch: 9/100..  Training Loss: 0.500..  Test Loss: 0.482..  Test Accuracy: 0.881\n",
      "Epoch: 10/100..  Training Loss: 0.468..  Test Loss: 0.458..  Test Accuracy: 0.883\n",
      "Epoch: 11/100..  Training Loss: 0.450..  Test Loss: 0.444..  Test Accuracy: 0.887\n",
      "Epoch: 12/100..  Training Loss: 0.440..  Test Loss: 0.436..  Test Accuracy: 0.886\n",
      "Epoch: 13/100..  Training Loss: 0.432..  Test Loss: 0.430..  Test Accuracy: 0.892\n",
      "Epoch: 14/100..  Training Loss: 0.427..  Test Loss: 0.426..  Test Accuracy: 0.893\n",
      "Epoch: 15/100..  Training Loss: 0.425..  Test Loss: 0.421..  Test Accuracy: 0.896\n",
      "Epoch: 16/100..  Training Loss: 0.421..  Test Loss: 0.420..  Test Accuracy: 0.896\n",
      "Epoch: 17/100..  Training Loss: 0.419..  Test Loss: 0.418..  Test Accuracy: 0.898\n",
      "Epoch: 18/100..  Training Loss: 0.417..  Test Loss: 0.416..  Test Accuracy: 0.898\n",
      "Epoch: 19/100..  Training Loss: 0.415..  Test Loss: 0.415..  Test Accuracy: 0.900\n",
      "Epoch: 20/100..  Training Loss: 0.413..  Test Loss: 0.413..  Test Accuracy: 0.901\n",
      "Epoch: 21/100..  Training Loss: 0.411..  Test Loss: 0.411..  Test Accuracy: 0.902\n",
      "Epoch: 22/100..  Training Loss: 0.411..  Test Loss: 0.411..  Test Accuracy: 0.903\n",
      "Epoch: 23/100..  Training Loss: 0.410..  Test Loss: 0.410..  Test Accuracy: 0.904\n",
      "Epoch: 24/100..  Training Loss: 0.408..  Test Loss: 0.408..  Test Accuracy: 0.905\n",
      "Epoch: 25/100..  Training Loss: 0.408..  Test Loss: 0.407..  Test Accuracy: 0.905\n",
      "Epoch: 26/100..  Training Loss: 0.407..  Test Loss: 0.407..  Test Accuracy: 0.906\n",
      "Epoch: 27/100..  Training Loss: 0.406..  Test Loss: 0.406..  Test Accuracy: 0.906\n",
      "Epoch: 28/100..  Training Loss: 0.406..  Test Loss: 0.405..  Test Accuracy: 0.909\n",
      "Epoch: 29/100..  Training Loss: 0.404..  Test Loss: 0.405..  Test Accuracy: 0.907\n",
      "Epoch: 30/100..  Training Loss: 0.405..  Test Loss: 0.405..  Test Accuracy: 0.906\n",
      "Epoch: 31/100..  Training Loss: 0.403..  Test Loss: 0.403..  Test Accuracy: 0.909\n",
      "Epoch: 32/100..  Training Loss: 0.404..  Test Loss: 0.403..  Test Accuracy: 0.909\n",
      "Epoch: 33/100..  Training Loss: 0.403..  Test Loss: 0.403..  Test Accuracy: 0.909\n",
      "Epoch: 34/100..  Training Loss: 0.402..  Test Loss: 0.402..  Test Accuracy: 0.909\n",
      "Epoch: 35/100..  Training Loss: 0.402..  Test Loss: 0.401..  Test Accuracy: 0.911\n",
      "Epoch: 36/100..  Training Loss: 0.401..  Test Loss: 0.401..  Test Accuracy: 0.911\n",
      "Epoch: 37/100..  Training Loss: 0.401..  Test Loss: 0.401..  Test Accuracy: 0.912\n",
      "Epoch: 38/100..  Training Loss: 0.401..  Test Loss: 0.401..  Test Accuracy: 0.911\n",
      "Epoch: 39/100..  Training Loss: 0.401..  Test Loss: 0.400..  Test Accuracy: 0.911\n",
      "Epoch: 40/100..  Training Loss: 0.400..  Test Loss: 0.399..  Test Accuracy: 0.913\n",
      "Epoch: 41/100..  Training Loss: 0.400..  Test Loss: 0.399..  Test Accuracy: 0.913\n",
      "Epoch: 42/100..  Training Loss: 0.399..  Test Loss: 0.398..  Test Accuracy: 0.914\n",
      "Epoch: 43/100..  Training Loss: 0.398..  Test Loss: 0.399..  Test Accuracy: 0.914\n",
      "Epoch: 44/100..  Training Loss: 0.398..  Test Loss: 0.398..  Test Accuracy: 0.913\n",
      "Epoch: 45/100..  Training Loss: 0.398..  Test Loss: 0.398..  Test Accuracy: 0.914\n",
      "Epoch: 46/100..  Training Loss: 0.398..  Test Loss: 0.398..  Test Accuracy: 0.915\n",
      "Epoch: 47/100..  Training Loss: 0.397..  Test Loss: 0.398..  Test Accuracy: 0.914\n",
      "Epoch: 48/100..  Training Loss: 0.397..  Test Loss: 0.396..  Test Accuracy: 0.917\n",
      "Epoch: 49/100..  Training Loss: 0.397..  Test Loss: 0.397..  Test Accuracy: 0.914\n",
      "Epoch: 50/100..  Training Loss: 0.396..  Test Loss: 0.397..  Test Accuracy: 0.915\n",
      "Epoch: 51/100..  Training Loss: 0.396..  Test Loss: 0.396..  Test Accuracy: 0.916\n",
      "Epoch: 52/100..  Training Loss: 0.396..  Test Loss: 0.395..  Test Accuracy: 0.917\n",
      "Epoch: 53/100..  Training Loss: 0.395..  Test Loss: 0.395..  Test Accuracy: 0.916\n",
      "Epoch: 54/100..  Training Loss: 0.395..  Test Loss: 0.395..  Test Accuracy: 0.918\n",
      "Epoch: 55/100..  Training Loss: 0.395..  Test Loss: 0.394..  Test Accuracy: 0.917\n",
      "Epoch: 56/100..  Training Loss: 0.395..  Test Loss: 0.395..  Test Accuracy: 0.917\n",
      "Epoch: 57/100..  Training Loss: 0.394..  Test Loss: 0.395..  Test Accuracy: 0.917\n",
      "Epoch: 58/100..  Training Loss: 0.394..  Test Loss: 0.393..  Test Accuracy: 0.919\n",
      "Epoch: 59/100..  Training Loss: 0.393..  Test Loss: 0.393..  Test Accuracy: 0.920\n",
      "Epoch: 60/100..  Training Loss: 0.393..  Test Loss: 0.393..  Test Accuracy: 0.919\n",
      "Epoch: 61/100..  Training Loss: 0.392..  Test Loss: 0.392..  Test Accuracy: 0.920\n",
      "Epoch: 62/100..  Training Loss: 0.393..  Test Loss: 0.393..  Test Accuracy: 0.919\n",
      "Epoch: 63/100..  Training Loss: 0.392..  Test Loss: 0.392..  Test Accuracy: 0.920\n",
      "Epoch: 64/100..  Training Loss: 0.393..  Test Loss: 0.392..  Test Accuracy: 0.921\n",
      "Epoch: 65/100..  Training Loss: 0.392..  Test Loss: 0.391..  Test Accuracy: 0.922\n",
      "Epoch: 66/100..  Training Loss: 0.392..  Test Loss: 0.392..  Test Accuracy: 0.921\n",
      "Epoch: 67/100..  Training Loss: 0.392..  Test Loss: 0.392..  Test Accuracy: 0.921\n",
      "Epoch: 68/100..  Training Loss: 0.392..  Test Loss: 0.391..  Test Accuracy: 0.921\n",
      "Epoch: 69/100..  Training Loss: 0.391..  Test Loss: 0.391..  Test Accuracy: 0.922\n",
      "Epoch: 70/100..  Training Loss: 0.391..  Test Loss: 0.390..  Test Accuracy: 0.923\n",
      "Epoch: 71/100..  Training Loss: 0.390..  Test Loss: 0.390..  Test Accuracy: 0.923\n",
      "Epoch: 72/100..  Training Loss: 0.389..  Test Loss: 0.389..  Test Accuracy: 0.924\n",
      "Epoch: 73/100..  Training Loss: 0.389..  Test Loss: 0.389..  Test Accuracy: 0.923\n",
      "Epoch: 74/100..  Training Loss: 0.390..  Test Loss: 0.389..  Test Accuracy: 0.924\n",
      "Epoch: 75/100..  Training Loss: 0.389..  Test Loss: 0.388..  Test Accuracy: 0.925\n",
      "Epoch: 76/100..  Training Loss: 0.388..  Test Loss: 0.388..  Test Accuracy: 0.924\n",
      "Epoch: 77/100..  Training Loss: 0.388..  Test Loss: 0.388..  Test Accuracy: 0.924\n",
      "Epoch: 78/100..  Training Loss: 0.389..  Test Loss: 0.388..  Test Accuracy: 0.926\n",
      "Epoch: 79/100..  Training Loss: 0.387..  Test Loss: 0.388..  Test Accuracy: 0.925\n",
      "Epoch: 80/100..  Training Loss: 0.388..  Test Loss: 0.387..  Test Accuracy: 0.925\n",
      "Epoch: 81/100..  Training Loss: 0.387..  Test Loss: 0.386..  Test Accuracy: 0.927\n",
      "Epoch: 82/100..  Training Loss: 0.387..  Test Loss: 0.387..  Test Accuracy: 0.926\n",
      "Epoch: 83/100..  Training Loss: 0.387..  Test Loss: 0.386..  Test Accuracy: 0.927\n",
      "Epoch: 84/100..  Training Loss: 0.387..  Test Loss: 0.386..  Test Accuracy: 0.927\n",
      "Epoch: 85/100..  Training Loss: 0.386..  Test Loss: 0.386..  Test Accuracy: 0.927\n",
      "Epoch: 86/100..  Training Loss: 0.386..  Test Loss: 0.385..  Test Accuracy: 0.928\n",
      "Epoch: 87/100..  Training Loss: 0.385..  Test Loss: 0.386..  Test Accuracy: 0.927\n",
      "Epoch: 88/100..  Training Loss: 0.385..  Test Loss: 0.386..  Test Accuracy: 0.927\n",
      "Epoch: 89/100..  Training Loss: 0.385..  Test Loss: 0.385..  Test Accuracy: 0.928\n",
      "Epoch: 90/100..  Training Loss: 0.385..  Test Loss: 0.384..  Test Accuracy: 0.930\n",
      "Epoch: 91/100..  Training Loss: 0.384..  Test Loss: 0.384..  Test Accuracy: 0.929\n",
      "Epoch: 92/100..  Training Loss: 0.384..  Test Loss: 0.384..  Test Accuracy: 0.929\n",
      "Epoch: 93/100..  Training Loss: 0.383..  Test Loss: 0.383..  Test Accuracy: 0.930\n",
      "Epoch: 94/100..  Training Loss: 0.383..  Test Loss: 0.383..  Test Accuracy: 0.931\n",
      "Epoch: 95/100..  Training Loss: 0.383..  Test Loss: 0.382..  Test Accuracy: 0.931\n",
      "Epoch: 96/100..  Training Loss: 0.383..  Test Loss: 0.383..  Test Accuracy: 0.930\n",
      "Epoch: 97/100..  Training Loss: 0.382..  Test Loss: 0.382..  Test Accuracy: 0.932\n",
      "Epoch: 98/100..  Training Loss: 0.382..  Test Loss: 0.382..  Test Accuracy: 0.932\n",
      "Epoch: 99/100..  Training Loss: 0.381..  Test Loss: 0.381..  Test Accuracy: 0.932\n",
      "Epoch: 100/100..  Training Loss: 0.381..  Test Loss: 0.381..  Test Accuracy: 0.933\n"
     ]
    }
   ],
   "source": [
    "print_every = 40\n",
    "steps = 0\n",
    "epochs=100\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        log_ps = model_3(images)\n",
    "#         print(log_ps)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        # Turn off gradients for validation, saves memory and computations\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                log_ps = model_3(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                \n",
    "                top_p, top_class = log_ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                \n",
    "        train_losses.append(running_loss/len(train_loader))\n",
    "        test_losses.append(test_loss/len(test_loader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True)\n",
    "train_iter = iter(probs_loader)\n",
    "images, labels = train_iter.next()\n",
    "y_probs= model_3(images)\n",
    "y_probs=y_probs.detach().numpy()\n",
    "X_probs=images.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.5325069e-05, 9.9995470e-01],\n",
       "       [9.9993038e-01, 6.9581860e-05],\n",
       "       [9.9130768e-01, 8.6922823e-03],\n",
       "       [1.3472762e-10, 1.0000000e+00],\n",
       "       [5.8282504e-04, 9.9941719e-01]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22884, 195)\n",
      "(22884, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y_probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =train_test_split(X_probs, y_probs, test_size = 0.2, random_state = 0)\n",
    "train_dataset_dist = Datasetcustom(X_train, y_train)\n",
    "test_dataset_dist= Datasetcustom(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_dist = DataLoader(train_dataset_dist, batch_size=20, shuffle=True)\n",
    "test_loader_dist = DataLoader(test_dataset_dist, batch_size=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_3dist(nn.Module):\n",
    "    def __init__(self,t):\n",
    "        super(model_3dist, self).__init__()\n",
    "        self.t=t\n",
    "        self.l1=nn.Linear(195, 200)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.l2=nn.Linear(200, 200)\n",
    "        self.l3=nn.Linear(200, 2)\n",
    "        self.dropout= nn.Dropout(0.4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.l1(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l2(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l3(x)\n",
    "        x= nn.Softmax(dim=1)(x/self.t)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3dist=model_3dist(5)\n",
    "criterion_dist =  nn.MSELoss()\n",
    "optimizer_dist = optim.SGD(model_3dist.parameters(), lr=0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "916\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader._SingleProcessDataLoaderIter'>\n",
      "torch.float32\n",
      "images shape on batch size = torch.Size([20, 195])\n",
      "labels shape on batch size = torch.Size([20, 2])\n",
      "tensor([[1.8068e-04, 9.9982e-01],\n",
      "        [9.9999e-01, 5.4352e-06],\n",
      "        [9.9034e-01, 9.6605e-03],\n",
      "        [1.5352e-02, 9.8465e-01],\n",
      "        [7.0682e-07, 1.0000e+00],\n",
      "        [9.9999e-01, 7.3657e-06],\n",
      "        [1.0359e-07, 1.0000e+00],\n",
      "        [4.5932e-08, 1.0000e+00],\n",
      "        [9.9552e-01, 4.4813e-03],\n",
      "        [2.4170e-03, 9.9758e-01],\n",
      "        [9.9998e-01, 2.2087e-05],\n",
      "        [9.9766e-01, 2.3350e-03],\n",
      "        [4.4052e-01, 5.5948e-01],\n",
      "        [5.9191e-01, 4.0809e-01],\n",
      "        [9.9793e-01, 2.0664e-03],\n",
      "        [9.9973e-01, 2.6742e-04],\n",
      "        [9.9102e-01, 8.9751e-03],\n",
      "        [7.4909e-07, 1.0000e+00],\n",
      "        [1.2126e-04, 9.9988e-01],\n",
      "        [9.9830e-01, 1.6951e-03]])\n"
     ]
    }
   ],
   "source": [
    "train_iter_dist = iter(train_loader_dist)\n",
    "print(type(train_iter_dist))\n",
    "\n",
    "images, labels = train_iter_dist.next()\n",
    "print(images.dtype)\n",
    "print('images shape on batch size = {}'.format(images.size()))\n",
    "print('labels shape on batch size = {}'.format(labels.size()))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/40..  Training Loss: 0.210..  Test Loss: 0.157.. \n",
      "Epoch: 2/40..  Training Loss: 0.082..  Test Loss: 0.044.. \n",
      "Epoch: 3/40..  Training Loss: 0.033..  Test Loss: 0.027.. \n",
      "Epoch: 4/40..  Training Loss: 0.023..  Test Loss: 0.021.. \n",
      "Epoch: 5/40..  Training Loss: 0.018..  Test Loss: 0.016.. \n",
      "Epoch: 6/40..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 7/40..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 8/40..  Training Loss: 0.012..  Test Loss: 0.013.. \n",
      "Epoch: 9/40..  Training Loss: 0.010..  Test Loss: 0.011.. \n",
      "Epoch: 10/40..  Training Loss: 0.010..  Test Loss: 0.010.. \n",
      "Epoch: 11/40..  Training Loss: 0.009..  Test Loss: 0.008.. \n",
      "Epoch: 12/40..  Training Loss: 0.008..  Test Loss: 0.009.. \n",
      "Epoch: 13/40..  Training Loss: 0.008..  Test Loss: 0.008.. \n",
      "Epoch: 14/40..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 15/40..  Training Loss: 0.007..  Test Loss: 0.007.. \n",
      "Epoch: 16/40..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 17/40..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 18/40..  Training Loss: 0.006..  Test Loss: 0.006.. \n",
      "Epoch: 19/40..  Training Loss: 0.005..  Test Loss: 0.007.. \n",
      "Epoch: 20/40..  Training Loss: 0.005..  Test Loss: 0.006.. \n",
      "Epoch: 21/40..  Training Loss: 0.005..  Test Loss: 0.006.. \n",
      "Epoch: 22/40..  Training Loss: 0.005..  Test Loss: 0.005.. \n",
      "Epoch: 23/40..  Training Loss: 0.005..  Test Loss: 0.005.. \n",
      "Epoch: 24/40..  Training Loss: 0.005..  Test Loss: 0.005.. \n",
      "Epoch: 25/40..  Training Loss: 0.004..  Test Loss: 0.005.. \n",
      "Epoch: 26/40..  Training Loss: 0.005..  Test Loss: 0.005.. \n",
      "Epoch: 27/40..  Training Loss: 0.004..  Test Loss: 0.005.. \n",
      "Epoch: 28/40..  Training Loss: 0.004..  Test Loss: 0.005.. \n",
      "Epoch: 29/40..  Training Loss: 0.004..  Test Loss: 0.005.. \n",
      "Epoch: 30/40..  Training Loss: 0.004..  Test Loss: 0.005.. \n",
      "Epoch: 31/40..  Training Loss: 0.004..  Test Loss: 0.005.. \n",
      "Epoch: 32/40..  Training Loss: 0.004..  Test Loss: 0.005.. \n",
      "Epoch: 33/40..  Training Loss: 0.004..  Test Loss: 0.004.. \n",
      "Epoch: 34/40..  Training Loss: 0.004..  Test Loss: 0.005.. \n",
      "Epoch: 35/40..  Training Loss: 0.004..  Test Loss: 0.005.. \n",
      "Epoch: 36/40..  Training Loss: 0.004..  Test Loss: 0.004.. \n",
      "Epoch: 37/40..  Training Loss: 0.004..  Test Loss: 0.004.. \n",
      "Epoch: 38/40..  Training Loss: 0.004..  Test Loss: 0.005.. \n",
      "Epoch: 39/40..  Training Loss: 0.004..  Test Loss: 0.005.. \n",
      "Epoch: 40/40..  Training Loss: 0.004..  Test Loss: 0.004.. \n"
     ]
    }
   ],
   "source": [
    "print_every = 40\n",
    "steps = 0\n",
    "epochs=40\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader_dist:\n",
    "        \n",
    "        optimizer_dist.zero_grad()\n",
    "#         print(labels)\n",
    "        log_ps = model_3dist(images)\n",
    "#         print(log_ps)\n",
    "        loss = criterion_dist(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer_dist.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader_dist:\n",
    "                log_ps = model_3dist(images)\n",
    "                test_loss += criterion_dist(log_ps, labels)   \n",
    "                \n",
    "        train_losses.append(running_loss/len(train_loader_dist))\n",
    "        test_losses.append(test_loss/len(test_loader_dist))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader_dist)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader_dist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=torch.load('Train-512-256-64.pth')\n",
    "Models={ \"3-layered\": (model_3dist,5620) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load('Train-512-256-64.pth')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier used here is : 3-layered\n",
      "Correct benign is 10766 \n",
      " correct malicious is 6253 \n",
      " converted to benign is  5189\n",
      "   bits_flipped     TP     TN    FN\n",
      "0             0  10531  10766   911\n",
      "1             1  10284  10766  1158\n",
      "2             2  10160  10766  1282\n",
      "3             3  10005  10766  1437\n",
      "4             4   9786  10766  1656\n",
      "5             5   9408  10766  2034\n",
      "6             6   8934  10766  2508\n",
      "7             7   8256  10766  3186\n",
      "8             8   7581  10766  3861\n",
      "9             9   6918  10766  4524\n",
      "10           10   6253  10766  5189\n"
     ]
    }
   ],
   "source": [
    "#Attack with original attacker after retraining\n",
    "for Algorithm in Models:\n",
    "        df1=pd.DataFrame(columns = ['bits_flipped','TP', 'TN','FN'])\n",
    "        for i in range(0,11):\n",
    "            df1=df1.append(pd.Series([i, 11442, 0, 0], index= df1.columns), ignore_index=True )\n",
    "        print(\"Classifier used here is : {}\".format(Algorithm))\n",
    "        classifier= Models[Algorithm][0]\n",
    "        correct_benign=0\n",
    "        correct_malicious=0\n",
    "        convert_to_benign=0\n",
    "#         df=pd.read_csv(Algorithm+'_distillation.csv')\n",
    "#         X=df.iloc[:,:-1].values\n",
    "#         y=df.iloc[:,-1].values\n",
    "        target_model= Models[Algorithm][0]\n",
    "        test_dataset= Datasetcustom(X, y)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "        for images, labels in test_loader:\n",
    "            images.requires_grad = True\n",
    "            model.zero_grad()\n",
    "            output = model(images)\n",
    "            y_pred = target_model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            data_grad = images.grad.data\n",
    "            if  y_pred[0][1]>y_pred[0][0] and labels[0]==1: #predicted malicious\n",
    "                grad_list=[]\n",
    "                for i in range(195):\n",
    "                    if images[0][i]==0:\n",
    "                        grad_list.append((data_grad[0][i],i))\n",
    "                grad_list.sort(key = lambda x: x[0], reverse=True)\n",
    "                flag=0\n",
    "                for i in range(0,10):\n",
    "                    images[0][grad_list[i][1]]=1\n",
    "                    y_pred = target_model(images)\n",
    "                    if y_pred[0][0]>y_pred[0][1]:\n",
    "                        for j in range(i,10):  #converted in i+1 flips, hence all bits>=i+1, the FN will increase\n",
    "                            df1.iloc[j+1,3]+=1\n",
    "                            df1.iloc[j+1,1]-=1\n",
    "                        flag=1\n",
    "                        convert_to_benign+=1\n",
    "                        break\n",
    "                if flag==0:          #Even after 10 flips, unable to convert to benignm update malicious counter\n",
    "                    correct_malicious+=1\n",
    "            elif y_pred[0][0]>y_pred[0][1] and labels[0]==1:  #If predicted as benign but is malicious\n",
    "                for j in range(0,11):\n",
    "                    df1.iloc[j,3]+=1\n",
    "                    df1.iloc[j,1]-=1\n",
    "                convert_to_benign+=1\n",
    "            elif  y_pred[0][0]>y_pred[0][1] and labels[0]==0:  #if predicted benign correctly\n",
    "                for j in range(0,11):\n",
    "                    df1.iloc[j,2]+=1\n",
    "                correct_benign+=1\n",
    "        \n",
    "        print(\"Correct benign is {} \\n correct malicious is {} \\n converted to benign is  {}\".format(correct_benign, correct_malicious, convert_to_benign))\n",
    "#         print(\"Final Accuracy is {:.3f} with max {} bits flipped\".format((correct_benign+5553-convert_benign)/11274, num_bits))\n",
    "        print(df1)\n",
    "        df1.to_csv(str(Algorithm)+\"_HybridDistillation_5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is for 5  Layered Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Datasetcustom(X, y)\n",
    "test_dataset = Datasetcustom(X, y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=True)\n",
    "mal_loader=DataLoader(mal_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_5(nn.Module):\n",
    "    def __init__(self,t):\n",
    "        super(model_5, self).__init__()\n",
    "        self.t=t\n",
    "        self.l1=nn.Linear(195, 512)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.l2=nn.Linear(512, 256)\n",
    "        self.l3= nn.Linear(256, 64)\n",
    "        self.l4=nn.Linear(64, 32)\n",
    "        self.l5=nn.Linear(32, 2)\n",
    "        self.dropout= nn.Dropout(0.4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.l1(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l2(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l3(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l4(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l5(x)\n",
    "        x= nn.Softmax(dim=1)(x/self.t)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5= model_5(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_5.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100..  Training Loss: 0.693..  Test Loss: 0.693..  Test Accuracy: 0.501\n",
      "Epoch: 2/100..  Training Loss: 0.693..  Test Loss: 0.693..  Test Accuracy: 0.501\n",
      "Epoch: 3/100..  Training Loss: 0.693..  Test Loss: 0.693..  Test Accuracy: 0.504\n",
      "Epoch: 4/100..  Training Loss: 0.693..  Test Loss: 0.693..  Test Accuracy: 0.509\n",
      "Epoch: 5/100..  Training Loss: 0.693..  Test Loss: 0.693..  Test Accuracy: 0.519\n",
      "Epoch: 6/100..  Training Loss: 0.693..  Test Loss: 0.693..  Test Accuracy: 0.534\n",
      "Epoch: 7/100..  Training Loss: 0.693..  Test Loss: 0.693..  Test Accuracy: 0.557\n",
      "Epoch: 8/100..  Training Loss: 0.693..  Test Loss: 0.692..  Test Accuracy: 0.586\n",
      "Epoch: 9/100..  Training Loss: 0.692..  Test Loss: 0.692..  Test Accuracy: 0.623\n",
      "Epoch: 10/100..  Training Loss: 0.692..  Test Loss: 0.692..  Test Accuracy: 0.646\n",
      "Epoch: 11/100..  Training Loss: 0.692..  Test Loss: 0.691..  Test Accuracy: 0.675\n",
      "Epoch: 12/100..  Training Loss: 0.691..  Test Loss: 0.690..  Test Accuracy: 0.689\n",
      "Epoch: 13/100..  Training Loss: 0.689..  Test Loss: 0.688..  Test Accuracy: 0.713\n",
      "Epoch: 14/100..  Training Loss: 0.686..  Test Loss: 0.683..  Test Accuracy: 0.727\n",
      "Epoch: 15/100..  Training Loss: 0.676..  Test Loss: 0.665..  Test Accuracy: 0.743\n",
      "Epoch: 16/100..  Training Loss: 0.641..  Test Loss: 0.611..  Test Accuracy: 0.792\n",
      "Epoch: 17/100..  Training Loss: 0.583..  Test Loss: 0.556..  Test Accuracy: 0.854\n",
      "Epoch: 18/100..  Training Loss: 0.532..  Test Loss: 0.506..  Test Accuracy: 0.878\n",
      "Epoch: 19/100..  Training Loss: 0.483..  Test Loss: 0.465..  Test Accuracy: 0.883\n",
      "Epoch: 20/100..  Training Loss: 0.453..  Test Loss: 0.443..  Test Accuracy: 0.889\n",
      "Epoch: 21/100..  Training Loss: 0.438..  Test Loss: 0.433..  Test Accuracy: 0.892\n",
      "Epoch: 22/100..  Training Loss: 0.429..  Test Loss: 0.423..  Test Accuracy: 0.898\n",
      "Epoch: 23/100..  Training Loss: 0.422..  Test Loss: 0.420..  Test Accuracy: 0.899\n",
      "Epoch: 24/100..  Training Loss: 0.418..  Test Loss: 0.416..  Test Accuracy: 0.900\n",
      "Epoch: 25/100..  Training Loss: 0.415..  Test Loss: 0.413..  Test Accuracy: 0.904\n",
      "Epoch: 26/100..  Training Loss: 0.413..  Test Loss: 0.411..  Test Accuracy: 0.906\n",
      "Epoch: 27/100..  Training Loss: 0.410..  Test Loss: 0.408..  Test Accuracy: 0.908\n",
      "Epoch: 28/100..  Training Loss: 0.407..  Test Loss: 0.406..  Test Accuracy: 0.909\n",
      "Epoch: 29/100..  Training Loss: 0.405..  Test Loss: 0.405..  Test Accuracy: 0.910\n",
      "Epoch: 30/100..  Training Loss: 0.405..  Test Loss: 0.403..  Test Accuracy: 0.912\n",
      "Epoch: 31/100..  Training Loss: 0.402..  Test Loss: 0.401..  Test Accuracy: 0.914\n",
      "Epoch: 32/100..  Training Loss: 0.400..  Test Loss: 0.400..  Test Accuracy: 0.914\n",
      "Epoch: 33/100..  Training Loss: 0.399..  Test Loss: 0.401..  Test Accuracy: 0.914\n",
      "Epoch: 34/100..  Training Loss: 0.400..  Test Loss: 0.397..  Test Accuracy: 0.917\n",
      "Epoch: 35/100..  Training Loss: 0.398..  Test Loss: 0.395..  Test Accuracy: 0.920\n",
      "Epoch: 36/100..  Training Loss: 0.395..  Test Loss: 0.395..  Test Accuracy: 0.919\n",
      "Epoch: 37/100..  Training Loss: 0.395..  Test Loss: 0.394..  Test Accuracy: 0.920\n",
      "Epoch: 38/100..  Training Loss: 0.393..  Test Loss: 0.392..  Test Accuracy: 0.923\n",
      "Epoch: 39/100..  Training Loss: 0.392..  Test Loss: 0.392..  Test Accuracy: 0.923\n",
      "Epoch: 40/100..  Training Loss: 0.390..  Test Loss: 0.389..  Test Accuracy: 0.926\n",
      "Epoch: 41/100..  Training Loss: 0.389..  Test Loss: 0.388..  Test Accuracy: 0.926\n",
      "Epoch: 42/100..  Training Loss: 0.389..  Test Loss: 0.388..  Test Accuracy: 0.927\n",
      "Epoch: 43/100..  Training Loss: 0.387..  Test Loss: 0.386..  Test Accuracy: 0.929\n",
      "Epoch: 44/100..  Training Loss: 0.386..  Test Loss: 0.384..  Test Accuracy: 0.930\n",
      "Epoch: 45/100..  Training Loss: 0.385..  Test Loss: 0.384..  Test Accuracy: 0.930\n",
      "Epoch: 46/100..  Training Loss: 0.384..  Test Loss: 0.384..  Test Accuracy: 0.930\n",
      "Epoch: 47/100..  Training Loss: 0.382..  Test Loss: 0.381..  Test Accuracy: 0.933\n",
      "Epoch: 48/100..  Training Loss: 0.381..  Test Loss: 0.381..  Test Accuracy: 0.933\n",
      "Epoch: 49/100..  Training Loss: 0.381..  Test Loss: 0.379..  Test Accuracy: 0.936\n",
      "Epoch: 50/100..  Training Loss: 0.380..  Test Loss: 0.378..  Test Accuracy: 0.936\n",
      "Epoch: 51/100..  Training Loss: 0.379..  Test Loss: 0.377..  Test Accuracy: 0.937\n",
      "Epoch: 52/100..  Training Loss: 0.379..  Test Loss: 0.376..  Test Accuracy: 0.938\n",
      "Epoch: 53/100..  Training Loss: 0.376..  Test Loss: 0.375..  Test Accuracy: 0.940\n",
      "Epoch: 54/100..  Training Loss: 0.374..  Test Loss: 0.374..  Test Accuracy: 0.940\n",
      "Epoch: 55/100..  Training Loss: 0.373..  Test Loss: 0.373..  Test Accuracy: 0.942\n",
      "Epoch: 56/100..  Training Loss: 0.373..  Test Loss: 0.372..  Test Accuracy: 0.944\n",
      "Epoch: 57/100..  Training Loss: 0.372..  Test Loss: 0.372..  Test Accuracy: 0.943\n",
      "Epoch: 58/100..  Training Loss: 0.371..  Test Loss: 0.370..  Test Accuracy: 0.945\n",
      "Epoch: 59/100..  Training Loss: 0.370..  Test Loss: 0.369..  Test Accuracy: 0.946\n",
      "Epoch: 60/100..  Training Loss: 0.368..  Test Loss: 0.371..  Test Accuracy: 0.944\n",
      "Epoch: 61/100..  Training Loss: 0.368..  Test Loss: 0.369..  Test Accuracy: 0.946\n",
      "Epoch: 62/100..  Training Loss: 0.368..  Test Loss: 0.367..  Test Accuracy: 0.949\n",
      "Epoch: 63/100..  Training Loss: 0.369..  Test Loss: 0.366..  Test Accuracy: 0.948\n",
      "Epoch: 64/100..  Training Loss: 0.367..  Test Loss: 0.370..  Test Accuracy: 0.944\n",
      "Epoch: 65/100..  Training Loss: 0.367..  Test Loss: 0.365..  Test Accuracy: 0.949\n",
      "Epoch: 66/100..  Training Loss: 0.365..  Test Loss: 0.366..  Test Accuracy: 0.949\n",
      "Epoch: 67/100..  Training Loss: 0.365..  Test Loss: 0.365..  Test Accuracy: 0.949\n",
      "Epoch: 68/100..  Training Loss: 0.365..  Test Loss: 0.365..  Test Accuracy: 0.950\n",
      "Epoch: 69/100..  Training Loss: 0.365..  Test Loss: 0.364..  Test Accuracy: 0.951\n",
      "Epoch: 70/100..  Training Loss: 0.364..  Test Loss: 0.364..  Test Accuracy: 0.951\n",
      "Epoch: 71/100..  Training Loss: 0.364..  Test Loss: 0.363..  Test Accuracy: 0.951\n",
      "Epoch: 72/100..  Training Loss: 0.363..  Test Loss: 0.364..  Test Accuracy: 0.951\n",
      "Epoch: 73/100..  Training Loss: 0.363..  Test Loss: 0.364..  Test Accuracy: 0.951\n",
      "Epoch: 74/100..  Training Loss: 0.362..  Test Loss: 0.362..  Test Accuracy: 0.953\n",
      "Epoch: 75/100..  Training Loss: 0.362..  Test Loss: 0.361..  Test Accuracy: 0.953\n",
      "Epoch: 76/100..  Training Loss: 0.361..  Test Loss: 0.361..  Test Accuracy: 0.954\n",
      "Epoch: 77/100..  Training Loss: 0.362..  Test Loss: 0.361..  Test Accuracy: 0.954\n",
      "Epoch: 78/100..  Training Loss: 0.362..  Test Loss: 0.360..  Test Accuracy: 0.954\n",
      "Epoch: 79/100..  Training Loss: 0.361..  Test Loss: 0.360..  Test Accuracy: 0.954\n",
      "Epoch: 80/100..  Training Loss: 0.360..  Test Loss: 0.359..  Test Accuracy: 0.955\n",
      "Epoch: 81/100..  Training Loss: 0.360..  Test Loss: 0.360..  Test Accuracy: 0.955\n",
      "Epoch: 82/100..  Training Loss: 0.359..  Test Loss: 0.359..  Test Accuracy: 0.955\n",
      "Epoch: 83/100..  Training Loss: 0.360..  Test Loss: 0.360..  Test Accuracy: 0.955\n",
      "Epoch: 84/100..  Training Loss: 0.359..  Test Loss: 0.358..  Test Accuracy: 0.956\n",
      "Epoch: 85/100..  Training Loss: 0.360..  Test Loss: 0.359..  Test Accuracy: 0.955\n",
      "Epoch: 86/100..  Training Loss: 0.358..  Test Loss: 0.358..  Test Accuracy: 0.957\n",
      "Epoch: 87/100..  Training Loss: 0.359..  Test Loss: 0.359..  Test Accuracy: 0.956\n",
      "Epoch: 88/100..  Training Loss: 0.358..  Test Loss: 0.358..  Test Accuracy: 0.957\n",
      "Epoch: 89/100..  Training Loss: 0.358..  Test Loss: 0.358..  Test Accuracy: 0.957\n",
      "Epoch: 90/100..  Training Loss: 0.357..  Test Loss: 0.358..  Test Accuracy: 0.957\n",
      "Epoch: 91/100..  Training Loss: 0.358..  Test Loss: 0.357..  Test Accuracy: 0.957\n",
      "Epoch: 92/100..  Training Loss: 0.357..  Test Loss: 0.358..  Test Accuracy: 0.957\n",
      "Epoch: 93/100..  Training Loss: 0.357..  Test Loss: 0.357..  Test Accuracy: 0.957\n",
      "Epoch: 94/100..  Training Loss: 0.357..  Test Loss: 0.356..  Test Accuracy: 0.958\n",
      "Epoch: 95/100..  Training Loss: 0.357..  Test Loss: 0.356..  Test Accuracy: 0.958\n",
      "Epoch: 96/100..  Training Loss: 0.357..  Test Loss: 0.356..  Test Accuracy: 0.958\n",
      "Epoch: 97/100..  Training Loss: 0.357..  Test Loss: 0.356..  Test Accuracy: 0.959\n",
      "Epoch: 98/100..  Training Loss: 0.356..  Test Loss: 0.355..  Test Accuracy: 0.959\n",
      "Epoch: 99/100..  Training Loss: 0.355..  Test Loss: 0.356..  Test Accuracy: 0.959\n",
      "Epoch: 100/100..  Training Loss: 0.356..  Test Loss: 0.356..  Test Accuracy: 0.958\n"
     ]
    }
   ],
   "source": [
    "print_every = 40\n",
    "steps = 0\n",
    "epochs=100\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        log_ps = model_5(images)\n",
    "#         print(log_ps)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        # Turn off gradients for validation, saves memory and computations\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                log_ps = model_5(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                \n",
    "                top_p, top_class = log_ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                \n",
    "        train_losses.append(running_loss/len(train_loader))\n",
    "        test_losses.append(test_loss/len(test_loader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True)\n",
    "train_iter = iter(probs_loader)\n",
    "images, labels = train_iter.next()\n",
    "y_probs= model_5(images)\n",
    "y_probs=y_probs.detach().numpy()\n",
    "X_probs=images.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9999404e-01, 5.9977260e-06],\n",
       "       [9.9994314e-01, 5.6847704e-05],\n",
       "       [9.9999571e-01, 4.2576462e-06],\n",
       "       [9.9935967e-01, 6.4032339e-04],\n",
       "       [9.9999607e-01, 3.9647698e-06]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22884, 195)\n",
      "(22884, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y_probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =train_test_split(X_probs, y_probs, test_size = 0.2, random_state = 0)\n",
    "train_dataset_dist = Datasetcustom(X_train, y_train)\n",
    "test_dataset_dist= Datasetcustom(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_dist = DataLoader(train_dataset_dist, batch_size=20, shuffle=True)\n",
    "test_loader_dist = DataLoader(test_dataset_dist, batch_size=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_5dist(nn.Module):\n",
    "    def __init__(self,t):\n",
    "        super(model_5dist, self).__init__()\n",
    "        self.t=t\n",
    "        self.l1=nn.Linear(195, 512)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.l2=nn.Linear(512, 256)\n",
    "        self.l3= nn.Linear(256, 64)\n",
    "        self.l4=nn.Linear(64, 32)\n",
    "        self.l5=nn.Linear(32, 2)\n",
    "        self.dropout= nn.Dropout(0.4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.l1(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l2(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l3(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l4(x)\n",
    "        x=self.relu(x)\n",
    "        x= self.dropout(x)\n",
    "        x= self.l5(x)\n",
    "        x= nn.Softmax(dim=1)(x/self.t)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5dist=model_5dist(5)\n",
    "criterion_dist =  nn.MSELoss()\n",
    "optimizer_dist = optim.SGD(model_5dist.parameters(), lr=0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "916\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader._SingleProcessDataLoaderIter'>\n",
      "torch.float32\n",
      "images shape on batch size = torch.Size([20, 195])\n",
      "labels shape on batch size = torch.Size([20, 2])\n",
      "tensor([[9.9974e-01, 2.5745e-04],\n",
      "        [1.3923e-10, 1.0000e+00],\n",
      "        [4.5683e-09, 1.0000e+00],\n",
      "        [4.5097e-02, 9.5490e-01],\n",
      "        [9.9998e-01, 1.8984e-05],\n",
      "        [4.6403e-01, 5.3597e-01],\n",
      "        [9.9996e-01, 4.4921e-05],\n",
      "        [1.0000e+00, 1.0254e-09],\n",
      "        [9.8503e-01, 1.4974e-02],\n",
      "        [1.0000e+00, 7.9239e-09],\n",
      "        [9.9993e-01, 7.2911e-05],\n",
      "        [2.9643e-10, 1.0000e+00],\n",
      "        [3.3702e-05, 9.9997e-01],\n",
      "        [9.9999e-01, 8.0235e-06],\n",
      "        [8.6743e-04, 9.9913e-01],\n",
      "        [1.0000e+00, 3.7270e-07],\n",
      "        [8.1307e-01, 1.8693e-01],\n",
      "        [9.9972e-01, 2.7908e-04],\n",
      "        [8.9104e-02, 9.1090e-01],\n",
      "        [5.4555e-04, 9.9945e-01]])\n"
     ]
    }
   ],
   "source": [
    "train_iter_dist = iter(train_loader_dist)\n",
    "print(type(train_iter_dist))\n",
    "\n",
    "images, labels = train_iter_dist.next()\n",
    "print(images.dtype)\n",
    "print('images shape on batch size = {}'.format(images.size()))\n",
    "print('labels shape on batch size = {}'.format(labels.size()))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/40..  Training Loss: 0.244..  Test Loss: 0.244.. \n",
      "Epoch: 2/40..  Training Loss: 0.242..  Test Loss: 0.240.. \n",
      "Epoch: 3/40..  Training Loss: 0.189..  Test Loss: 0.099.. \n",
      "Epoch: 4/40..  Training Loss: 0.074..  Test Loss: 0.058.. \n",
      "Epoch: 5/40..  Training Loss: 0.051..  Test Loss: 0.049.. \n",
      "Epoch: 6/40..  Training Loss: 0.041..  Test Loss: 0.040.. \n",
      "Epoch: 7/40..  Training Loss: 0.032..  Test Loss: 0.032.. \n",
      "Epoch: 8/40..  Training Loss: 0.027..  Test Loss: 0.024.. \n",
      "Epoch: 9/40..  Training Loss: 0.022..  Test Loss: 0.021.. \n",
      "Epoch: 10/40..  Training Loss: 0.019..  Test Loss: 0.020.. \n",
      "Epoch: 11/40..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 12/40..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 13/40..  Training Loss: 0.013..  Test Loss: 0.015.. \n",
      "Epoch: 14/40..  Training Loss: 0.013..  Test Loss: 0.019.. \n",
      "Epoch: 15/40..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 16/40..  Training Loss: 0.011..  Test Loss: 0.015.. \n",
      "Epoch: 17/40..  Training Loss: 0.011..  Test Loss: 0.012.. \n",
      "Epoch: 18/40..  Training Loss: 0.010..  Test Loss: 0.012.. \n",
      "Epoch: 19/40..  Training Loss: 0.010..  Test Loss: 0.011.. \n",
      "Epoch: 20/40..  Training Loss: 0.010..  Test Loss: 0.012.. \n",
      "Epoch: 21/40..  Training Loss: 0.009..  Test Loss: 0.012.. \n",
      "Epoch: 22/40..  Training Loss: 0.009..  Test Loss: 0.011.. \n",
      "Epoch: 23/40..  Training Loss: 0.008..  Test Loss: 0.010.. \n",
      "Epoch: 24/40..  Training Loss: 0.008..  Test Loss: 0.011.. \n",
      "Epoch: 25/40..  Training Loss: 0.008..  Test Loss: 0.011.. \n",
      "Epoch: 26/40..  Training Loss: 0.008..  Test Loss: 0.013.. \n",
      "Epoch: 27/40..  Training Loss: 0.008..  Test Loss: 0.010.. \n",
      "Epoch: 28/40..  Training Loss: 0.008..  Test Loss: 0.014.. \n",
      "Epoch: 29/40..  Training Loss: 0.008..  Test Loss: 0.011.. \n",
      "Epoch: 30/40..  Training Loss: 0.008..  Test Loss: 0.011.. \n",
      "Epoch: 31/40..  Training Loss: 0.007..  Test Loss: 0.009.. \n",
      "Epoch: 32/40..  Training Loss: 0.007..  Test Loss: 0.010.. \n",
      "Epoch: 33/40..  Training Loss: 0.007..  Test Loss: 0.010.. \n",
      "Epoch: 34/40..  Training Loss: 0.007..  Test Loss: 0.011.. \n",
      "Epoch: 35/40..  Training Loss: 0.007..  Test Loss: 0.012.. \n",
      "Epoch: 36/40..  Training Loss: 0.006..  Test Loss: 0.011.. \n",
      "Epoch: 37/40..  Training Loss: 0.007..  Test Loss: 0.009.. \n",
      "Epoch: 38/40..  Training Loss: 0.007..  Test Loss: 0.010.. \n",
      "Epoch: 39/40..  Training Loss: 0.006..  Test Loss: 0.010.. \n",
      "Epoch: 40/40..  Training Loss: 0.006..  Test Loss: 0.010.. \n"
     ]
    }
   ],
   "source": [
    "print_every = 40\n",
    "steps = 0\n",
    "epochs=40\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader_dist:\n",
    "        \n",
    "        optimizer_dist.zero_grad()\n",
    "#         print(labels)\n",
    "        log_ps = model_5dist(images)\n",
    "#         print(log_ps)\n",
    "        loss = criterion_dist(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer_dist.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader_dist:\n",
    "                log_ps = model_5dist(images)\n",
    "                test_loss += criterion_dist(log_ps, labels)   \n",
    "                \n",
    "        train_losses.append(running_loss/len(train_loader_dist))\n",
    "        test_losses.append(test_loss/len(test_loader_dist))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader_dist)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader_dist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=torch.load('Train-512-256-64.pth')\n",
    "Models={ \"5-layered\": (model_5dist,5620) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load('Train-512-256-64.pth')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier used here is : 5-layered\n",
      "Correct benign is 11139 \n",
      " correct malicious is 4942 \n",
      " converted to benign is  6500\n",
      "   bits_flipped     TP     TN    FN\n",
      "0             0  10748  11139   694\n",
      "1             1  10463  11139   979\n",
      "2             2  10215  11139  1227\n",
      "3             3   9916  11139  1526\n",
      "4             4   9468  11139  1974\n",
      "5             5   8835  11139  2607\n",
      "6             6   8054  11139  3388\n",
      "7             7   7208  11139  4234\n",
      "8             8   6374  11139  5068\n",
      "9             9   5610  11139  5832\n",
      "10           10   4942  11139  6500\n"
     ]
    }
   ],
   "source": [
    "#Attack with original attacker after retraining\n",
    "for Algorithm in Models:\n",
    "        df1=pd.DataFrame(columns = ['bits_flipped','TP', 'TN','FN'])\n",
    "        for i in range(0,11):\n",
    "            df1=df1.append(pd.Series([i,  11442, 0, 0], index= df1.columns), ignore_index=True )\n",
    "        print(\"Classifier used here is : {}\".format(Algorithm))\n",
    "        classifier= Models[Algorithm][0]\n",
    "        correct_benign=0\n",
    "        correct_malicious=0\n",
    "        convert_to_benign=0\n",
    "#         df=pd.read_csv(Algorithm+'_distillation.csv')\n",
    "#         X=df.iloc[:,:-1].values\n",
    "#         y=df.iloc[:,-1].values\n",
    "        target_model= Models[Algorithm][0]\n",
    "        test_dataset= Datasetcustom(X, y)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "        for images, labels in test_loader:\n",
    "            images.requires_grad = True\n",
    "            model.zero_grad()\n",
    "            output = model(images)\n",
    "            y_pred = target_model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            data_grad = images.grad.data\n",
    "            if  y_pred[0][1]>y_pred[0][0] and labels[0]==1: #predicted malicious\n",
    "                grad_list=[]\n",
    "                for i in range(195):\n",
    "                    if images[0][i]==0:\n",
    "                        grad_list.append((data_grad[0][i],i))\n",
    "                grad_list.sort(key = lambda x: x[0], reverse=True)\n",
    "                flag=0\n",
    "                for i in range(0,10):\n",
    "                    images[0][grad_list[i][1]]=1\n",
    "                    y_pred = target_model(images)\n",
    "                    if y_pred[0][0]>y_pred[0][1]:\n",
    "                        for j in range(i,10):  #converted in i+1 flips, hence all bits>=i+1, the FN will increase\n",
    "                            df1.iloc[j+1,3]+=1\n",
    "                            df1.iloc[j+1,1]-=1\n",
    "                        flag=1\n",
    "                        convert_to_benign+=1\n",
    "                        break\n",
    "                if flag==0:          #Even after 10 flips, unable to convert to benignm update malicious counter\n",
    "                    correct_malicious+=1\n",
    "            elif y_pred[0][0]>y_pred[0][1] and labels[0]==1:  #If predicted as benign but is malicious\n",
    "                for j in range(0,11):\n",
    "                    df1.iloc[j,3]+=1\n",
    "                    df1.iloc[j,1]-=1\n",
    "                convert_to_benign+=1\n",
    "            elif  y_pred[0][0]>y_pred[0][1] and labels[0]==0:  #if predicted benign correctly\n",
    "                for j in range(0,11):\n",
    "                    df1.iloc[j,2]+=1\n",
    "                correct_benign+=1\n",
    "        \n",
    "        print(\"Correct benign is {} \\n correct malicious is {} \\n converted to benign is  {}\".format(correct_benign, correct_malicious, convert_to_benign))\n",
    "#         print(\"Final Accuracy is {:.3f} with max {} bits flipped\".format((correct_benign+5553-convert_benign)/11274, num_bits))\n",
    "        print(df1)\n",
    "        df1.to_csv(str(Algorithm)+\"_HybridDistillation_5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproject",
   "language": "python",
   "name": "mlproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
